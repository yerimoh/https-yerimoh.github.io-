---
title: "Quantifying the advantage of domain-specific pre-training on named entity recognition tasks in materials science
 정리" 
date:   2023-08-17
excerpt: "Quantifying the advantage of domain-specific pre-training on named entity recognition tasks in materials science"
category: [Paper]
layout: post
tag:
- Paper
order: 0

comments: true
---

   **[원 논문]**     
[Quantifying the advantage of domain-specific pre-training on named entity recognition tasks in materials science](https://www.sciencedirect.com/science/article/pii/S2666389922000733)


-----


# THE BIGGER PICTURE 
새로운 materials 발견을 기존 문헌에 효율적으로 연결하는 데 병목 현상이 발생했음.     
그래서 이를 해결하기위해 materials science articles에서 **중요한 정보를 자동으로 수집**하도록 네 가지 언어 모델을 교육한다.      
그리고 materials 과학 지식을 갖춘 간단한 모델(BiLSTM)을 3가지 science model과 비교한다.       
**1)** 일반 지식을 갖춘 모델 (BERT)    
**2)** 일반 과학 지식을 갖춘 모델 (SciBERT)    
**3)** materials 과학 지식을 갖춘 모델(MatBERT)    

그 결과,    
* **MatBERT가 전반적으로 가장 성능이 좋음**을 발견함.          
이것은 materials 과학 지식을 담은 언어 모델이 materials 과학 관련 작업에서 더 잘 수행할 것임을 암시한다.     
* 더 간단한 모델은 심지어 지속적으로 BERT를 능가한다.           
* 모델이 **배울 정보 추출의 예가 더 적을 때 성능 격차가 증가**     


MatBERT의 더 높은 품질의 결과는 materials 과학 문헌에서 정보 수집을 가속화해야할 것이다.     


----

# SUMMARY
많은 established literature로 인해 **새로운 재료 발견을 기존 문헌에 효율적으로 연결하는 데 병목 현상이 발생**함      
이 문제는 **NER(Named Entity Recognition)** 를 사용하여 <span style="background-color:#fff5b1">**비정형 재료 과학 텍스트**에서 **구조화된 요약 수준 데이터**를 **추출**함으로써 해결</span> 가능.    

**[실험]**
우리는 3개의  materials science datasets에서 4개의 NER 모델의 성능을 비교함.      
* **4개의 모델:**
a bidirectional long shortterm memory (BiLSTM)      
domain-specific materials science pre-training 정도가 증가하는 3개의 transformer models(BERT, SciBERT 및 MatBERT)이 포함됨

**[결과]**       
* **MatBERT**는 다른 2개의 BERTBASE 기반 모델보다 1%~12% 향상되 **domain-specific pre-training이 측정 가능한 이점을 제공**한다는 것을 의미함       
* **BiLSTM** 모델은  **domain-specific pre-trained word embeddings** 때문에 BERT를 지속적으로 능가
* 게다가, **MatBERT와 SciBERT** 모델은 **작은 데이터 한계에도 original BERT 모델보다 더 우수**      

 
 MatBERT의 materials science literature에서 **구조화된 데이터 추출을 가속화**해야한다.        

----


# **INTRODUCTION**
**[PROBLEM]**        
* 최근 재료 과학 분야의 출판물 수가 기하급수적으로 증가하고 있다.       
그 결과, 연구자들은 상대적으로 <span style="background-color:#fff5b1">제한된 하위 영역 내에서도 **연구 성과를 따라가기가 점점 어려워지고 있다**</span>       
* <span style="background-color:#fff5b1">재료과학 문헌이 매우 많아 졌다는 것은 이전에 **특정 응용을 위해 연구된 재료 후보들이 어떤 것**인지와 같은 **비교적 간단한 질문**들조차도 포괄적으로 **대답하기가 어렵거나 불가능**할 수 있다</span>는 것을 의미한다.       
* <span style="background-color:#FFE6E6">이것은 **관련 문헌과 관련된 정보를 추출**하기 위한 **새롭고 효율적인 방법에 대한 필요성**을 창출함</span>           


**[Motivation]**      
* **Natural language processing (NLP)로 접근**해 위 문제 해결 시도.        
NLP는 많은 재료 과학 응용 분야에 성공적으로 적용되었고 재료 정보학 분야에서 최근 몇 가지 연구의 주제이기 때문        
* BERT와 같은 **transformer ML 아키텍처**의 등장은 NLP를 벤치마크화했다          
Transformer models 은 downstream tasks을 위해 pre train과 fine tuning의 개념을 도입합.    
이 방식은 task별 모델이 비교적 적은 hand-annotated examples를 사용하여 교육될 수 있도록 한다.      
* single pre-trained model이 여러 NLP 작업(예: QA, NER, 다음 문장 예측)을 처리할 수 있지만,
domain-specific pre-training 모델(예: BioBERT, CaseHOLD)의 성공이 아래의 질문을 제기한다.
<span style="background-color:#FFE6E6"> **can transformer models be further improved with even more domain-specific pre-training?**</span>
즉, domain-specific pre-training을 transformer에 model에 적용해해도 성능이 좋을까라는 의문이다.


**[Main Idea]**       
* domain-specific pre-training로 보여졌던 측정 가능한 이점(예: SciBERT)이 **재료 과학과 같은 더 좁은 과학 분야에 특화된 모델**로 **다시 확장될 수 있다고 가정**        
✨ 여기서, domain-specific 모델 성능이 향상되었다는 것은 (NLP 모델의 관점에서) 가장 복잡하고 성가신 과학 영역에서도 **자동화된 지식 추출 능력이 향상**되었다는 것을 의미함


**[NER]**    
* transformer models을 **named entity recognition(NER)** 작업에 적용하여 비정형 텍스트에서 **재료 화학과 관련**된 **중요한 과학 개체를 추출하고 레이블을 지정**한다.
* 본 연구에서, 우리는 **3개의 다른 재료 과학 데이터 세트**에 **4개의 다른 NER 모델**을 적용하고 성능을 분석한다.


------

# Datasets
Here we consider three different NER datasets, chosen to represent a diversity of text sources and problems relevant to materials science; a set of solid-state materials science abstracts
with entities of broad interest,28 a set of abstracts with inorganic
doping information, and a set of methods/results sections relevant to gold nanoparticle synthesis. Each of these is described
in detail below. The solid-state dataset is publicly available,63
though only the DOIs and annotated entities are available for
the other two.64


## Solid-state dataset
The solid-state dataset discussed in this work consists of 800
annotated abstracts from solid-state materials publications
collected using Elsevier’s Scopus/ScienceDirect65 and
Springer-Nature66 APIs as well as web scraping for journals published by the Royal Society of Chemistry67 and the Electrochemical Society.68 Abstracts are considered relevant if they mention
at least one inorganic material and at least one synthesis or characterization method for inorganic materials. The entity labels are
chosen to represent a broad domain of materials science knowledge with eight different labeled entity types: inorganic materials
(MAT), symmetry/phase labels (SPL), sample descriptors (DSC),
material properties (PRO), material applications (APL), synthesis
methods (SMT), and characterization methods (CMT). Details of
the collection and pre-processing of these abstracts and
detailed definitions of the labels are available in Weston et al.28


A condensed example is shown in Figure 1.
69 This dataset is
intended to provide a ‘‘catch-all’’ of relevant information without
focusing on any specific facet of solid-state materials. Due to the
broad definitions of the entities, the solid-state dataset generally
contains more entities per paragraph than the other datasets.
Additionally, an inter-annotator agreement of 87:4% was evaluated utilizing 25 annotations from a second annotator.28

