---
title: "[+] Deep learning 1: 배치 정규화 Batch Normalization"
date:   2020-03-8
excerpt: "배치 정규화 Batch Normalization,배치 정규화 알고리즘,배치 정규화 과정 "
category: [Deep Learning]
layout: post
tag:
- Deep Learning
order: 0

comments: true
---


# 목차
- [배치 정규화 Batch Normalization](#배치-정규화-batch-normalization)
  * [배치 정규화 알고리즘](#배치-정규화-알고리즘)
  * [배치 정규화 과정](#배치-정규화-과정)
- [정리](#정리)


---



👀, 🤷‍♀️ , 📜    
이 아이콘들을 누르시면 코드, 개념 부가 설명을 보실 수 있습니다:)


---
----



# 배치 정규화 Batch Normalization

앞 절에서는 각 층의 활성화값 분포를 직접 관찰 후, 가중치의 초깃값을 적절히 설정           
그렇다면 **각 층이 활성화를 적당히 퍼뜨리도록 ‘강제’**해보면?            
➡ 배치 정규화 Batch Normalization를 이용


---


## 배치 정규화 알고리즘
**[의미]**    
1) 미니배치의 평균과 분산을 이용해서 정규화 한 뒤에      
2) scale 및 shift 를 감마(γ) 값, 베타(β) 값을 통해 실행     
3)  정규화 된 값을 활성화 함수의 입력으로 사용하고, 최종 출력 값을 다음 레이어의 입력으로 사용       

**[장점]**     
* 학습을 빨리 진행할 수 있다(학습 속도 개선).     
* 초깃값에 크게 의존하지 않는다(골치 아픈 초깃값 선택 장애여 안녕!).     
* 오버피팅을 억제한다(드롭아웃 등의 필요성 감소).         

➡ ‘배치 정규화 Batch Norm 계층’을 신경망에 삽입

![image](https://user-images.githubusercontent.com/76824611/128637880-045a1ae0-e79d-4e95-8b2c-e830601e2fd6.png)

----


## 배치 정규화 과정   
학습 시 미니배치를 단위로 정규화       
➡ 데이터 분포가 평균이 0, 분산이 1이 되도록 정규화     
미니배치 B = {x 1 , x 2 , ..., x m }이라는 m개의 입력 데이터집합     
**1)** 평균 μ B 와분산 σ B2 구함       
**2)** 입력 데이터를 **평균이 0, 분산이 1**이 되게(적절한 분포가 되게) 정규화.    
* 이 처리를 활성화 함수의 앞(혹은 뒤)에 삽입함으로써 **데이터 분포가 덜 치우치게** 할 수 있음.          ![image](https://user-images.githubusercontent.com/76824611/128638137-3490d074-08f8-486b-8eee-f303195c954b.png)
+ ɛ(epsilon, 엡실론) 는 작은 값(예컨대 10e-7 등)으로, 0으로 나누는 사태를 예방하는 역할    
    ex)       
    단순히 미니배치 입력 데이터{x 1 , x 2 , ..., x m }을 평균 0, 분산 1인 데이터 {x ˆ 1 , x ˆ 2 , ..., x ˆ m }으로 변환하는 일을 함        
    {4,5,6} -> {-0.01,0,0.01}

**3)** 배치 정규화 계층마다 이 정규화된 데이터에 고유한 확대 scale 와 이동 shift 변환을 수행.     ![image](https://user-images.githubusercontent.com/76824611/128638295-f1787682-e7ff-4e36-955e-29a22c8cc48c.png)
* γ: 확대     
* β: 이동     
처음에는 γ = 1(1배 확대), β = 0(이동 안함)부터 시작하고,     
학습하면서 적합한 값으로 조정해감     
➡ 이 알고리즘이 신경망에서 순전파 때 적용     
![image](https://user-images.githubusercontent.com/76824611/128638467-56f457c1-916f-46dd-9713-8c0201c65ab9.png) 


----
----

# 정리  
● 배치 정규화를 이용하면 학습을 빠르게 진행할 수 있으며, 초깃값에 영향을 덜 받게 된다.       
     
