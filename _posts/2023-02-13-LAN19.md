---
title: "Do Language Models Understand Measurements? 정리"
date:   2023-02-13
excerpt: "Do Language Models Understand Measurements?"
category: [Paper]
layout: post
tag:
- Paper
order: 0

comments: true
---


# 목차 




# Abstract
**[배경]**     
최근 pre-trained language models (PLMs)의 **성공은 숫자를 이해**하고 **작업**하는 능력에 대한 관심을 자극했다.     

**[문제]**     
그러나 <span style="background-color:#FFE6E6">**측정에 대한 수치 추론**은 그 중요성에도 불구하고 공식적으로 연구되지 않았다</span>.    

**[논문의 목적]**       
본 논문은 아래와 같은 내용으로 구성되어있다.     
* **PLMs가 측정에 대한 추론에 필요한 능력이 부족**하다는 것을 보여준다.       
* **measurement-rich 말뭉치에 대해 train된 언어 모델**이, **understanding measurements**에 **더 나은 성능**을 보인다는 것을 발견했다.     
* 본 논문은 **숫자와 단위를 더 잘 구별**하기 위한 **간단한 임베딩 전략**을 제안한다.   
➡ 이는 probing tasks의 상당한 개선으로 이어진다.   



# 1 Introduction
**[기존 연구]**     
pre-trained language models (PLMs)의 성공은 **상식을 이해하는 능력**에 대한 더 많은 연구로 이어졌다.    
이러한 맥락에서 숫자 또는 단어 형태의 숫자를 해석하고 작업하는 NLP 모델의 능력 연구,    
수치, 스칼라 크기 비교, 수치 사실 및 수학 단어 문제에 대한 질문에 답하기 위한 NRoT 테스트 PLM에 대한 연구가 최근에 진행되었었다.       



**[기존 연구의 한계]**     
이러한 노력에도 불구하고 기존의 paper들은 **숫자가 나타나는 형태에 대한 분석이 부족**하다.    
특히, 우리는 맥락에서 숫자가 **measurement으로 나타나는 경우에만 초점을 맞추는 경향**이 있다.   
* **위 문제점의 예**        
대부분의 과학 기사에서 measurement은 **맥락의 필수적인 부분**이다.(적적한 의미를 담기 위해선)   
아래 두 문장을 보자    
![image](https://user-images.githubusercontent.com/76824611/220443999-fd3d274d-c83b-48d2-80b9-067b155f6675.png)   
두 문장은 측정단위(unit of measurement,UoM)인 g과 mg을 제외하고는 같은 단어이지만,    
두 번째 문장은 UoM 때문에 incorrect하다.    


**[본 논문의 개선: MST]**    
* 본 논문에서는 PLMs의 **measuring skill**를 조사한다.     
즉, measurement **시스템을 이해**하고 measurement에 대한 **수치 추론을 수행하는 능력**을 조사한다.     
* <span style="background-color:#fff5b1">세 가지 측정 기술 테스트(measuring skill tests, MSTs)를 설계</span> 한다.     
➡ 얼마나 많은 measuring 기술을 습득할 수 있는지 연구한다.       
   * **UNIT CONVERSION(단위 변환)**: 측정 시스템에 대한 이해 필요        
   * **REFERENCE RANGE DETECTION(기준 범위 검출)**: 생체 의학 실체의 정상 범위 이해 필요       
   * **MEASUREMENT COMPARISON(측정 비교)**: 측정 시스템과 NRoT에 대한 지식을 결합할 수 있는 능력 필요로 한다. * Table 1 은 각 measuring skill tests의 예를 보여줌(MST 결과)      
![image](https://user-images.githubusercontent.com/76824611/223579239-cffa8d7f-e759-466e-ac85-7e19d00a71f1.png)


**[실험 및 결과 요약]**
* 한계 발견: 모델들이 measurements 목록에서 **가장 큰(또는 가장 작은) 값을 찾고**, **측정값을 다른 단위로 변환**하는 데 어려움을 겪음    
* 장점: 그 외의 다른 테스트에서는 잘 작동함       
* 다른 PLM에 비해 BioBERT(Lee et al., 2020)는 UNIT CONVERSION 및 REFERENCE RANGE Detection에서 우수한 성능을 보임     
➡ **measurements가 풍부한 텍스트를 사용한 pre-trian**이 모델의 measurements 시스템 **이해 능력에 도움**이 된다는 것을 의미한다.       


마지막으로,    
본 논문은 **맥락에서 숫자, 단위 및 다른 단어를 구별하는 기술의 부족**이 **일부 MST에서 모델을 실패**하게 한다고 추측한다.     
➡ 이를 완화하기 위해 input 텍스트에서 숫자의 위치와 척도에 대한 정보를 모델에 제공하는 <span style="background-color:#fff5b1">**scale  embedding**</span>을 도입한다.    
우리는 scale  embedding이 모든 PLM의 MST 성능을 크게 향상시킨다는 것을 보여준다.     



---
----

# 2 Measuring Skill Test
In this section, we describe three MSTs to carefully
study the ability of PLMs to understand the system
of measurement and perform numerical reasoning
over the measurements.



----

## 2.1 Unit Conversion
This task requires the model to decide whether
the two measurements represent the same quantity.
For example, the model might correctly predict
[MASK] in a sentence, such as "3.5g and 3500mg
are [MASK] value" to be filled with same if it under
stands the conversion of units correctly. In general,
it is a convention to combine the unit (e.g., liter,
meter) and its prefix (e.g., kilo, milli) to represent
the numerical value of the measurement within a
range [10−3, 103). Therefore, various unit prefixes
can appear in a single passage, even if the units
are the same. To handle this, UNIT CONVERSION
is essential for complex reasoning over measurements. To succeed in UNIT CONVERSION, we expect the model to handle the unit and numerical
value jointly, based on an understanding of the system of measurement


## 2.2 Reference Range Detection
Given a biomedical entity and measurement, this
task requires a model to predict whether the measurement falls within the reference range. Knowledge of the biomedical entity plays a crucial role
in understanding measurements, since the unit is
determined by the biomedical entity. For example,
we measure the hemoglobin level in g/dL. In addition to understanding UoMs, PLMs must rely on
domain knowledge embedded in their parameters
to solve this task, as context alone does not provide
sufficient clues as to what the reference range is for
the given biomedical entity

## 2.3 Measurement Comparison
Given two measurements (or a series of n measurements), the task is to predict the correct relationship between them. We created the synthetic dataset following other well-known NRoT
tasks. Here, we consider three numerical reasoning tasks: COMPARISON (Talmor et al., 2020),
ARGMIN/MAX (Wallace et al., 2019), and SORTING (Pal and Baral, 2021), all requiring the model
to compare numbers. Note that each measurement
in this task can have a different unit prefix. For
example, the sample "1.59mg is [MASK] than 3.8g"
containing two different units "mg" and "g" appears
in the COMPARISON dataset. This task assesses the
model’s ability to combine an understanding of
measurements and numerical reasoning skills.



**[INTRO]**      
NIPS에서 Google이 소개했던 Transformer는 NLP 학계에서 정말 큰 주목을 받음  
CNN 과 RNN 이 주를 이뤘던 연구들에서 벗어나 아예 새로운 모델을 제안했기 때문    

**[핵심]**     

**[읽기 위해 필요한 지식]**    
* [attention](https://yerimoh.github.io/DL19/)       
* [transformer](https://yerimoh.github.io/Lan/)    


**[원 논문]**    
[Self-Attention with Relative Position Representations](https://arxiv.org/pdf/1803.02155.pdf)  


----
