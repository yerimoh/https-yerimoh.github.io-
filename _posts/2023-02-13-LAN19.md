---
title: "Do Language Models Understand Measurements? 정리"
date:   2023-02-13
excerpt: "Do Language Models Understand Measurements?"
category: [Paper]
layout: post
tag:
- Paper
order: 0

comments: true
---


# 목차 




# Abstract
<span style="background-color:#F5F5F5">**[배경]**</span>     
최근 pre-trained language models (PLMs)의 **성공은 숫자를 이해**하고 **작업**하는 능력에 대한 관심을 자극했다.     

<span style="background-color:#F5F5F5">**[문제]**</span>     
그러나 <span style="background-color:#FFE6E6">**측정에 대한 수치 추론**은 그 중요성에도 불구하고 공식적으로 연구되지 않았다</span>.    

<span style="background-color:#F5F5F5">**[논문의 목적]**</span>       
본 논문은 아래와 같은 내용으로 구성되어있다.     
* **PLMs가 측정에 대한 추론에 필요한 능력이 부족**하다는 것을 보여준다.       
* **measurement-rich 말뭉치에 대해 train된 언어 모델**이, **understanding measurements**에 **더 나은 성능**을 보인다는 것을 발견했다.     
* 본 논문은 **숫자와 단위를 더 잘 구별**하기 위한 **간단한 임베딩 전략**을 제안한다.   
➡ 이는 probing tasks의 상당한 개선으로 이어진다.   



# 1 Introduction
<span style="background-color:#F5F5F5">**[기존 연구]**</span>     
pre-trained language models (PLMs)의 성공은 **상식을 이해하는 능력**에 대한 더 많은 연구로 이어졌다.    
이러한 맥락에서 숫자 또는 단어 형태의 숫자를 해석하고 작업하는 NLP 모델의 능력 연구,    
수치, 스칼라 크기 비교, 수치 사실 및 수학 단어 문제에 대한 질문에 답하기 위한 NRoT 테스트 PLM에 대한 연구가 최근에 진행되었었다.       



<span style="background-color:#F5F5F5">**[기존 연구의 한계]**</span>     
이러한 노력에도 불구하고 기존의 paper들은 **숫자가 나타나는 형태에 대한 분석이 부족**하다.    
특히,  논문은 맥락에서 숫자가 **measurement으로 나타나는 경우에만 초점을 맞추는 경향**이 있다.   
* **위 문제점의 예**        
대부분의 과학 기사에서 measurement은 **맥락의 필수적인 부분**이다.(적절한 의미를 담기 위해선)   
아래 두 문장을 보자    
![image](https://user-images.githubusercontent.com/76824611/220443999-fd3d274d-c83b-48d2-80b9-067b155f6675.png)   
두 문장은 측정단위(unit of measurement,UoM)인 g과 mg을 제외하고는 같은 단어이지만,    
두 번째 문장은 UoM 때문에 incorrect하다.    


<span style="background-color:#F5F5F5">**[본 논문의 개선: MST]**</span>    
* 본 논문에서는 PLMs의 **measuring skill**를 조사한다.     
즉, measurement **시스템을 이해**하고 measurement에 대한 **수치 추론을 수행하는 능력**을 조사한다.     
* <span style="background-color:#fff5b1">세 가지 측정 기술 테스트(measuring skill tests, MSTs)를 설계</span> 한다.     
➡ 얼마나 많은 measuring 기술을 습득할 수 있는지 연구한다.       
   * **UNIT CONVERSION(단위 변환)**: 측정 시스템에 대한 이해 필요        
   * **REFERENCE RANGE DETECTION(기준 범위 검출)**: 생체 의학 실체의 정상 범위 이해 필요       
   * **MEASUREMENT COMPARISON(측정 비교)**: 측정 시스템과 NRoT에 대한 지식을 결합할 수 있는 능력 필요 
* Table 1 은 각 measuring skill tests의 예를 보여줌(MST 결과)      
![image](https://user-images.githubusercontent.com/76824611/223579239-cffa8d7f-e759-466e-ac85-7e19d00a71f1.png)


<span style="background-color:#F5F5F5">**[실험 및 결과 요약]**</span>    
* 한계 발견: 모델들이 measurements 목록에서 **가장 큰(또는 가장 작은) 값을 찾고**, **측정값을 다른 단위로 변환**하는 데 어려움을 겪음    
* 장점: 그 외의 다른 테스트에서는 잘 작동함       
* 다른 PLM에 비해 BioBERT(Lee et al., 2020)는 UNIT CONVERSION 및 REFERENCE RANGE Detection에서 우수한 성능을 보임     
➡ **measurements가 풍부한 텍스트를 사용한 pre-trian**이 모델의 measurements 시스템 **이해 능력에 도움**이 된다는 것을 의미한다.       


마지막으로,    
본 논문은 **맥락에서 숫자, 단위 및 다른 단어를 구별하는 기술의 부족**이 **일부 MST에서 모델을 실패**하게 한다고 추측한다.     
➡ 이를 완화하기 위해 input 텍스트에서 숫자의 위치와 척도에 대한 정보를 모델에 제공하는 <span style="background-color:#fff5b1">**scale  embedding**</span>을 도입한다.    
우리는 scale  embedding이 모든 PLM의 MST 성능을 크게 향상시킨다는 것을 보여준다.     



---
----

# 2 Measuring Skill Test
In this section, we describe three MSTs to carefully
study the ability of PLMs to understand the system
of measurement and perform numerical reasoning
over the measurements.

이 섹션에서는 **PLM이 measurements 시스템을 이해**하고 **measurements에 대해 수치 추론을 수행하는 능력을 신중하게 연구하기 위한 <span style="background-color:#fff5b1">세 가지 MST</span>**를 설명한다.    
(앞서 잠깐 설명했다)      
* **UNIT CONVERSION(단위 변환)**: 측정 시스템에 대한 이해 필요        
* **REFERENCE RANGE DETECTION(기준 범위 검출)**: 생체 의학 실체의 정상 범위 이해 필요       
* **MEASUREMENT COMPARISON(측정 비교)**: 측정 시스템과 NRoT에 대한 지식을 결합할 수 있는 능력 필요


----




## 2.1 Unit Conversion: 단위 변환
이 task를 수행하려면 model에서 <span style="background-color:#fff5b1">**두 measurements**가 **동일한 양**을 나타내는지</span> 여부를 결정해야 한다.        

예를 들어 아래와 같은 문장이 있다고 해보자.            
<center>__"3.5g and 3500mg are [MASK] value"__</center>          
* **모델이 단위 변환을 올바르게 이해하는 경우**: [MASK]를 _same_으로 추론한다.     
* **모델이 단위 변환을 올바르게 이해하는 못하는 경우**: [MASK]를 __same__으로 추론하지 못한다.     

일반적으로, **단위(예: liter, meter)와 그 접두사(예: kilo, milli)를 결합**하여 [&&10^{-3}, 10^3&&) 범위 내에서 measurement의 수치를 나타내는 것이 관례이다.        
따라서 단위가 동일하더라도 single passage에 다양한 단위 접두사가 나타날 수 있다.      
이를 처리하기 위해서는 **measurement의 대한 복잡한 추론을 위해 UNIT CONVERSION이 필수적**이다.     

UNIT CONVERSION에 성공하기 위해서는 **measurement 시스템에 대한 이해를 바탕**으로 모델이 **단위(unit)와 수치(numerical value)를 공동으로 처리**할 것으로 기대한다.     


---

## 2.2 Reference Range Detection: 기준 범위 감지
Given a biomedical entity and measurement, this
task requires a model to predict whether the measurement falls within the reference range. Knowledge of the biomedical entity plays a crucial role
in understanding measurements, since the unit is
determined by the biomedical entity. For example,
we measure the hemoglobin level in g/dL. In addition to understanding UoMs, PLMs must rely on
domain knowledge embedded in their parameters
to solve this task, as context alone does not provide
sufficient clues as to what the reference range is for
the given biomedical entity


생물 의학 entity와 measurement가 주어지면, 이 작업은 측정이 기준 범위 내에 있는지 예측하는 모델을 필요로 한다. 단위는 생물의학적 실체에 의해 결정되기 때문에 생물의학적 실체에 대한 지식은 측정을 이해하는 데 중요한 역할을 한다. 예를 들어, 우리는 헤모글로빈 수준을 g/dL로 측정한다. PLM은 UoM을 이해하는 것 외에도 주어진 생물 의학 엔티티에 대한 참조 범위가 무엇인지에 대한 충분한 단서를 제공하지 않기 때문에 이 작업을 해결하기 위해 매개 변수에 내장된 도메인 지식에 의존해야 한다

## 2.3 Measurement Comparison
Given two measurements (or a series of n measurements), the task is to predict the correct relationship between them. We created the synthetic dataset following other well-known NRoT
tasks. Here, we consider three numerical reasoning tasks: COMPARISON (Talmor et al., 2020),
ARGMIN/MAX (Wallace et al., 2019), and SORTING (Pal and Baral, 2021), all requiring the model
to compare numbers. Note that each measurement
in this task can have a different unit prefix. For
example, the sample "1.59mg is [MASK] than 3.8g"
containing two different units "mg" and "g" appears
in the COMPARISON dataset. This task assesses the
model’s ability to combine an understanding of
measurements and numerical reasoning skills.

2.3 측정 비교
두 개의 측정값(또는 일련의 n개의 측정값)이 주어지면 이들 사이의 올바른 관계를 예측하는 것이 과제입니다. 우리는 잘 알려진 다른 NRoT 작업을 따라 합성 데이터 세트를 만들었다. 여기서 우리는 세 가지 수치 추론 작업, 즉 비교(Talmor et al., 2020), ARGMIN/MAX(Wallace et al., 2019) 및 정렬(Pal and Baral, 2021)을 고려하며, 모두 모델이 숫자를 비교해야 한다. 이 작업의 각 측정에는 서로 다른 단위 접두사가 사용될 수 있습니다. 예를 들어, 두 개의 서로 다른 단위 "mg"과 "g"가 포함된 샘플 "1.59mg은 3.8g보다 [MASK]입니다"가 비교 데이터 세트에 나타납니다. 이 작업은 측정에 대한 이해와 수치 추론 기술을 결합하는 모델의 능력을 평가한다.





**[INTRO]**      
NIPS에서 Google이 소개했던 Transformer는 NLP 학계에서 정말 큰 주목을 받음  
CNN 과 RNN 이 주를 이뤘던 연구들에서 벗어나 아예 새로운 모델을 제안했기 때문    

**[핵심]**     

**[읽기 위해 필요한 지식]**    
* [attention](https://yerimoh.github.io/DL19/)       
* [transformer](https://yerimoh.github.io/Lan/)    


**[원 논문]**    
[Self-Attention with Relative Position Representations](https://arxiv.org/pdf/1803.02155.pdf)  


----
