---
title: "[25] CS231N: Lecture 5 Convolutional Neural Networks"
date:   2020-02-8
excerpt: "Lecture 5 | Convolutional Neural Networks 요약"  
category: [Deep Learning]
layout: post
tag:
- Deep Learning
order: 0

comments: true
---



# 목차


------

👀 코드 보기 , 🤷‍♀️     
이 두개의 아이콘을 누르시면 코드, 개념 부가 설명을 보실 수 있습니다:)

------


[CS231N: Lecture 4](https://www.youtube.com/watch?v=bNb2fEVKeEo&list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk&index=5)

------


오늘 배울것
CNN: NN과 같은 부류이긴 하지만 이번에는 Convolutional Layer에 대해 배울 것     
이 레이어는 기본적으로 "공간적 구조"를 유지       

CNN의 역사도


---
----

# **History of CNN**
전체 개요를 정리해보자면 아래와 같다.     



## 신경망의 

**[1957년: Mark I Perceptron machine 개발]**        
* **개발자**: Frank Rosenblatt            
* **의의**     
     * 이 기계는 ["perceptron"](https://yerimoh.github.io/DL1/)을 구현한 최초의 기계    
     * "Perceptron"은 우리가 배운 Wx + b 와 유사한 함수를 사용          
         * 다른점: 여기에서는 출력 값이 1 또는 0     
         * 같은점: 가중치 W를 Update 하는 Update Rule이 존재합니다.    
         * 이 Update Rule은 Backprop과 유사     
         * 하지만 당시에는 backprob이라는 개념이 없어서, 단지 W를 이리저리 조절하면서 맞추는 식이었음     


**[1960년: Adaline and Madaline을 개발]**      
* **개발자**: Widrow와 Hoff     
* **의의**    
    * 최초의 Multilayer Perceptron Network       
    * 이 시점에서야 비로소 Neural network와 비슷한 모양을 하기 시작하긴 했지만 아직 Backprob같은 학습 알고리즘은 없음        
    
    
**[1986: 최초의 Backporp]**           
* **개발자**: Rumelhart       
* **의의**    
   * 우리에게 익숙한 Chain rule과 Update rule        
   * 이때 최초로 network를 학습시키는 것에 관한 개념이 정립되기 시작함         
   * 하지만 그 이후로 NN을 더 크게 만들지는 못함.        


**[암흑기]**      
* 그리고 한동안은 새로운 이론이 나오지 못했고 널리 쓰이지도 못함      
* 2000년대가 되서야 다시 활기를 찾기 시작함       




**[2006: DNN의 학습가능성]**      
* **개발자**: Geoff Hinton 과 Ruslan Salakhutdinov      
* **의의**      
    * DNN의 학습가능성을 선보임      
    * 그것이 실제로 아주 효과적이라는 것을 보여줌      
    * 하지만 그 때 까지도 아직 모던한 NN는 아니었음     
    * backprop이 가능하려면 아주 세심한 초기화가 필요하기 때문          
    * 그래서 여기에서는 **전처리 과정이 필요**했고, 초기화를 위해 RBM을 이용해서 각 히든레이어 가중치를 학습시켜야 했음        
    * 이렇게 초기화된 히든 레이어를 이용해서 전체 신경망을 backprop하거나 fine tune하는 것이었음         



**[2012: NN의 광풍]**       
* **개발자**: Hintin lab            
* **의의**      
   * NN이 음성 인식에서 아주 좋은 성능을 보임     
   * acoustic modeling과 speech recognition에 관한 것



**[2012: AlexNet]**       
* **개발자**: Hintin lab            
* **의의**      
   * 영상인식에 관한 landmark paper      
   * 이 논문에서는 ImageNet Classification에서 최초로 NN을 사용했고, 결과는 정말 놀라웠음     
   * AlexNet은 ImageNet benchmark의 Error를 극적으로 감소시킴      
   * 그 이후로  ConNets은 아주 널리 쓰이고 있음             



## CNN의 역사    

다시 돌아가서 구체적으로 "CNN이 어떻게 유명해졌는지" 에 대해 한 번 알아보도록 하겠다.


**[1950:  일차시각피질의 뉴런에 관한 연구]**       
* **개발자**: Hubel과 Wiesel                 
* **의의**      
    * 고양이의 뇌에 전극을 꽂아 고양이에게 다양한 자극을 주며 실험       
    * 이 실험에서 뉴런이 oriented edges와 shapes같은 것에 반응한다는 것을 알아냄         
* **결론 **          
    * 피질 내부에 지형적인 매핑(topographical mapping)이 있다    
        * 피질 내 서로 인접해 있는 세포들은 visual field내에 어떤 지역성을 띄고 있음.       
        * 밑의 그림은 보면 해당하는 spatial mapping을 볼 수 있음     
        * 중심에서 더 벗어난 파란색 지역도 볼 수 있습니다.
    * 뉴런들이 계층구조를 지닌다는 것도 발견      
        * 다양한 종류의 시각자극을 관찰하면서 시각 신호가 가장 먼저 도달하는 곳이 바로 Retinal ganglion 이라는 것을 발견함        
        * Retinal ganglion cell은 원형으로 생긴 지역임     
        * 가장 상위에는 Simple cells이 있는데, 이 세포들은 다양한 edges의 방향과 빛의 방향에 반응함         
        * 그리고 더 나아가, 그런 Simple Cells 이 Complex cells과 연결되어 있다는 것을 발견함.       
        * Complex cells는 빛의 방향 뿐만 아니라 움직임에서 반응함       
        * 복잡도가 증가함게 따라, 가령  hypercomplex cells은 끝 점(end point) 과 같은것에 반응하게 되는 것입니다.
     * 이런 결과로부터  "corner" 나 "blob"에 대한 아이디어를 얻기 시작한 것임        



**[1980: neocognitron]**       
* **개발자**: Hubel과 Wiesel                 
* **의의**      
     * simple/complex cells의 아이디어를 사용한 최초의 NN     
     * Fukishima는 simple/complex cells을 교차시킴 (SCSCSC..)     
     * Simple cells은 학습가능한 parameters를 가지고 있고 Complex cells은 pooling과 같은 것으로 구현했는데
작은 변화에 Simple cells보다 좀 더 강인함.       





**[1998: Backprob과 gradient-based learning을 적용]**       
* **개발자**: Yann LeCun                 
* **의의**    
      * 1998년 Yann LeCun이 최초로 NN을 학습시키기 위해 Backprob과 gradient-based learning을 적용함.     
      * 실제로 그 방법은 문서인식에 아주 잘 동작함     
      * 그리고 우편번호의 숫자를 인식하는데도 아주 잘 동작함      
      * 그리고 실제 우편 서비스에서 우편번호 인식에 널리 쓰임         
      * 하지만 아직 이 Network를 더 크게만들 수는 없었습니다.     
그리고 숫자 라는 데이터는 단순했습니다.

79
00:08:56,350 --> 00:09:08,900
2012년 Alex Krizhevsky가 CNN의 현대화 바람을 이르켰습니다.
이 Network는 AlexNet이라고도 불립니다.

80
00:09:08,900 --> 00:09:21,751
Yann LeCun의 CNN과 크게 달라보이진 않습니다.
다만 더 크고 깊어진 것입니다.

81
00:09:21,751 --> 00:09:37,724
가장 중요한 점은 지금은 ImageNet dataset과 같이 대규모의
데이터를 활용할 수 있다는 것입니다. 또한 GPU의 힘도 있었습니다.

82
00:09:37,724 --> 00:09:41,033
나중에 더 자세히 다루도록 하죠

83
00:09:41,033 --> 00:09:45,434
다시 오늘날로 돌아와보면
ConvNets은 모든 곳에 쓰입니다.

84
00:09:45,434 --> 00:09:55,188
AlexNet의 ImageNet 데이터 분류 결과를 살펴보자면
이미지 검색에 정말 좋은 성능을 보이고 있습니다.

85
00:09:55,188 --> 00:10:04,134
가령 꽃을 검색하는 것을 보면 학습된 특징이 유사한 것을
매칭시키는데 아주 강력하다는 것을 볼 수 있습니다.

86
00:10:04,134 --> 00:10:07,049
Detection에서도 ConvNet을 사용합니다.

87
00:10:07,049 --> 00:10:17,705
영상 내에 객체가 어디에 있는지를 아주 잘 찾아냅니다.
버스나 보트 등을 찾아내고 네모박스를 정확하게 그립니다.

88
00:10:17,705 --> 00:10:26,112
그리고 그보다 더 어려운 일들도 할 수 있는데 segmentation
은 단지 네모박스만 치는 것이 아니라

89
00:10:26,112 --> 00:10:32,125
나무나 사람 등을 구별하는데
픽셀 하나 하나에 모두 레이블링하는 것입니다.

90
00:10:34,126 --> 00:10:38,864
이런 알고리즘은 자율주행 자동차에 사용할 수 있습니다.

91
00:10:38,864 --> 00:10:48,812
대부분의 작업은 GPU가 수행할 수 있으며, 병렬처리를 통해
ConvNet을 아주 효과적으로 훈련하고 실행시킬 수 있습니다.

92
00:10:48,812 --> 00:10:59,207
자율 주행에 들어가는 임베디드 시스템에서도 동작할 뿐만 아니라
최신의 GPU에서도 가능합니다.

93
00:10:59,207 --> 00:11:03,399
이는 모두 Convnet 을 활용할 수 있는 다양한
애플리케이션의 예라고 할 수 있습니다.

94
00:11:03,399 --> 00:11:10,394
얼굴인식의 예를 보면 얼굴 이미지를 입력으로 받아서
이 사람이 누구인지에 대한 확률을 추정할 수 있습니다.

95
00:11:12,626 --> 00:11:25,951
ConvNets을 비디오에도 활용할 수 있는데, 단일 이미지의
정보 뿐만 아니라 시간적 정보도 같이 활용하는 방법입니다.

96
00:11:25,951 --> 00:11:32,770
또한 pose recognition도 가능합니다. 어깨나 팔꿈치와 같은
다양한 관절들을 인식해 낼 수 있습니다.

97
00:11:32,770 --> 00:11:42,234
여기 우리 조교 Lane의 이미지가 있습니다.
다양하고 비 정형적인 사람의 포즈를 아무 잘 잡아냅니다.

98
00:11:42,234 --> 00:11:48,465
오늘날 ConvNets을 이용한 pose recognotion은
아주 잘 동작합니다.

99
00:11:48,465 --> 00:11:51,741
Convnet을 가지고 게임도 할 수 있습니다.

100
00:11:51,741 --> 00:11:58,595
더 깊은 강화학습을 통해서 Atari 게임을 하거나
바둑을 두는 모습을 보신 적이 있을 것입니다.

101
00:11:58,595 --> 00:12:02,981
ConvNets은 이 모든 일들에서
아주 중요한 역할을 합니다.

102
00:12:02,981 --> 00:12:10,150
또다른 예로는 의학 영상을 가지고 해석을 하거나
진단을 하는데도 이용할 수 있습니다.

103
00:12:10,150 --> 00:12:14,317
또한 은하를 분류하거나 표지판을 인식하는데도 쓰입니다.

104
00:12:18,059 --> 00:12:22,342
최근의 Kaggle Chanllange에서는
고래를 분류하는 것도 있었습니다.

105
00:12:22,342 --> 00:12:33,249
또한 항공지도를 가지고 어디가 길이고 어디가 건물인지를
인식하기도 합니다.

106
00:12:35,089 --> 00:12:41,587
Classification이나 Detection에서 좀 더 나아가는 방법도
있습니다. Image Captioning같은 방법이죠

107
00:12:41,587 --> 00:12:48,644
이미지가 주어지면 이미지에 대한 설명을
문장으로 만들어 내는 것입니다.

108
00:12:48,644 --> 00:12:52,819
아마 나중에 배우게 될 것입니다.

109
00:12:52,819 --> 00:13:01,251
또한 Neural Network를 이용해 간지나는 예술작품도
만들어 낼 수 있습니다.

110
00:13:01,251 --> 00:13:12,412
왼쪽에 Deep Dream 알고리즘의 결과를 볼 수 있는데
다양한 어떤 객체가 보이고 약빨고 만든듯한 느낌을 줍니다

111
00:13:12,412 --> 00:13:23,808
또한 Style Transfer라는 방법은 원본 이미지를 가지고
특정 화풍으로 다시 그려주는 알고리즘도 있습니다.

112
00:13:23,808 --> 00:13:33,370
가령 맨 오른쪽은 반 고흐의 별의 빛나는 밤의 화풍으로 바뀐 것입니다.

113
00:13:33,370 --> 00:13:38,239
Jstin이 이와 관련된 연구를 많이 합니다.
만약 이에 관심이 있다면

114
00:13:38,239 --> 00:13:46,244
여기 예제 모두 Justin이 만든 코드이기 때문에
가서 물어보면 될 것입니다.

115
00:13:46,244 --> 00:13:52,727
지금까지는 오늘날 ConvNets이 어떻게 사용되는지
간략하게 한 번 알아보았습니다.

116
00:13:52,727 --> 00:13:55,289
물론 이보다 더 많은 일들을 할 수 있을 것입니다.

117
00:13:55,289 --> 00:14:06,465
때문에 여러분도 무수히 많은 상상을 할 수 있을 것이고
저는 개인적으로 여러분들의 프로젝트가 몹시 기대됩니다.

118
00:14:06,465 --> 00:14:10,307
오늘은 Convolutional Neural Network가 어떻게
작동하는지를 살펴 볼 것입니다.

119
00:14:10,307 --> 00:14:22,835
이번에 CNN의 첫 시간이니, CNN이 어떻게 동작하는지에 대해서만 간단하게
이야기해 볼 것입니다.

120
00:14:25,453 --> 00:14:31,444
지난 강의에서 Fully Connected Layer에 대한
아이디어를 소개해 드렸습니다

121
00:14:32,878 --> 00:14:36,257
그리고 완전히 연결된 레이어의 경우

122
00:14:36,257 --> 00:14:48,443
FC Layer에서 하는 일은 어떤 벡터를 가지고 연산을 하는 것이었습니다.
우선 입력으로 32 x 32 x 3 의 이미지가 있었습니다.

123
00:14:48,443 --> 00:14:56,787
그리고 이 이미지를 길게 펴서
3072차원의 벡터로 만들었습니다.

124
00:14:56,787 --> 00:15:01,741
그리고 가중치 W가 있어서 벡터와 곱했습니다. (Wx)

125
00:15:01,741 --> 00:15:05,908
이 예시에서는 W가 10x3072 행렬입니다.

126
00:15:07,264 --> 00:15:13,943
그리고 activation 을 얻습니다.
이 Layer의 출력입니다.

127
00:15:13,943 --> 00:15:20,389
10개의 행으로 되어있는데 3072 차원의 입력와
내적을 한 결과라고 할 수 있습니다.

128
00:15:22,207 --> 00:15:27,892
그러면 어떤 숫자 하나를 얻게 되는데
이는 그 Neuron의 한 값이라고 할 수 있습니다.

129
00:15:27,892 --> 00:15:32,270
이 예시의 경우 10개의 출력이 있게 됩니다.

130
00:15:35,417 --> 00:15:44,165
Convolution Layer와 기존의 FC레이어의 주된 차이점이 있다면
Convolution Layer는 기존의 구조를 보존시킨다는 것입니다.

131
00:15:44,165 --> 00:15:57,750
기존의 FC Layer가 입력 이미지를 길게 쭉 폈다면
이제는 기존의 이미지 구조를 그대로 유지하게 됩니다.

132
00:15:57,750 --> 00:16:01,910
그리고 이 작은 필터가 우리가 가진 가중치가 되는 것이고

133
00:16:01,910 --> 00:16:13,153
이 예시에서는 5x5x3 필터가, 이 필터를 가지고 이미지를
슬라이딩하면서 공간적으로 내적을 수행하게 됩니다.

134
00:16:13,153 --> 00:16:17,320
이제 이것을 어떻게 수행하는지 자세하게 알아보겠습니다.

135
00:16:18,668 --> 00:16:23,957
우선 필터는 입력의 깊이(Depth)만큼 확장됩니다.

136
00:16:23,957 --> 00:16:33,425
여기에서 하나의 필터는 아주 작은 부분만 취할 수 있습니다.
전체 32x32 이미지의 5x5 만 취하는 것입니다.

137
00:16:33,425 --> 00:16:42,499
하지만 깊이를 보면 전체 깊이를 전부 취합니다.
여기에서는 5 x 5 x 3 가 되는 것입니다.

138
00:16:42,499 --> 00:16:52,901
이제 이 필터를 가지고 전체 이미지에 내적을 시킬 적입니다.

139
00:16:52,901 --> 00:16:58,636
이 필터를 이미지의 어떤 공간에 겹쳐놓고 내적을 수행합니다.

140
00:16:58,636 --> 00:17:09,732
그리고 필터의 각 w와, 이에 해당하는 이미지의 픽셀을 곱해줍니다.

141
00:17:09,733 --> 00:17:18,755
여기에 필터가 5 x 5 x 3 라는건 그만큼 곱셈연산을 한다는 것입니다.
물론 bias term도 하나 들어가겠지만요

142
00:17:18,755 --> 00:17:26,491
여기에서는 기본적으로 W^tx + b를 수행하는 것입니다.

143
00:17:27,722 --> 00:17:31,771
이해했나요?
질문있나요

144
00:17:31,771 --> 00:17:34,521
[학생이 질문]

145
00:17:35,656 --> 00:17:40,722
그럼 여기에서 내적을 할때는
5x5x3짜리 긴 벡터를 사용하는 것입니까? 입니다.

146
00:17:40,722 --> 00:17:42,907
맞습니다. 엄밀히 말하면 그렇습니다.

147
00:17:42,907 --> 00:17:57,891
각 원소끼리 Convolution 을 하는 거나 그것을 쭉 펴서
내적을 하는거나 똑같은 일을 하는 것입니다.

148
00:17:57,891 --> 00:18:01,111
다른 질문 있으십니까?

149
00:18:01,111 --> 00:18:03,867
[학생이 질문]

150
00:18:03,867 --> 00:18:07,997
질문은 바로 왜 W를 Transpose하는지에 대한
직관이 있습니까? 하는 것입니다.

151
00:18:07,997 --> 00:18:15,978
그런것은 따로 없습니다. 내적을 수학적으로 표현하기 위해서
표현만 그렇게 한 것일 뿐입니다.

152
00:18:15,978 --> 00:18:29,593
이는 W를 어떻게 표현하느냐의 차이일 뿐입니다.
단지 행벡터를 만들어 주려고 Transpose를 하는 것입니다.

153
00:18:29,593 --> 00:18:31,989
하지만 여기에 어떤 직관은 없습니다.

154
00:18:31,989 --> 00:18:42,862
W를 펴서 D차원 벡터로 만들어보면 내적을 하려면
다시 내적을 1 x N 행벡터로 만들어 줘야 겠죠

155
00:18:42,862 --> 00:18:45,612
[학생이 질문]

156
00:18:48,263 --> 00:18:49,829
그래, 문제는

157
00:18:49,829 --> 00:18:53,996
그럼 여기에서 W가 의미하는것은 5x5x3 가 아니라
1 x 75 인 것입니까? 입니다.

158
00:18:55,180 --> 00:19:02,550
네 맞습니다. Wx에 대해 생각해보면 우선 내적을 수행하기 앞서
W를 길게 펼 것입니다.

159
00:19:02,550 --> 00:19:09,629
다시말해 5x5x3의 입력값 x더 길게 펴진 벡터의 형태가 되겠죠

160
00:19:10,913 --> 00:19:16,706
이전 질문과도 유사한데요

161
00:19:16,706 --> 00:19:27,527
필터를 이미지에 겹쳐놓고 해당하는 값들을 서로 곱합니다
우리가 보기 좋으라고 저렇게 표현을 해 놨지만

162
00:19:27,527 --> 00:19:35,061
실제로는 모두 펴서 벡터간 내적을 구하는 것입니다.

163
00:19:35,061 --> 00:19:36,311
질문있나요?

164
00:19:37,232 --> 00:19:40,740
[학생이 질문]

165
00:19:40,740 --> 00:19:46,760
질문은 바로 필터를 이미지에 어떻게 슬라이딩 하는지 입니다.
그건 앞으로 배울 내용입니다.

166
00:19:46,760 --> 00:19:49,510
[학생이 질문]

167
00:19:52,071 --> 00:20:00,178
질문은 엄밀하게 Convolution을 수행하려면
커널에 180도 회전되어야 하지 않느냐는 것입니다.

168
00:20:00,178 --> 00:20:09,451
Convolution의 수식을 후에 볼 것이지만 여기에서의 Conv는
좀 더 느슨한 정의라고 할 수 있습니다.

169
00:20:09,451 --> 00:20:18,738
신호처리 분야에서의 convolution은 실제로
필터를 뒤집은 다음에 연산을 수행합니다.

170
00:20:18,738 --> 00:20:27,983
하지만 CNN의 Convolution은 의미적인 요소만 가져온
것이기 때문에 걱정하지 않으셔도 됩니다.

171
00:20:27,983 --> 00:20:37,246
이떤 분이 질문했던, 어떻게 슬라이딩을 하는지에 대해 알아보겠습니다.

172
00:20:37,246 --> 00:20:49,975
Convolution은 이미지의 좌상단부터 시작하게 됩니다.
그리고 필터의 중앙을 값들을 모으게 됩니다.

173
00:20:49,975 --> 00:20:57,511
필터의 모든 요소를 가지고 내적을 수행하게 되면
하나의 값을 얻게됩니다.

174
00:20:57,511 --> 00:21:00,927
그리고 슬라이딩하게 됩니다.

175
00:21:00,927 --> 00:21:09,442
Conv연산을 수행하는 값들을 다시 Output activation map의
해당하는 위치에 저장하게 됩니다.

176
00:21:10,352 --> 00:21:15,532
여기 보면 입력 이미지와 출력 activation map의 차원이
다르다는 것을 알 수 있습니다.

177
00:21:15,532 --> 00:21:20,126
입력은 32 x 32 이고 출력은 28 x  28 이죠

178
00:21:20,126 --> 00:21:26,364
그래서 우리는 나중에 수학에 대해 설명 할 것입니다. 이 방법이
차원 적으로 어떻게 작동하는지 정확히 알 수 있습니다.

179
00:21:26,364 --> 00:21:31,393
기본적으로는 어떻게 슬라이딩을 할 것인지를
선택할 수 있습니다.

180
00:21:31,393 --> 00:21:41,326
슬라이딩여부와 관계없이 입력 값을 두 개씩 뽑아서
연산을 수행할 수도 있을 것입니다.

181
00:21:41,326 --> 00:21:48,990
출력 행렬의 크기는 슬라이드를 어떻게 하느냐에 따라 다르게됩니다.
하지만 기본적으로는 하나씩 연산을 수행합니다.

182
00:21:50,180 --> 00:21:58,141
하나의 필터를 가지고 전체 이미지에 Convolution
연산을 수행합니다.

183
00:21:58,141 --> 00:22:04,731
그러면 activation map이라는 출력값을 얻게 되는 것입니다.

184
00:22:04,731 --> 00:22:16,250
보통 Convolution Layer에서는 여러개의 필터를 사용합니다.
왜냐하면 필터마다 다른 특징을 추출하고 싶기 때문입니다.

185
00:22:16,250 --> 00:22:26,359
따라서 우리는 보통 여러개의 필터를 사용합니다. 가령 여기에
두 번째 필터가 있습니다. 초록색의 5 x 5 x 3 필터입니다.

186
00:22:26,359 --> 00:22:37,425
이 녹색 필터를 연산하고 나면, 앞서 계산했던 activate map과
같은 크기의 새로운 map이 만들어집니다.

187
00:22:40,081 --> 00:22:43,553
우리는 한 Layer에서 원하는 만큼 여러개의 필터를
사용할 수 있습니다.

188
00:22:43,553 --> 00:22:51,698
가령 5 x 5 필터가 6개가 있다면
총 6개의 activation map을 얻게 될 것입니다.

189
00:22:51,698 --> 00:22:58,368
출력 map의 크기는 28 x 28이 되겠죠.

190
00:23:01,607 --> 00:23:11,152
이 CNN을 어떻게 활용할 지를 조금 말씀드려보면
이런식으로  Cov Layer들의 연속된 형태가 될 것입니다.

191
00:23:11,152 --> 00:23:16,676
그리고 각각을 쌓아 올리게 되면 보시는 것과 같이
간단한 Linear Layer로 된 Neural Network가 됩니다.

192
00:23:16,676 --> 00:23:23,057
이제는 그 사이 사이에 activation function을 넣을 것입니다.
가령 ReLU 같은 것들을 사용할 수 있겠죠.

193
00:23:24,503 --> 00:23:31,257
그렇게 되면 Conv-ReLU 가 반복되겠죠
그리고 가끔은 pooling layer도 들어갑니다.

194
00:23:31,257 --> 00:23:40,465
그리고 각 Layer의 출력은 다음 Layer의 입력이 됩니다.

195
00:23:43,638 --> 00:23:52,957
그리고 말씀드렸듯 각 Layer는 여러개의 필터를 가지고 있습니다.
그리고 각 필터마다 각각의 출력 map을 만듭니다.

196
00:23:52,957 --> 00:24:01,175
그러므로 여러개의 Layer들을 쌓고나서 보면 결국
각 필터들이 계층적으로 학습을 하는것을 보게됩니다.

197
00:24:01,175 --> 00:24:09,257
앞쪽에 있는 필터들은 low-level feature를 학습하게 됩니다.
Edge와 같은것들이 보입니다.

198
00:24:09,257 --> 00:24:19,113
Mid-level을 보면 좀더 복잡한 특징을 가지게 됩니다.
코너나 blobs 등과 같이 보입니다.

199
00:24:19,113 --> 00:24:25,852
그리고 high-level features를 보면 좀 더 객체와 닮은 것들이
출력으로 나오는 것을 볼 수 있습니다.

200
00:24:25,852 --> 00:24:35,561
나중 수업에서 객 특징을 어떻게 시각화하는지, 그리고 특징들이
어떻게 학습되는지를 살펴보겠습니다.

201
00:24:35,561 --> 00:24:46,967
여기에서 이해하고 넘어가야 하는 것은 특징이 어떻게 생겼고,
Layer의 계층에 따라 단순/복잡한 특징을이 존재한다는 것을 아는 것입니다.

202
00:24:48,305 --> 00:24:49,138
[학생이 질문]

203
00:24:49,138 --> 00:25:03,113
질문은 바로 필터의 Depth를 늘리는데 어떤 직관을 가져야 하는지 입니다.

204
00:25:03,113 --> 00:25:08,814
이 예시에서 처음에는 3개의 필터가 그 다음에는
6개의 필터가 있었습니다.

205
00:25:08,814 --> 00:25:17,255
이는 어떻게 모델을 디자인해야 되는지의 문제인데
실제로는 어떤것이 더 좋은지를 찾아내야 합니다.

206
00:25:17,255 --> 00:25:28,344
나중 수업에서 다양한 CNN 아키텍쳐를 살펴보면서 왜 어떤
모델이 더 좋은지를 살펴볼 것입니다.

207
00:25:28,344 --> 00:25:33,238
하지만 기본적으로 여러분은 아주 다양하 방법으로
CNN 모델을 디자인할 수 있습니다.

208
00:25:33,238 --> 00:25:39,611
필터 사이즈라던가 Stride, 그리고 얼마나 많은 필터를
사용할지 등을 말이죠. 다음에 다시 이야기하겠습니다.

209
00:25:39,611 --> 00:25:41,246
질문있나요?

210
00:25:41,246 --> 00:25:43,996
[학생이 질문]

211
00:25:50,300 --> 00:26:00,177
질문은 바로 우리가 전체 이미지를 슬라이딩 하면서 필터링을 하는데
이미지의 가장자리는 필터가 덜 적용되지 않냐는 것입니다.

212
00:26:00,177 --> 00:26:07,900
아주 좋은 질문 입니다. 그리고 어떻게 그것을 다시 보완해야
하는지가 앞으로 할 내용입니다. (ex zero-padding)

213
00:26:12,009 --> 00:26:26,228
지금까지는 Conv Layer를 계층적으로 쌓아서 단순한 특징을을 뽑고
그것을 또 조합해서 더 복잡한 특징으로 활용했습니다.

214
00:26:26,228 --> 00:26:32,549
그리고 이는 Hubel과 Wiesel의 이론과도 잘 맞습니다.

215
00:26:32,549 --> 00:26:39,532
네트워크에 앞쪽에서는 단순한 것들일 처리하고
뒤로 갈수록 점점 더 복잡해 지는 식이죠

216
00:26:39,532 --> 00:26:55,041
우리는 그것을 강제로 학습시킨 것이 아니라 계층적 구조를 설계하고
역전파로 학습시킨 것 뿐이지만 필터는 이렇게 학습되는 것입니다.

217
00:26:55,041 --> 00:26:57,791
[학생의 질문]

218
00:27:05,555 --> 00:27:10,979
질문은 바로 여기에서 시각화 한 것이
무엇인지 입니다.

219
00:27:10,979 --> 00:27:20,975
가령 Cov1을 보면 각 그리드의 요소가
하나의 뉴런(필터) 라고 보시면 됩니다.

220
00:27:20,975 --> 00:27:29,956
그리고 시각화 시킨 이 뉴런의 모습은 바로 이미지가 어떻게 생겨야 해당
뉴런의 활성을 최대화시킬 수 있는지는 나타내는 것입니다.

221
00:27:29,956 --> 00:27:36,594
이미지가 뉴런과 비슷하게 생겼으면 출력 값을 큰 값을 가지게 됩니다.

222
00:27:36,594 --> 00:27:56,280
시각화는 Backpopagation을 통해 해볼 수 있는데.
이를 시각화하는 방법은 나중에 더 자세하게 배울 것입니다.

223
00:27:56,280 --> 00:28:06,775
그러나 기본적으로 여기 그리드의 각 요소는 각 뉴런의 활성을
최대화시키는 입력의 모양을 나타내게 됩니다.

224
00:28:06,775 --> 00:28:10,608
그런 의미에서 뉴런이 어떻게 생겼는지를 의미합니다.

225
00:28:13,537 --> 00:28:19,835
Activation map의 예제를 한 번 보겠습니다.
각 필터가 만든 출력값이죠

226
00:28:19,835 --> 00:28:30,407
위에 5 x 5 필터들을 시각화 한 것을 볼 수 있습니다.
실제 ConvNet을 학습시킨 결과입니다.

227
00:28:30,407 --> 00:28:38,511
5 x 5 필터가 어떻게 생겼는지를 보여 줍니다. 그리고
이미지와 필터간 Conv의 activation 결과를 볼 수 있습니다.

228
00:28:38,511 --> 00:28:44,346
이 경우 입력 이미지는 자동차의 한 부분인것 같습니다.

229
00:28:44,346 --> 00:28:51,330
우선 여기 빨간색 네모박스를 친 필터를 한 번 봅시다.

230
00:28:51,330 --> 00:28:56,432
이 필터는 edge를 찾고 있는 것입니다.

231
00:28:56,432 --> 00:29:06,601
그리고 이 필터를 슬라이딩 시키면 이 필터와 비슷한 값들은 값이
더 커지게 됩니다.

232
00:29:06,601 --> 00:29:12,358
따라서 각 actavation은 이미지가 필터를 통과한
결과가 되며

233
00:29:12,358 --> 00:29:20,747
이미지 중 어느 위치에서 이 필터가 크게 반응하지는지를
보여줍니다.

234
00:29:20,747 --> 00:29:29,153
우리가 이걸 Convolution이러고 칭하는 이유는 바로 위에 언급
한 것이 바로 두 신호 사이에 cov를 하는것과 유사하기 때문입니다.

235
00:29:29,153 --> 00:29:38,927
여기 Conv 식이 있습니다. 예전에 신호처리에서 Conv를 본 적이
있는 학생이라면 이 식이 correlation 같아 보일 것입니다.

236
00:29:38,927 --> 00:29:50,149
우리는 사실 Conv의 뒤집힌 버전을 쓰고 있는 것입니다.
하지만 이 수업에서는 이를 더 자세히 다루지는 않겠습니다.

237
00:29:50,149 --> 00:29:58,385
하지만 손으로 직접 계산해보면 conv에 정확한 정의와
크게 다르지 않을 것입니다.

238
00:29:58,385 --> 00:30:06,432
하지만 기본적으로는 필터를 가지고 이미지에 슬라이딩하면서
모든 위치에서 내적을 수행하게 되는 것입니다.

239
00:30:09,088 --> 00:30:17,278
이전에도 언급했듯이 CNN이 어떻게 수행되는지를 살펴보면

240
00:30:17,278 --> 00:30:28,236
입력 이미지는 여러 레이어를 통과하게 됩니다. 가령 첫 번째
Conv Layer 후에는  non-linear layer를 통과합니다.

241
00:30:28,236 --> 00:30:33,608
나중에 배우겠지만, ReLU를 가장 많이 사용합니다.

242
00:30:33,608 --> 00:30:41,244
Conv, ReLU, Conv, ReLU를 하고나면 pooling layer를
거치게 됩니다. 다시 배우겠지만-

243
00:30:41,244 --> 00:30:45,411
pooling 은 activation maps의 사이즈를
줄이는 역할을 합니다.

244
00:30:47,300 --> 00:30:56,872
그리고 CNN의 끝단에는 FC-Layer가 있습니다.
FC-Layer는 지난시간까지 배운 레이어입니다.

245
00:30:56,872 --> 00:31:07,178
마지막 Conv 출력 모두와 연결되어 있으며 최종 스코어를 계산하기
위해 사용합니다.

246
00:31:08,445 --> 00:31:14,181
그럼 이제 "Spatial dimension"에 대해 알아보겠습니다.

247
00:31:18,363 --> 00:31:28,025
자 여기 32 x 32 x 3 이미지가 있습니다. 그리고 이 이미지를
5 x 5 x 3 필터를 가지고 연산을 수행합니다.

248
00:31:28,025 --> 00:31:34,337
이제 어떻게 이 둘을 가지고 28 x 28 activation map이
생기는지를 알아보겠습니다.

249
00:31:34,337 --> 00:31:41,505
간단한 예시로 7 x 7  입력에 3 x 3 필터가 있다고 해봅시다.

250
00:31:41,505 --> 00:31:47,418
이제 이 필터를 이미지의 왼상당부터 씌웁니다.

251
00:31:47,418 --> 00:31:53,169
그리고 이제 해당 값들의 내적을 수행할 것입니다.

252
00:31:53,169 --> 00:31:56,764
이 값들은 activation map의 좌 상단에 위치하게 되겠죠

253
00:31:56,764 --> 00:32:02,389
그리고 다음 단계로 필터를 오른쪽으로 한칸 움직입니다.

254
00:32:02,389 --> 00:32:05,535
그러면 값 하나를 또 얻을 수 있을 것입니다.

255
00:32:05,535 --> 00:32:14,528
이렇게 계속 반복하게 되면  결국 5 x 5의 출력을 얻게 됩니다.

256
00:32:14,528 --> 00:32:25,381
이 슬라이드 필터는 좌우 방향으로는 5번만 수행가능하고
상하 방향으로도 5번만 수행가능합니다.

257
00:32:27,834 --> 00:32:31,906
그리고 여기에는 다양한 방법을 이용해 볼 수 있습니다.

258
00:32:31,906 --> 00:32:40,326
지금까지는 슬라이딩을 한칸씩만 진행했었죠.
이때 움직이는 칸을  바로 "stride" 라고 합니다.

259
00:32:40,326 --> 00:32:46,700
지금까지는 stide = 1을 사용했습니다.
그럼 stride = 2 일때는 어떨까요?

260
00:32:46,700 --> 00:32:58,944
다시 왼쪽 위부터 시작해서 움직입니다. 다만 여기에서는
1칸은 건너뛰고 그 다음칸으로 이동해서 계산을 합니다.

261
00:33:00,773 --> 00:33:11,257
이렇게 tride가 2 이면 3칸이면 못움직이고
결국 출력은 3 x 3 이 됩니다.

262
00:33:13,035 --> 00:33:18,653
그렇다면 stride = 3 이면 출력의 사이즈는 몇일까요?

263
00:33:18,653 --> 00:33:27,905
stride가 3인 경우에는 이미지를 슬라이딩해도 필터가
모든 이미지를 커버할 수 없습니다.

264
00:33:27,905 --> 00:33:32,363
이 예시에서 stride 가 3이면 이미지에 잘 맞아떨어지지 않습니다.

265
00:33:32,363 --> 00:33:41,903
실제로 이렇게 되면 잘 동작하지 않습니다. 이렇게 하면 안됩니다.
이로 인해 불균형한 결과를 볼 수도 있기 때문입니다.

266
00:33:46,095 --> 00:33:54,690
그래서 상황에 따라 출력의 사이즈가 어떻게 될 것인지를
계산할 수 있는 아주 유용한 수식이 있습니다.

267
00:33:54,690 --> 00:34:05,597
입력의 차원이 N이고 필터 사이즈가 F이고
스트라이드가 몇이다 라고 주어지게 되면

268
00:34:06,992 --> 00:34:12,850
출력의 크기는 (N - F) / stride + 1 이 됩니다.

269
00:34:12,850 --> 00:34:18,619
이를 이용해서 어떤 필터 크기를 사용해야 하는지를 알 수 있습니다.

270
00:34:18,620 --> 00:34:27,326
그리고 어떤 stride를 사용했을때 이미지에 꼭 맞는지,
그리고 몇 개의 출력값을 낼 수 있는지도 알 수 있습니다.

271
00:34:29,257 --> 00:34:32,546
지금까지 유용한 수식을 한 번 알아봤습니다.

272
00:34:32,547 --> 00:34:38,637
앞서 보신바와 같이 N = 7 이고 F = 3 일때,
그리고 stride가 1이면

273
00:34:38,637 --> 00:34:43,498
이걸 그대로 수식에 적용해보면 5 x 5 출력이
나올 것이라는 것을 알 수 있습니다.

274
00:34:43,498 --> 00:34:47,665
stride가 3인 경우를 보면, 잘 동작하지 않겠죠. (2.33)

275
00:34:50,288 --> 00:34:59,552
그리고 가장 흔히 쓰는 기법은 zero-pad 입니다.
출력의 사이즈 의도대로 만들어 주기 위해서죠

276
00:34:59,552 --> 00:35:04,140
이는 이전 질문이었던 "코너는 어떻게 처리하나요"
와도 연결되는 문제입니다.

277
00:35:04,140 --> 00:35:09,222
이를 위해 할 일은, 이미지의 가장자리에 0을 채워 넣는 것입니다.

278
00:35:09,222 --> 00:35:19,134
이렇게 되면 좌 상단의 자리에서도 필터 연산을
수행할 수 있게 됩니다.

279
00:35:19,134 --> 00:35:33,654
자 이제 다시 질문입니다. 7 x 7 입력에 3 x 3 필터 연산을 수행할 때
zero-padding을 하면 출력이 어떻게 될까요?

280
00:35:33,654 --> 00:35:36,285
[학생들이 대답]

281
00:35:36,285 --> 00:35:44,847
몇 명이 6이라고 하는 것 같은데요
저 수식을 한 번 잘 생각해 보세요

282
00:35:44,847 --> 00:35:52,594
N에 7을, F에 3을 대입하고 stride를 1으로 하면

283
00:35:52,594 --> 00:35:57,264
그래서 우리가 실제로 얻는 것, 실제로
이것은 우리에게주는 것입니다.

284
00:35:57,264 --> 00:36:06,707
(7 - 3) /1 + 1 = 5 입니다. 이건 zero-padding이 없고
우리는 이 수식을 살짝 고쳐야합니다.

285
00:36:06,707 --> 00:36:12,161
이 수식은 zero-padding을 하지 않은 수식이죠

286
00:36:12,161 --> 00:36:24,173
하지만 zero-padding을 하면 출력이 7이 됩니다.
그래서 결국 7 x 7 출력을 얻게 되는 것입니다.

287
00:36:24,173 --> 00:36:30,178
원래 공식으로 돌아가보자면 N은 7이 아니라 9가 되겠죠

288
00:36:30,178 --> 00:36:42,253
N = 9 가 되고 필터 사이즈인 3을 빼면 6이 됩니다. 이를 stride
1나누면 다시 6이고 여기에 1을 더하면 7이 됩니다.

289
00:36:42,253 --> 00:36:47,974
padding을 하려면 수식을 이런식으로 적용하면 되겠습니다.

290
00:36:49,739 --> 00:36:51,646
질문 있나요?

291
00:36:51,646 --> 00:36:54,396
[학생이 질문]

292
00:37:00,717 --> 00:37:08,962
질문은 "실제 출력 값의 사이즈는 몇입니까?
7 x 7 입니까 7 x 7 x 3 입니까?" 입니다.

293
00:37:08,962 --> 00:37:14,495
출력은 7 x 7 x "필터의 갯수" 가 됩니다.

294
00:37:14,495 --> 00:37:21,320
명심해야할 점은 각 필터가 입력의 모든 depth에
내적을 수행한다는 것입니다.

295
00:37:21,320 --> 00:37:23,801
하나의 값만 나오겠죠

296
00:37:23,801 --> 00:37:37,124
다시 이전 슬라이드로 돌아가보겠습니다. 이전의 예제에서는
각 필터는 7 x 7 x 1이 되겠죠

297
00:37:37,124 --> 00:37:40,493
activation map의 depth는 우리

























