---
title: "[04] GAN 정리 "
date:   2021-09-07
excerpt: "Generative Adversarial Network" 
category: [Paper]
layout: post
tag:
- Paper
order: 0

comments: true
---

# INTRO

**[원논문]**      
* [Generative Adversarial Network](https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf)     



 
----


# GAN 의미
**Discriminator(판별기)** 와 **Generator(생성기)**가 경쟁적으로 **대립**시켜(Adversarial) 학습을 시키는 신경망      

생성모델을 대표한다     


GAN에서는 단순히 하나를 학습하기보다 **경쟁시켜 학습**하기 때문에 **판별기**와 **생성기**가 **함께 성장**    

**[GAN의 핵심 목표]**       
각각의 역할을 가진 두 모델을 통해 적대적 학습을 하면서 **‘진짜같은 가짜’** 를 **생성해내는 능력**을 키워주는 것.


---

# GAN 특징
## 구성        
![image](https://user-images.githubusercontent.com/76824611/132297871-f92c6458-f0ce-481d-8d55-f9f27067a28d.png)
* **Generator(생성기)**: 생성된 z를 받아 실제 데이터와 **비슷한 데이터**를 **만들어내**도록 학습     
* **Discriminator(판별기)**:  실제 데이터와 생성자가 생성한 가짜 데이터를 구별하도록 학습    

## ex    
예를들어 강아지를 판별하는 모델 (혹은 강아지를 생성하는 모델을) 학습하고 싶다고 하였을 때,    

**입력**: 강아지 사진 & 강아지가 아닌 사진이 들어옴    

**Discriminator(판별기)**: 이를 입력받아 강아지가 맞다/아니다 라고 답함       

**Generator(생성기)**
   * 이제 그 입력에 Generator(생성기) 모델이 만들어낸 이미지를 사용하는 것       
   * 이것은 강아지 이미지(엄밀히 말하자면, 분류기가 강아지로 분류할 이미지)를 만들어내기 위해서 노력           
   * Generator의 성능이 높아질 수록 분류모델은 어려운 문제를 풀게되고, 성능도 함께 오를 것       


----
-----


# GAN의 loss function
GAN에서 사용하고 있는 loss function은 **minimax loss**이다     
복잡한것 같지만 읽어보면 의외로 간단하다.


## minimax loss 
![image](https://user-images.githubusercontent.com/76824611/132304292-e3e276ef-a16c-4ee4-b33b-2d6274916383.png)

**[첫번째 항]**   
real data x를 discriminator 에 넣었을 때 나오는 결과를 log 취했을 때 얻는 기댓값     
![image](https://user-images.githubusercontent.com/76824611/132312183-68816d26-a9aa-4f34-a88f-f5b89587f776.png)


**[두번째 항]**     
fake data z를 generator에 넣었을 때 나오는 결과를 discriminator에 넣었을 때 그 결과를 log(1-결과)했을 때 얻는 기댓값
![image](https://user-images.githubusercontent.com/76824611/132312214-65c0cba2-e58e-4ea9-9d0b-33bc170722b9.png)

---

## 식 해설    
**[Discriminator에서 위의 식(value function V(D,G))의 이상적인 결과]**        
Discriminator가 real data와 fake data를 잘 구별해 낸다.      
* **Discriminator에 들어온 데이터가 real data**일 때    
   * **D(x)**가 1이 되어 첫번째 항은 0이 되어 사라지고 G(z)가 생성해낸 **가짜 이미지를 구별해낼 수 있음**             
   * **D(G(z))** 는 0이 되어 두번째 항은 log(1-0)=log1=0이 되어 **전체 식 V(D,G) = 0**이 된다.   
   * 즉, 최댓값'은 '0'      

**[Generator에서 value function V(D,G)의 이상적인 결과]**     
Generator가 discriminator가 구분 못할 만큼 진짜같은 데이터를 생성해낸다.      
* ~~**첫번째 항**~~: Discriminator가 real data에 대해 처리하는 것이므오 fake data를 생성하는 generator와는 관련이 없다.(무시)         
* **두번째 항**: discriminator가 구분 못하므로 fake data를 real data로 잘못 인식한다.      
  * 그러므로 D(G(z)) =1이 되고 log(1-1) = log0 = -∞ 가 된다.       
  *  '최솟값'은 '-∞'임      
  
    
**[Discriminator]**    
real or fake를 판단함 ➡ [Binary Cross Entropy loss]()를 사용     
➡ G는 log(1-D(G(z))를 최소화(D(G(z))를 최대화)하기 위해 학습되도록하는 것     
➡ (V(D,G) 최소화)    
 





















