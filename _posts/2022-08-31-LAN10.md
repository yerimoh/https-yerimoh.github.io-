---
title: "New Intent Discovery with Pre-training and Contrastive Learning 정리"
date:   2022-08-31
excerpt: "Between words and characters:A Brief History of Open-Vocabulary Modeling and Tokenization in NLP"
category: [Paper]
layout: post
tag:
- Paper
order: 0

comments: true
---


   

# 원 논문
[Enriching Word Vectors with Subword Information](https://arxiv.org/abs/2112.10508)


# 소스코드
[git adress](https://github.com/ zhang-yu-wei/MTP-CLNN)


---

# Abstract
새로운 의도(intent) 발견은 지원되는 **의도(intent) 클래스 세트**를 확장하기 위해,       
**사용자 발화에서 새로운 의도 범주를 발견**하는 것을 목표로 한다.       

이 발견은 실질적인 대화 시스템의 개발과 서비스 확대를 위한 중요한 과제이다.   

이러한 중요성에도 불구하고, 이 문제는 여전히 문헌에서 충분히 연구되지 않고 있다.  

**[기존 접근 방식의 문제]**        
* 일반적으로 레이블이 지정된 발화(labeled utterances)에 의존     
* 표현 학습 및 클러스터링을 위해 pseudo-labeling 방법을 사용 ➡ 이는 레이블 집약적이고 비효율적이며 부정확하다.     



**[본 논문의 해결책]**    
* 우리는 새로운 의도 발견을 위한 두 가지 중요한 연구 질문에 대한 새로운 해결책을 제공한다:    
* **(1)** 의미론적 발화 표현을 배우는 방법     
* **(2)** 발화를 더 잘 클러스터링하는 방법      
* 특히, 우리는 먼저 표현 학습을 위해 외부 레이블이 지정된 데이터와 함께 레이블이 지정되지 않은 풍부한 데이터를 활용하는 multi-task pre-training 전략을 제안한다.     
* 그런 다음 클러스터링을 위해 레이블이 지정되지 않은 데이터에서 self-supervisory 신호를 이용하기 위해 새로운 대조 손실(contrastive loss)을 설계한다.    
* 세 가지 의도 인식 벤치마크에 대한 광범위한 실험은 제안된 방법의 높은 효과를 입증하는데, 이는 비지도 및 준지도 시나리오 모두에서 최첨단 방법을 큰 폭으로 능가한다. 



1 Introduction
Why Study New Intent Discovery (NID)? Recent years have witnessed the rapid growth of conversational AI applications. To design a natural
language understanding system, a set of expected
customer intentions are collected beforehand to
train an intent recognition model. However, the predefined intents cannot fully meet customer needs.
This implies the necessity of expanding the intent
recognition model by repeatedly integrating new
intents discovered from unlabeled user utterances
(Fig. 1). To reduce the effort in manually identifying unknown intents from a mass of utterances,
previous works commonly employ clustering algorithms to group utterances of similar intents (Cheung and Li, 2012; Hakkani-Tür et al., 2015; Padmasundari, 2018). The cluster assignments thereafter
can either be directly used as new intent labels or
as heuristics for faster annotations.



