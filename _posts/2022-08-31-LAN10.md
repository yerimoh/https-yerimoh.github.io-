---
title: "New Intent Discovery with Pre-training and Contrastive Learning 정리"
date:   2022-08-31
excerpt: "Between words and characters:A Brief History of Open-Vocabulary Modeling and Tokenization in NLP"
category: [Paper]
layout: post
tag:
- Paper
order: 0

comments: true
---


   

# 원 논문
[Enriching Word Vectors with Subword Information](https://arxiv.org/abs/2112.10508)


# 소스코드
[git adress](https://github.com/ zhang-yu-wei/MTP-CLNN)


---

# Abstract
새로운 의도(intent) 발견은 지원되는 **의도(intent) 클래스 세트**를 확장하기 위해,       
**사용자 발화에서 새로운 의도 범주를 발견**하는 것을 목표로 한다.       

이 발견은 실질적인 대화 시스템의 개발과 서비스 확대를 위한 중요한 과제이다.   

이러한 중요성에도 불구하고, 이 문제는 여전히 문헌에서 충분히 연구되지 않고 있다.  

**[기존 접근 방식의 문제]**        
* 일반적으로 레이블이 지정된 발화(labeled utterances)에 의존     
* 표현 학습 및 클러스터링을 위해 pseudo-labeling 방법을 사용 ➡ 이는 레이블 집약적이고 비효율적이며 부정확하다.     



**[본 논문의 해결책]**    
* 우리는 새로운 의도 발견을 위한 두 가지 중요한 연구 질문에 대한 새로운 해결책을 제공한다:    
* **(1)** 의미론적 발화 표현을 배우는 방법     
* **(2)** 발화를 더 잘 클러스터링하는 방법      
* 특히, 우리는 먼저 표현 학습을 위해 외부 레이블이 지정된 데이터와 함께 레이블이 지정되지 않은 풍부한 데이터를 활용하는 multi-task pre-training 전략을 제안한다.     
* 그런 다음 클러스터링을 위해 레이블이 지정되지 않은 데이터에서 self-supervisory 신호를 이용하기 위해 새로운 대조 손실(contrastive loss)을 설계한다.    
* 세 가지 의도 인식 벤치마크에 대한 광범위한 실험은 제안된 방법의 높은 효과를 입증하는데, 이는 비지도 및 준지도 시나리오 모두에서 최첨단 방법을 큰 폭으로 능가한다. 


---
---


# **1 Introduction**

## Why Study New Intent Discovery (NID)      
최근 몇 년 동안 대화형 AI 애플리케이션의 급속한 성장을 목격했다.   

**[문제]**      
자연어 이해 시스템(NLU)을 설계하기 위해, 의도 인식 모델(intent recognition model)을 훈련시키기 위해 **미리** **예상 고객의 의도 세트(predefined intents)를 수집**한다.    
그러나 미리 정의된 의도(predefined intents)는 고객의 요구를 완전히 충족시킬 수 없다.      
➡ 이는 레이블이 지정되지 않은 사용자 발화에서 발견된 새로운 의도를 반복적으로 통합하여 **의도 인식 모델을 확장할 필요성**을 시사한다
![image](https://user-images.githubusercontent.com/76824611/187633563-3b928c35-4da8-42d9-b82b-b4f7be06c397.png)


**[해결책]**      
다수의 발화에서 알려지지 않은 의도를 수동으로 식별하는 노력을 줄이기 위해, 이전 연구는 일반적으로 유사한 의도를 가진 발화를 그룹화하기 위해 clustering algorithms을 사용한다(Cheung and Li, 2012; Hakkani-Tür et al., 2015; Padmasundari, 2018).     
➡ 이후 클러스터 할당은 **새로운 의도 레이블로 직접 사용**하거나 **더 빠른 주석을 위한 휴리스틱**으로 사용가능함



----


## Research Questions (RQ) and Challenges
Current study of NID centers around two basic
research questions: 1) How to learn semantic utterance representations to provide proper cues for
clustering? 2) How to better cluster the utterances?
The study of the two questions are often interwoven
in existing research. Utterances can be represented
according to different aspects such as the style of
language, the related topics, or even the length
of sentences. It is important to learn semantic utterance representations to provide proper cues for
clustering. Simply applying a vanilla pre-trained
language model (PLM) to generate utterance representations is not a viable solution, which leads to
poor performance on NID as shown by the experimental results in Section 4.2. Some recent works
proposed to use labeled utterances of known intents
for representation learning (Forman et al., 2015;
Haponchyk et al., 2018; Lin et al., 2020; Zhang
et al., 2021c; Haponchyk and Moschitti, 2021),
but they require a substantial amount of known
intents and sufficient labeled utterances of each
intent, which are not always available especially
at the early development stage of a dialogue system. Further, pseudo-labeling approaches are often
exploited to generate supervision signals for representation learning and clustering. For example, Lin
et al. (2020) finetune a PLM with an utterance similarity prediction task on labeled utterances to guide
the training of unlabeled data with pseudo-labels.
Zhang et al. (2021c) adopt a deep clustering method
(Caron et al., 2018) that uses k-means clustering
to produce pseudo-labels. However, pseudo-labels
are often noisy and can lead to error propagation







---



