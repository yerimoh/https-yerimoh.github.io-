---
title: "Rethinking Style Transformer with Energy-based Interpretation: Adversarial Unsupervised Style Transfer using a Pretrained Model정리"
date:   2023-02-17
excerpt: "Rethinking Style Transformer with Energy-based Interpretation: Adversarial Unsupervised Style Transfer using a Pretrained Model paper review"
category: [Paper]
layout: post
tag:
- Paper
order: 0

comments: true
---

# Abstract
<span style="background-color:#F5F5F5">**[해결하고자 하는 문제]**</span>        
Style control, content preservation 및 fluency는 text style transfer models의 품질을 결정한다.      
nonparallel 말뭉치에 대해 train하기 위해, 몇 가지 기존 접근법은 **adversarial loss로  style discriminator를 속이는 것을 목표**로 한다.     
그러나 <span style="background-color:#FFE6E6">adversarial training은 다른 두  metrics에 비해 **fluency를 크게 저하**</span>시킨다.     


<details>
<summary>📜 Adversarial loss란? </summary>
<div markdown="1">
  
Adversarial loss는 Generator로 하여금 진짜처럼 보일 정도로 사실적인 가짜 이미지를 생성하도록 학습 알고리즘

</div>
</details>


<details>
<summary>📜 adversarial training란? </summary>
<div markdown="1">
  
적대적 훈련 Adversarial training은 regularization의 한 방법이다.

머신러닝, 딥러닝 분야에서 regularization은 overfitting을 막고 모델을 robust하게 만들어주기 위해 사용한다.

딥러닝 모델은 Input data를 학습하여 적절한 label을 반환하는 것을 목적으로 훈련을 진행한다.

Adversarial attack은 반대로 이미 훈련된 모델에 대하여 입력 데이터를 잘못 예측하도록 Input을 조작하는 것을 말한다 .

이미지 데이터를 input으로 받는 CNN의 경우 정답 Y에서 내가 원하는 예측값Y'를 반환하도록 조금씩 이미지의 픽셀을 수정한다.
  
</div>
</details>


<span style="background-color:#F5F5F5">**[본 논문의 목적]**</span>        
* 본 연구에서는 <span style="background-color:#fff5b1">energy-based interpretation을 사용하여 **이 현상을 설명**</span>하고,        
<span style="background-color:#fff5b1">pretrained language model을 활용하여 **fluency을 향상**</span>시킨다.      
* 구체적으로, 우리는 <span style="background-color:#fff5b1">**discriminator와 모델 자체를 재구성**</span>하고,    
<span style="background-color:#fff5b1">**pretrained language model을 text style transfer framework에 적용**</span>하여 **generator와  discriminator가 pretrained model의 힘을 활용할 수 있는 새로운 접근 방식을 제안**한다.         


본 논문은 GYAFC, Amazon 및 Yelp의 세 가지 공개 벤치마크에서 모델을 평가하고 **전체 메트릭에서 SOTA 달성**했다.


---
---

# 1 Introduction

**Text style transfer**은 **스타일에 구애받지 않는 의미론을 유지**하면서, **한 스타일에서 다른 스타일로 문장을 변환하는 작업**이다.          

Text style transfer task을 해결할 때는 **세 가지 기준**을 고려해야 한다.            
1) ***style control***, style이 원래 문장에서 생성된 문장으로 얼마나 잘 transfer되는지,        
2) ***content preservation***,  생성된 문장이 원본의 의미를 얼마나 잘 유지했는지,       
3) ***fluency***,생성된 문장이 얼마나 자연스러운지.      


**문장의 style을 fluently하게 변환**하는 것은 종종 **content preservation과 충돌**하기 때문에 Text style transfer은 어렵다.          

이 문제를 해결하기 위해,   
여러 supervised text style transfer method이 시도되었다. 그러나 style-labeled이 있는 문장 쌍을 사용할 수 없는 경우가 많기 때문에 실제 환경에서는 이러한 접근 방식이 실용적이지 않다.   

다양한 비지도 텍스트 스타일

Various unsupervised text style
transfer approaches have become popular, including those using an autoencoder (Hu et al., 2017;
Huang et al., 2020), back-translation (Prabhumoye
et al., 2018; Lample et al., 2019), and reinforcement learning (Xu et al., 2018; Luo et al., 2019).
Among previous studies, Style Transformer (Dai
et al., 2019) achieved fine-grained style control by
deceiving the style discriminator through adversarial training. Aside from their strengths, however,
adversarial models including Style Transformer degrades the fluency of generated sentences.


In this paper, we review Style Transformer to
investigate the reason behind the fluency degradation in adversarial models. To more precisely
interpret what fluency is, we introduce the notion of energy (Hinton, 2002; Lecun et al., 2006),
which is the entropy of variables. The energy function, which measures the energy of input variables
with respect to a particular style, outputs low energy if the inputs are common in that style and
outputs high energy otherwise. For example, formal/informal sentences would likely have low energy in the formality corpus, while sentences that
have nothing to do with formality (e.g., political
expressions) would have high energy in the corpus. Accordingly, we define fluency as having low
energy in a particular corpus, in which the fluent
sentences express one of the styles in the corpus.
As illustrated in Figure 1, fluency degrades while
deceiving the discriminator, since adversarial learning maximizes the energy to the source style and
drives the generated sentence far away from the distribution of the corpus. To counter fluency degradation, we introduce a regularizer using a language
model (LM) to keep the generated sentences in the
distribution of the corpus. This LM-based regularizer keeps the generated sentences in the corpus by
pulling the sentence to the target corpus.


To apply the LM-based regularizers, we can
leverage pretrained models such as GPT-2 to generate fluent sentences. Moreover, fluency is expected to further improve when the generator and
the discriminator are also replaced with a pretrained
model. However, as shown in Figure 2, the generator, discriminator, and LM must share the same
vocabulary and tokenizer in order to propagate gradients successfully. Thus, inefficiency can arise,
in that two of the three modules may need to be
re-trained from scratch because the existing pretrained models are based on different tokenizers.
To address this issue, we restructured the discriminator and LM such that a single pretrained model is
applied to all three modules: the generator, discriminator, and LM. By using a single pretrained model,
our method not only solves the inconsistent vocabulary problem but also has advantages when applying further pretraining for domain adaptation (Gururangan et al., 2020) or additional dataset (Lai
et al., 2021a). This is because additional pretraining is necessary when only a single model is used
to improve style transfer performance.
Our contributions can be summarized as follows:

• We analyze the fluency degradation in adversarial training with an energy-based interpretation, and propose a regularizer leveraging a
language model to prevent fluency degradation.


• We reconstruct the discriminator and language
model such that the single pretrained language
model can be employed in the text style transfer framework.


• We achieve new state-of-the-art results on
GYAFC, Amazon, and Yelp datasets and carefully analyze the contribution of each component of our model.


---
---

# 2 Related Work

## 2.1 Unsupervised style transfer
Many of the previous studies have attempted to
learn disentangled representations of text by separating representations of content and style in a latent space. For instance, Shen et al. (2017) trained
a cross-aligned autoencoder to learn a shared latent space for contents, while learning a separate
representation for styles using adversarial learning. Yang et al. (2018) further extended this crossaligned approach by leveraging LM as a discriminator to enhance the informativeness and stability
of adversarial training. Yi et al. (2020) leveraged
multiple instances of the same style to model the
latent space of underlying stylistic characteristics,
and samples extracted from this space were fed into
the decoder to balance with contents. These works
using disentangled representations exhibited reasonable performance with high interpretability, but
disentangled content representations can still contain style-relevant information, as pointed out by
Lample et al. (2019). In addition, there is a limitation in that the meaning of the input sentence must
be expressed in a fixed-size vector with a limited
capacity (Dai et al., 2019).


In contrast, there are methods without disentangled representations that do not explicitly disentan
gle the content and style of text using reinforcement learning (Xu et al., 2018; Luo et al., 2019)
and back-translation (Lample et al., 2019; Prabhumoye et al., 2018). Dai et al. (2019) proposed a
novel style transfer model based on the transformer
architecture without disentangled representations,
and Wang et al. (2019) also utilized a transformer
for an unsupervised framework by editing entangled latent representations. These models are novel
in their model architecture or training strategy, but
they do not utilize pretraining models, which results in lower performance than the state-of-the-art
methods. On the other hand, our work proposes a
novel approach to effectively leverage a pretrained
LM in an unsupervised text style transfer task.



## 2.2 Style transfer with pretrained models
Recently, pretrained models have achieved great
success on various NLP tasks such as machine
translation (Chronopoulou et al., 2020; CONNEAU
and Lample, 2019) and text summarization (Liu
and Lapata, 2019). The pretrained models are also
being used for text style transfer tasks. Sudhakar
et al. (2019) used two variants of ‘decoder-only’
transformer to generate sentences in a target style
and leveraged the power of GPT (Radford et al.,
2018). Malmi et al. (2020) used a padded masked
language model (Mallinson et al., 2020) variant,
whose architecture and the trained corpus were
identical to those of BERT (Devlin et al., 2019).
Although these studies exploited the power of pretrained models, our approach differs in that we train
our model adversarially in an end-to-end manner.


In addition, several works have focused on style
transfer in a specific domain, or for leveraging an
additional corpus. To transfer writing styles between authors, Syed et al. (2020) pretrained LM on
the author corpus from scratch using masked language modeling. Laugier et al. (2021) detoxified
toxic texts by fine tuning a pretrained T5 (Raffel et al., 2020) using additional denoising and
cycle-consistency objectives. However, these studies only focused on a specific domain. Lai et al.
(2021a) built a pseudo-parallel dataset by leveraging generic resources including WordNet (Baccianella et al., 2010) and Parabank (Hu et al., 2019)
to fine tune BART on style transfer tasks. Lai et al.
(2021b) fine tuned BART (Lewis et al., 2020) using
parallel data with a policy gradient (Sutton et al.,
1999) which maximized the style classifier reward
and the BLEU score reward. Our work incorporates
pretrained models with adversarial training on various domains, while trained only on a non-parallel
corpus.


## Energy-based model
The conventional probabilistic model outputs the
normalized probability p(x) for input variable x.
In contrast, the energy-based model outputs the
non-normalized scalar value E(x) denoted as energy (Hinton, 2002; Lecun et al., 2006) Using the
energy-based model, we can classify x by comparing the energy of each label, or generate x by
optimizing arg minx E(x).


Several works have leveraged the energy-based
model for image generation (Ngiam et al., 2011;
Zhao et al., 2017), text generation (Deng et al.,
2020; Bakhtin et al., 2021), and reinforcement
learning (Haarnoja et al., 2017). We borrow the
main idea of the energy-based model, which expresses the classifier in the form of an energy function. In the work of Che et al. (2020), the authors
interpreted the GAN discriminator (Goodfellow
et al., 2014) using the energy-based model, but
we apply this interpretation to the style transfer
task. We show that Style Transformer can be interpreted as an energy-based model by decomposing
the discriminator, and provide the reason why fluency degradation occurs when we try to deceive
the style discriminator.






