---
title: "MatSciBERT: A materials domain language model for text mining and information extraction 정리"
date:   2023-02-15
excerpt: "Specializing Multi-domain NMT via Penalizing Low Mutual Information paper review"
category: [Paper]
layout: post
tag:
- Paper
order: 0

comments: true
---



[사전지식]   
* BERT    
* SCIBERT  
* [개체명 인식의 BIO 표현 이해하기](https://wikidocs.net/24682)   
* [CRF(Conditional Random Field)](https://wikidocs.net/34156)
materials science에 대한 knowledge가 많이 생성되며, 텍스트로 저장되어왔다.    

<span style="background-color:#F5F5F5">**[문제]**</span>         
Bidirectional Encoder Representations from Transformers (BERT)과 같은 NLP 모델은 유용한 정보 추출 도구이지만, 이러한 모델은 <span style="background-color:#fff5b1">**materials science 특정 표기법(materials science specific notations)**과 **전문 용어(jargons)**에 대해 train되지 않았기 때문에</span> materials science에 적용할 때 좋은 결과를 얻지 못한다.         

<span style="background-color:#F5F5F5">**[해결: MatSciBERT]**</span>     
* <span style="background-color:#FFE6E6">**peer-reviewed materials science publications의 large corpus**에 대해 train</span>된 materials-aware language model이다.        
* 이 모델은 MatSciBERT가  science corpus에 대해 훈련된 언어 모델인 **[SciBERT](https://yerimoh.github.io/LAN22/)보다 성능이 좋다.**    
* downstream tasks, named entity recognition, relation classification, and abstract classification에서 SOTA성능이 난다.   


본 논문은 MatSciBERT의 pre-trained weights를 공개적으로 액세스할 수 있도록 한다.      

----
---


# INTRODUCTION
<span style="background-color:#fff5b1">**materials를 발견하고 실용적인 응용에 활용**하는 것은 수십 년 단위로 걸려 **시간이 매우 많이든다**.</span>       
**이 과정을 가속화**하기 위해서는 엄격한 과학적 절차를 통해 
<span style="background-color:#fff5b1"**수세기에 걸쳐 개발된 재료에 대한 지식을 응집력 있는 방식으로 활용하고 활용**</span>해야 한다.       

Textbooks, scientific publications, reports, handbooks, websites 등은 이미 존재하는 정보를 얻기 위해 채굴할 수 있는 큰 데이터 저장소의 역할을 한다.     
그러나 대부분의 과학 데이터는 the form of text, paragraphs with cross reference, image captions, and tables의 형태로 **반구조화되거나 구조화되지 않았기 때문**에 이러한 텍스트에서 **유용한 정보를 추출하는 것은 어려운 작업**이다.       

⚠ 이러한 정보를 수동으로 추출하는 것은, **시간과 자원이 매우 많이 소요**되며 **domain 전문가의 해석에 의존**한다.   




---

<span style="background-color:#F5F5F5">**[NLP 모델 동향]**</span>      
인공지능의 하위 도메인인 자연어 처리(NLP)는 텍스트에서 **정보 추출을 자동화**할 수 있는 대체 접근법을 제시한다.     
* **word2vec 및 GloVe:** Neural pretrained embeddings으로, 꽤 인기가 있지만 **domain-specific knowledge이 부족**하고 **상황별 임베딩을 생성하지 않는다**.          
* 최근 NLP의 발전은 **domain-specific tasks에 대해 pre-trained language model (LM)이 finetuned되는 계산 패러다임의 개발**로 이어졌다.        
* 연구에 따르면 이러한 pretrain-finetune paradigm은 19-23년 사이에 SOTA였다.    
* 최근에, 많은 양의 텍스트와 높은 컴퓨팅 능력의 가용성 때문에, 연구자들은 이러한 **큰 신경 언어 모델을 pretrain시킬 수 있었다**.          
예를 들어, Bidirectional Encoder Representations from Transformers (BERT)은 BookCorpus 및 English Wikipedia에서 훈련되어  question answering과 entity recognition과 같은 여러 NLP 작업에서 SOTA를 발휘한다.         


---


<span style="background-color:#F5F5F5">**[materials science domain에서의 NLP applications]**</span>       
연구원들은 **materials science domain**에서 ML 응용 프로그램을 위한 **데이터베이스 생성을 자동화**하기 위해 **NLP tools를 사용**했다. 아래는 활용의 예시이다.          
아래 예시들은 모두 NLP 파이프라인인 [ChemDataExtractor](https://pubs.acs.org/doi/10.1021/acs.jcim.6b00207)를 사용했다.    
* [create databases of battery materials](https://www.nature.com/articles/s41597-020-00602-2)       
* [Curie and Néel temperatures of magnetic materials](https://www.nature.com/articles/sdata2018111)              
* [inorganic material synthesis routes](https://www.nature.com/articles/s41597-019-0224-1)       
* [composition and dissolution rate of calcium aluminosilicate glassy materials](https://ceramics.onlinelibrary.wiley.com/doi/10.1111/jace.17631)의 조성     
* [용해율과 zeolite 합성경로를 수집하여 zeolite](https://pubs.acs.org/doi/10.1021/acscentsci.9b00193)를 함유하는 게르마늄을 합성     
* [process and testing parameters of oxide glasses 및 testing parameters를 추출하여 Vickers
hardness의 향상된 예측을 가능하게 함](https://web.iitd.ac.in/~krishnan/publications/Krishnan/102_Extracting%20processing%20and%20test.html)              
* [computational materials science research papers에서 추출한 정보를 사용하여 데이터베이스를 만드는 자동화된 NLP](https://www.researchgate.net/publication/349533689_MatScIE_An_automated_tool_for_the_generation_of_databases_of_methods_and_parameters_used_in_the_computational_materials_science_literature) 도구를 만듦              
* [topic modeling in glasses](http://www.gstatic.com/generate_204): unsupervised fashion으로 문학을 다른 주제로 그룹화함, specific queries(elements present, synthesis, or characterization techniques, and applications)를 기반으로 이미지를 찾는 데 사용되었다.           




**[Olivetti et al.(2019)](https://aip.scitation.org/doi/abs/10.1063/5.0021106)의 포괄적 검토**는 NLP가 materials science에 이익을 줄 수 있는 몇 가지 방법을 설명한다.    
* [OSCAR4](https://jcheminf.biomedcentral.com/articles/10.1186/1758-2946-3-41): insights into chemical parsing tools제공, 화학적 구문 분석 도구에 대한 통찰력을 제공        
* [Artificial Chemis](https://onlinelibrary.wiley.com/doi/10.1002/adma.202001626): 전구체 정보의 입력을 받아 목표 대역 간격을 가진 광전자 반도체를 제조하기 위한 합성 경로를 생성          
* [robotic system](https://www.science.org/doi/10.1126/sciadv.aaz8867): 보다 깨끗하고 지속 가능한 에너지 솔루션을 생산하기 위해 thin films을 만듦     
➡ 37과 8천만 개 이상의 materials science domain-specific named entities를 식별하는 연구는 ML과 NLP 기술의 결합을 통해 **다양한 응용을 위한 재료의 가속화를 촉진**했다.      


---


<span style="background-color:#F5F5F5">**[Word2vec와 BERT의 확장]**</span>       
연구자들은 Word2vec와 BERT의 도메인 적응 능력을 아래와 같이 확장하였다.    
* [BioWordVec](https://www.nature.com/articles/s41597-019-0055-0), [BioBERT](https://arxiv.org/abs/1901.08746): 생물과학 분야에서 확장            
* [SciBERT](https://yerimoh.github.io/LAN22/): scientific and biomedical corpus으로 train        
* [clinicalBERT](https://arxiv.org/abs/1904.05342): 2 million clinical notes in [MIMIC-III v1.4 database](https://www.nature.com/articles/sdata201635)에서 훈련됨    
* [mBERT](https://aclanthology.org/2020.findings-emnlp.150/): multilingual machine translations tasks    
* [PatentBERT](http://www.digital.ntu.edu.tw/hsiang/pdf/WPI%20Patent%20classification%20by%20fine-tuning%20BERT.PDF): patent classification    
* [FinBERT](https://arxiv.org/abs/1908.10063): financial tasks        



✨ 이는 <span style="background-color:#fff5b1">**materials-aware LM**이 downstream tasks에 추가로 적응함으로써 **해당 분야의 연구를 크게 가속화할 수 있음을 시사**</span>한다.       


이 연구 이전에는 재료 인식 언어 모델 개발에 대한 논문이 없었지만, 최근 [a recent preprint](https://www.researchgate.net/publication/355846376_The_Impact_of_Domain-Specific_Pre-Training_on_Named_Entity_Recognition_Tasks_in_Materials_Science)은  materials science에서 domain-specific language models이 named entity recognition (NER) 작업에 미치는 영향을 강조한다.       

---

<span style="background-color:#F5F5F5">**[본 논문]**</span>       
이 연구에서, 우리는 materials science domain-specific BERT, 즉 **MatSciBERT**를 훈련시킨다.      
Fig. 1은 materials science 말뭉치 생성, MatSciBERT 훈련 및 다양한 downstream tasks 평가를 포함하는 본 연구에 채택된 방법론의 그래픽 요약을 보여준다.              
우리는 아래 나열된 것처럼 **domain-specific tasks에 대한 SoTA**를 달성한다.      
* **a.**  [NER on SOFC, SOFC Slot dataset by Friedrich et al. (2020)45     
 Matscholar dataset by Weston et al](https://pubmed.ncbi.nlm.nih.gov/31361962/)                    
* **b.** [Glass vs. Non-Glass classification of paper abstracts](https://www.sciencedirect.com/science/article/pii/S2666389921001239)             
* **c.**  [Relation Classification on MSPT corpus](https://aclanthology.org/W19-4007/)            


현재 연구는 materials domain language model의 가용성 격차를 해소하여 연구자가 정보 추출, knowledge graph completion 및 기타  downstream tasks을 자동화하여 **materials 발견을 가속화**할 수 있다.        

**[Fig. 1 Methodology for training MatSciBERT]**
![image](https://user-images.githubusercontent.com/76824611/225840065-ddbf1a52-fd41-4e8f-9f53-55d4f966fb06.png)   
* 우리는 관련 연구 논문을 선택한 후 query search을 통해 Materials Science Corpus (MSC)를 만든다.     
* MSC에서 pre-trained된 MatSciBERT는 다양한 downstream tasks에서 평가된다.       


---

<span style="background-color:#F5F5F5">**[open source]**</span>       
* [huggingface/matscibert](https://huggingface.co/m3rg-iitd/matscibert): pre-trained weights을 제공    
[github/MatSciBERT](https://github.com/M3RG-IITD/MatSciBERT): MatSciBERT의 pretraining과 finetuning on downstream tasks 코드 공개            
* [zenodo](https://doi.org/ 10.5281/zenodo.6413296): downstream tasks을 위한finetuned
models이 있는 코드      




---
---

# RESULTS AND DISCUSSION
## Dataset
Textual datasets는 LM 훈련의 필수적인 부분이다.     

<span style="background-color:#F5F5F5">**[materials domain에 적합하지 않은 corpora]**</span>       
* **BookCorpus, 위키피디아**과 영어와 같은 많은 범용 말뭉치     
* **biomedical corpus, clinical database**: 같은 domain-specific corpora   


<span style="background-color:#F5F5F5">**[materials domain에 적합한 corpora로 data 만들기]**</span>       
* materials specific LM을 제공하기 위해 **4개의 important materials 제품군에 걸친 말뭉치**를 생성    
   * inorganic glasses    
   * metallic glasses     
   * alloys    
   * cement & concrete     
* 위와 같은 광범위한 범주가 언급되었지만, 2차원 물질을 포함한 **몇 가지 다른 범주의 물질도 말뭉치에 존재했다는 점에 유의**해야 한다.         
* 이 연구를 위해 개발된 materials science corpus는 ~285M 단어를 가지고 있으며,
 이는 SciBERT(3.17B 단어)와 BERT(3.3B 단어)를 사전 훈련하는 데 사용되는 단어의 거의 9%이다.    
 ➡ <span style="background-color:#fff5b1"> **SciBERT pre-train을 계속**하기 때문에</span>        MatSciBERT는 3.17 + 0.28 = 3.45B 단어로 구성된 말뭉치에 대해 **효과적으로 훈련**된다.         


<details>
<summary>📜 Supplementary Table 1</summary>
<div markdown="1"> 
 
**[Supplementary Table 1]**      
![image](https://user-images.githubusercontent.com/76824611/225872626-6ca1a9b1-fd9a-49fb-b015-8e0ca1d22b83.png)
* 말뭉치를 만드는 단계는 방법은  Methods section에 나와 있다.     
* 단어의 40%는 norganic glasses 및 ceramics과 관련된 연구 논문에서 나왔다.        
* 단어의 각각 20%는 bulk metallic glasses(BMG), alloys에서 나온 것을 알 수 있다.      
* 'cement and concrete'의 연구 논문 수는 'inorganic glasses and ceramics'보다 많지만,   
 'inorganic glasses and ceramics'가 단어 수가 더 많다.     
➡ 이는 'inorganic glasses and ceramics'의 범주와 관련하여 검색된 많은 수의 full-text documents가 존재하기 때문이다.    
* 구체적으로, 우리는 Elsevier Science Direct Database에서 다운로드한 약 1백만 개의 논문 중에서 약 150만 개의 논문을 선택했다.   

</div>
</details>

<details>
<summary>📜 Supplementary Table 2</summary>
<div markdown="1">
 
**[Supplementary Table 2]**     
![image](https://user-images.githubusercontent.com/76824611/225872675-f316ca7f-b015-4ec4-95f1-20f6b527545a.png)
* materials science 분야와 관련된 중요한 문자열의 단어 수를 나타낸다.    
* 말뭉치는 thermoelectric(열전), nanomaterials(나노 재료), polymers(고분자), and biomaterials(생체 재료)의 중요한 분야를 포괄한다는 점에 유의해야 한다.     
* 또한 언어 모델을 훈련하는 데 사용되는 말뭉치는 실험(experimental) 및 계산(computational) task로 구성되어 있으며, 이 두 가지 접근 방식 **모두 물질 반응(material response)을 이해**하는 데 중요한 역할을 한다.    
* 이 말뭉치의 평균 논문 길이는 ~1848 단어이며,    
이는 **SciBERT** 말뭉치의 평균 논문 길이 2769 단어의 **3분의 2**다.     
* 평균 논문 길이가 적은 2가지 이유   
    * **(a)** 일반적으로 **materials science 논문**은 biomedical 논문보다 **짧다**.         
    * **(b)** 우리 말뭉치에도 full text가 없는 논문이 있다. 그러한 경우, 우리는 최종 말뭉치에 도달하기 위해 그러한 **논문의 요약을 사용**했다.            

</div>
</details>



---



## Pre-training of MatSciBERT


<span style="background-color:#F5F5F5">**[domain adaptive pretraining]**</span>       
MatSciBERT pre-training의 경우,    
본 논문은 <span style="background-color:#fff5b1">[domain adaptive pretraining](https://aclanthology.org/2020.acl-main.740/)을 따른다</span>.              
* **방법**      
이 연구에서 저자들은 domain-specific text의 말뭉치에 대한 initial LM의 pre-training을 계속했다.(처음부터 다시 하지 않고 기존 pretrain된 것에 추가로 했다는 뜻)           
* **결과**      
그들은 initial LM 어휘와 domain별 어휘 사이의 중복이 54.1% 미만임에도 불구하고,            
4개 domain 모두에 대한 **domain별 downstream tasks의 성능이 크게 향상**되는 것을 관찰했다.           
* **비슷한 방식의 모델**    
**BioBERT19와 FinBERT22:** vanilla BERT 모델에 domain-specific text를 추가로 pretrained한 비슷한 접근 방식을 사용하여 개발됨(토큰화는 원래 BERT 어휘를 사용)      



<span style="background-color:#F5F5F5">**[본 논문에의 적용]**</span>       
* **MatSciBERT weights:**    
일부 적합한 LM의 가중치로 초기화한 다음, MSC에서 pre-train한다.         
MatSciBERT에 대한 적절한 초기 가중치를 결정하기 위해, 우리는 tokenizers library(48)을 사용하여   
Materials Science Corpus(MSC)를 기반으로 uncased wordpiece(47)를 훈련시켰다.     
* **MSC 어휘의 중복:**     
uncased SciBERT21 어휘의 경우 53.64%, uncased는 BERT 어휘의 경우 38.90%이다.    
SciBERT의 어휘와 중복이 커서, 우리는 <span style="background-color:#fff5b1">**SciBERT 어휘를 사용하여 말뭉치를 토큰화**</span>하고,   
Beltagy et al. (2019)(21)에 의해 공개된 <span style="background-color:#fff5b1">**SciBERT의 가중치로 MatSciBERT 가중치를 초기화**</span>한다.     


<details>
<summary>📜 materials domain-specific vacab이 아닌 SciBERT vocabulary로 토큰화 하는 이유</summary>
<div markdown="1">

 
materials science별 어휘는 말뭉치를 **더 적은 수의 단어로 표현**하고 **잠재적으로 더 나은 언어 모델로 이어질 수 있다는 것**을 언급할 가치가 있다.      
예를 들어,    
<center>“yttria-stabilized zirconia”</center>         
* SciBERT vocabulary로 토큰화: ```[ “yt”, “##tri”, “##a”, “-”, “stabilized”, “zircon”, “##ia”]```     
* domain-specific 토큰화: ```["yttria", "-", "stabilized", "zircon"]```       
⚠️ 그러나, domain-specific 토큰화를 사용하면 SciBERT 가중치를 사용할 수 없으며,    
SciBERT가 이미 학습한 과학 지식을 활용한다.      
⚠️ 또한  deep neural language models 은 기존 토큰화를 사용하여 **새로운 단어를 나타내는 반복 패턴을 학습할 수 있기 때문에**, **재료 영역에 SciBERT 어휘를 사용하는 것이 반드시 해로운 것은 아니다**.     

예를 들어, 단어 조각 ```"yt"```, ```"##tri"```, 그리고 ```"##a"```가 연속적으로 발생할 때,   
SciBERT는 downstream tasks에서 입증된 것처럼 어떤 물질이 논의되고 있음을 인식한다.  
이러면 domain-specific이 ```"yttria"```라고 토큰화 한것과 비슷한 결과를 얻을 수 있다는 것이다.     
 
➡ 이게 왜 BERT-based LMs(FinBERT22, BioBERT19, and ClinicalBERT40)이 <span style="background-color:#fff5b1">**domain-specific tokenizers를 안쓰고 기존 pre-training을 확장**하는 이유이다.</span> 
 
</div>
</details>  

         

<span style="background-color:#F5F5F5">**[pretraining 결과: Supplementary Fig1.]**</span>       
![image](https://user-images.githubusercontent.com/76824611/225911756-535c3e47-1001-412d-84aa-86d94d9cd082.png)
* pre-training에 대한 자세한 내용은 Methods section에 나와 있다.    
* pre-training은 360시간 동안 수행되었고, final perplexity of 2.998을 달성했다(Supplementary Fig1. 1a).      
* 서로 다른 vocabulary와 validation corpus로 인해 직접 비교할 수는 없지만,     
BERT25와 RoBERTa49 저자는 각각 동일한 범위에 있는 3.99의 perplexities를 달성했다.     
* 우리는 또한 Supplementary Fig. 1b, c의 MLM loss 및 MLM accuracy와 같은 evaluation metrics에 대한 그래프를 제공한다.     
그런 다음 최종 pre-trained LM을 사용하여 **다양한 materials science domain-specific downstream tasks을 평가**했으며, 이에 대한 자세한 내용은 후속 섹션에 설명되어 있다.      
* **downstream tasks에서 LM의 성능을 SciBERT, BERT 및 기타 기준 모델과 비교**하여  **materials’ specific information**를 학습하기 위해 **MatSciBERT의 효과**를 평가했다.     



<span style="background-color:#F5F5F5">**[pretraining 이 모델 성능에 미치는 영향을 이해]**</span>       
* pre-training이 모델 성능에 미치는 영향을 이해하기 위해,     
[SOFC-slot](https://huggingface.co/datasets/sofc_materials_articles)에 대한 materials domain-specific downstream task인 **NER이 pre-training의 정기적인 간격으로 모델을 사용하여 수행되**었다.      
* 이것으로, pre-trained model은 SOFC-slot dataset의 training set에서 finetuned되었다.     
* **SOFC-slot dataset**은 **dataset가 세분화된  materials-specific information로 구성**되어 있어서 이걸 사용했다.     
➡ 따라서 이 데이터 세트는** SciBERT의 성능을 materials-aware LMs과 구별하는 데 적합**하다.      
* 이러한 finetuned 모델의 성능은 test 세트에서 평가되었다.       


<span style="background-color:#F5F5F5">**[longer durations train의 중요성]**</span>       
![image](https://user-images.githubusercontent.com/76824611/225914989-9358c11b-7357-41a8-aeba-fe14a9b298c9.png)
* LM-CRF architecture는 이 연구의 후반부에서 보여주듯이  downstream task에 대해 지속적으로 최상의 성능을 제공하기 때문에 분석에 사용되었다.        
* macro-F1 averages(across three seeds exhibited)은 증가 추세를 보인다(Supplementary Fig. 2a)     
➡ **longer durations train의 중요성**을 시사함    
* 우리는 또한 abstract classification task에 대한 유사한 그래프를 보여준다(Supplementary Fig. 2b).




---
---

## Downstream tasks

여기서 우리는 아래 3가지 materials science specific downstream tasks에 대해 MatSciBERT를 평가한다.   
* Named Entity Recognition (NER)   
* Relation Classification   
* Paper Abstract Classification     





이제 방법 섹션에 설명된 대로 **세 가지 materials science NER datasets에 대한 결과를 제시**한다.      
* solid oxide fuel cells (SOFC)와 SOFC-Slot dataset에 대한 **기존 연구의 최상의 Macro-F1**는 각각 81.50%와 62.60%이다.      
* 우리는 결과의 공정한 비교를 위해 [위 실험](https://pubmed.ncbi.nlm.nih.gov/35465225/)이 수행한 것과 동일한 train-validation-test splits 실험을 실행한다.        
* 더욱이 저자들은 SOFC-Slot dataset에 대해 17개 엔티티(extra entity is “Thickness”)에 걸쳐 평균 결과를 보고했기 때문에, 우리는 또한 ‘Thickness’ entity를 고려한 결과를 보고한다     



<span style="background-color:#F5F5F5">**[Table 1]**</span>      
![image](https://user-images.githubusercontent.com/76824611/225958808-4e283cea-5c08-4d25-a221-c8bc37ca04af.png)  
* Table 1은 MatSciBERT, SciBERT 및 BERT의 SOFC-Slot 및 SOFC 데이터 세트에 대한 NER 작업에 대한  Macro-F1 scores를 보여준다.         
* 우리는 **LM-[CRF](https://wikidocs.net/34156)가** 항상 LM-Linear보다 **더 나은 성능**을 보인다는 것을 관찰한다.     
➡ CRF 층을 추가하면 모델은 예측 개체명, 다시 말해 **레이블 사이의 의존성을 고려할 수 있음** (B가 I앞에 온다)   
➡ 이는 **CRF 계층이 [BIO 태그](https://wikidocs.net/24682)를 정확하게 모델링**할 수 있기 때문이라고 할 수 있다.     
* 또한 **모든 SciBERT 아키텍처**는 **BERT 아키텍처보다 성능이 우수**합니다.      
* 우리는 LM-CRF 아키텍처를 사용하는 동안,   
 MatSciBERT 대 SciBERT에 대한 SOFC-Slot 테스트 세트에서 ~6.3 Macro F1 및 ~3.2 Micro F1(Supplementary Table 3)의 개선을 얻었다.      
     * SOFC 테스트 데이터 세트의 경우, MatSciBERT-BiLSTM-CRF는 SciBERTBiLSTM-CRF보다 ~2.1 Macro F1 and ~2.1 Micro F1만큼 성능이 우수하다.    
     * 다른 아키텍처에서도 유사한 개선을 볼 수 있다.    
     * 이러한 MatSciBERT 결과는 SOFC Slot 및 SOFC 데이터 세트에 대한 현재 최고의 결과를 각각 ~3.35 and ~0.9 Macro-F1로 능가한다.  
 
 
<details>
<summary>📜 Supplementary Table 3</summary>
<div markdown="1"> 
 
 ![image](https://user-images.githubusercontent.com/76824611/225964247-5274b93a-bf6a-4f91-a6ab-522c6f5b3d3d.png)
 
</div>
</details>



<span style="background-color:#F5F5F5">**[Fig. 2: Comparison of MatSciBERT and SciBERT on validation sets of SOFC-Slot dataset]**</span>      
![image](https://user-images.githubusercontent.com/76824611/226265253-82923bc6-bad8-4328-9562-70af23f6917b.png)
* fig 설명    
  * The entity-level F1-score for MatSciBERT and Scibert models        
  * **blue:** entity-level F1-score for **MatSciBERT**    
  * **red:** entity-level F1-score for **SciBERT**        
  * The bold colored text represents the best model’s score.    
* 이 test에는 **SOFC-slot dataset이 쓰였다**.    
   * SOFC dataset: **덜 세분화된 정보**를 나타내는 4개의 entity 유형만 가지고 있다.     
   * SOFC-slot dataset: 17개의 entity 유형으로 구성되어있음.          
➡** materials과 관련된 보다 세분화된 정보를** 가지고 있다는 점에 주목할 필요가 있다.    
* 이 데이터에서 **MatSciBERT의 성능이 SciBERT의 성능보다 훨씬 우수**하다는 것을 알 수 있다.     
* 이 측면을 추가로 평가하기 위해,     
Fig. 2 와 같이 SOFC-slot의 모든 17개 entity 유형에 대한 SciBERT와 MatSciBERT의 F1 점수를 개별적으로 분석했다.       * **모든 materials 관련 entity 유형**(anode material, cathode material, electrolyte
material, interlayer material, and support material)에서 **MatSciBERT가 SciBERT보다 성능이 우수**하다는 것을 관찰한다.    
      * **materials 관련 특성**(open circuit voltage, degradation rate)의 경우 **MatSciBERT가 SciBERT를 크게 능가**할 수 있다.     
* 이는 <span style="background-color:#fff5b1">MatSciBERT가 실제로 **MSC에서 학습한 추가 정보를 활용**하여 **materials 영역에 특정된 복잡한 문제에 대해 더 나은 성능을 제공**할 수 있음을 시사</span>한다.   




<span style="background-color:#F5F5F5">**[Table 2]**</span>      
![image](https://user-images.githubusercontent.com/76824611/226270775-64be5af2-f25f-421b-b124-5aec41973ca3.png)
* [Matscholar dataset](https://pubmed.ncbi.nlm.nih.gov/31361962/)에 대한 결과이다.      
* 이 데이터 세트의 경우에도 MatSciBERT는 SciBERT, BERT의 SoTA result보다 성능이 좋다.        
* Macro-F1은 validation set에서 85.41%, test set에서 85.10%의 성능을 보였다.      
Micro-F1은 validation set에서 87.09%, test set에서 87.04%의 성능을 보였다.   
(더 확인하려면 Supplementary Table 4를 보면 된다).      
* **MatSciBERT-CRF가** Macro-F1 값이 88.66%와 86.38%로 **기존의 SoTA model다 더 낫다**.     



<details>
<summary>📜 Supplementary Table 4</summary>
<div markdown="1"> 
 
![image](https://user-images.githubusercontent.com/76824611/226272981-1e744326-5a7a-4ec3-8b03-767c286774f8.png)
 
</div>
</details>




<details>
<summary>📜 Supplementary Figs. 3 and 4: MatSciBERT의 성능을 입증</summary>
<div markdown="1"> 
 
**MatSciBERT의 성능을 입증**하기 위해,    
 우리는 Supplementary Figs. 3 and 4에서 **validation set** of the dataset**의 예를 보여**준다.     
 MatSciBERT의 전반적인 우수한 성능은 위의Table 2.에서 명백하게 확인가능하다.   
 
![image](https://user-images.githubusercontent.com/76824611/226274932-e59302f2-d014-40b9-95ca-886aef325051.png)
![image](https://user-images.githubusercontent.com/76824611/226274986-e473b32c-d5ac-4a73-a87b-02d7ecbaca8e.png)

**[Supplementary Figure 3]**       
* 우리는 합금(alloys)과 관련된 manuscript의 문장을 보여준다.      
* entities는 실제 레이블을 기준으로 색상이 지정됩니다.     
* MatSciBERT와 SciBERT 모두 ‘dislocation cell-like structure’ 문구를 **'PRO'로 잘못 분류**    
     * PRO: 데이터 세트에서 'O' 또는 'Other'로 레이블이 지정된 것.    
* 'ND'와 'TD'   
     * SciBERT는 'PRO'*(material property)로 분류      
     * MatSciBERT는 이들 엔티티를 'O'(other)로 정확하게 식별함       
* 전반적으로, 우리는 **MatSciBERT가 자료와 관련된 텍스트의 맥락을 식별**할 수 있으며,        
여기서 **entity가 올바르게 태그 지정**된다는 것을 관찰한다.         
* SciBERT의 실수: normal font (non-italicized)로 써져있는 단어에서 실수가 나옴       
* MatSciBERT의 실수: 밑줄이 쳐져있는 단어에서 실수가 나옴.     

 
 
**[Supplementary Figure 3]**       
* SciBERT를 사용하여 얻은 결과를 보여준다.     
* 여기서 ‘YSZ’ (also called yttria-stabilized zirconia)를 B-electrolyte_material로 오분류 하였다.    
이것의 실제 label B-interlayer_materia이다.        
* 그러나 MatSciBERT는 'YSZ'의 라벨을 정확하게 식별할 수 있었다.     

이것들은 SciBERT와 MatSciBERT의 성능을 보여주기 위해 선택된 몇 가지 예시이다.    실측 자료 및 모델 선행

entity 용어를 모르면, 아래의 [논문](https://pubs.acs.org/doi/pdf/10.1021/acs.jcim.9b00470)을 보자!       

 
</div>
</details>






<span style="background-color:#F5F5F5">**[Table 3]**</span>      
![image](https://user-images.githubusercontent.com/76824611/226282239-9fa30d21-66c2-4cfd-9810-ca7c3a8c4edd.png)
* [Materials Synthesis Procedures dataset](https://doi.org/10.18653/v1/W19-4007)에서 수행된 Relation Classification task의 결과를 보여준다.      
* 우리는 또한 그 결과를 두 개의 recent baseline models인 MaxPool과 [MaxAt](https://aclanthology.org/2020.findings-emnlp.410/)과 비교한다.     
 (이에 대한 자세한 내용은 Methods section에서 확인할 수 있다)      
* 이 작업에서도 **MatSciBERT는** margin이 낮지만 SciBERT, BERT 및 기준 모델보다 **일관되게 성능이 우수**하다.       






<span style="background-color:#F5F5F5">**[Table 4]**</span>      
* Paper Abstract Classification downstream task에서,      
우리는 LMs가 [in-house dataset](https://www.sciencedirect.com/science/article/pii/S2666389921001239)을 기반으로 glass vs. non-glass를 주제로 분류할 수 있는 능력을 고려한다.      
이것은 iput이 논문의 abstract인 이진 분류 문제이다.        
여기서도 동일한 baseline model인 MaxPool과 [MaxAt](https://aclanthology.org/2020.findings-emnlp.410/)을 사용한다.            
* 이 table은 MatSciBERT, SciBERT, BERT 및 baseline에 의해 달성된 accuracy의 비교를 보여준다.     
* **MatSciBERT**는 test 세트에서 SciBERT를 **2.75% 이상 accuracy로 능가**한다는 것을 분명히 알 수 있다.
![image](https://user-images.githubusercontent.com/76824611/226286553-ee844713-cfe7-4461-84c8-79211cd794dc.png)



<span style="background-color:#F5F5F5">**[결론]**</span>      
* 결론적으로, 우리는 **materials science corpus에 대해 pre-trained된 MatSciBERT**가 materials datasets에 대한  아래의 downstream task에 대해서 **SciBERT보다 더 나은 성능을 발휘**할 수 있음을 보여준다.       
     * NER    
     * abstract classification     
     * relation classification      
* 이는 **MatSciBERT가** computer science and biomedical domains로 pre train된 **SciBERT과 크게 다르다**는 것을 시사한다.     
* 특히, **각 과학 분야**는 **ontology, vocabulary, and domain-specific notations 측면에서 상당한 가변성**을 보인다.     
따라서 **과학 문헌 내에서도 도메인별 언어 모델의 개발**은 문헌에서 텍스트 마이닝 및 정보 추출과 관련된 다운스트림 작업의 **성능을 크게 향상**시킬 수 있다




----


# Applications in materials domain



이제, 우리는 재료 과학에서 MatSciBERT의 **potential areas of application**에 대해 논의한다.    



<span style="background-color:#F5F5F5">**[문서분류(Document classification)]**</span>      
* materials 관련 주제로 많은 수의 manuscripts가 출판되었고, 그 수는 기하급수적으로 증가하고 있다.    
**주어진 주제와 관련된 원고를 식별**하는 것은 어려운 작업이다.      
* **기존 방식**:  frequency-inverse document frequency (TF-IDF), Word2Vec     
⚠️ 이러한 접근 방식은 단어를 직접 벡터화하며 **문맥에 민감하지 않다**.      
**eg)** “flat glass”, “glass transition temperature”, “tea glass” 라는 문구에서 "glass"라는 단어는 매우 다른 의미로 사용되는데 위의 모델로는 이 의미차이 파악이 힘들다.        
* **MatSciBERT는 주제를 효과적으로 분류하여 개선된 주제 분류를 가능**하게 할 것이다.       
➡ 이는 Table 4에서 제시된 이진 분류 결과에서 명백히 보여준다.       
* 여기서 우리는 MatSciBERT(96.22%)를 사용하여 얻은 정확도가 풀링 기반 BiLSTM 모델(91.44%)을 사용하여 얻은 결과보다 상당히 높은 것으로 나타났다.      
* 이 접근법은 문헌에서 문서를 정확하게 분류하기 위해 더 큰 abstracts 집합으로 확장될 수 있다



<span style="background-color:#F5F5F5">**[주제 모델링(Topic modeling)]**</span>      
* 이는 **유사한 주제에 속하는 문서를 함께 그룹화**하는 unsupervised approach다.      
* **기존 방식:** TF-IDF 또는 Word2Vec과 함께  latent Dirichlet allocation (LDA)과 같은 알고리즘 사용     
➡ 동일하거나 의미적으로 유사한 단어를 가진 문서를 함께 클러스터링한다.      
⚠️ **문맥을 고려하지 않고** 클러스터링을 위해 순전히 단어 빈도(TF-IDF) 또는 단어 임베딩(Word2Vec)에 의존함.        
* **MatSciBERT에서 학습한 context-aware embeddings**을 사용하면 **Topic modeling task를 크게 향상**시킬 수 있다.      
* **preliminary study:**     
 glasses, ceramics에 대한  in-house corpus of abstracts에 MatSciBERT를 사용하여 주제 모델링을 수행한다.     
 이는 아래와 같은 순서로 진행된다.     
    * **1)** 우리는 MatSciBERT를 사용하여 **각 abstracts에 대한 ```[CLS]``` 토큰의 출력 임베딩**을 얻는다.       
    * **2)** 또한, 이러한 임베딩은 [UMAP algorithm](https://direct.mit.edu/neco/article/33/11/2881/107068/Parametric-UMAP-Embeddings-for-Representation-and) 을 사용하여 2차원으로 투영한다.         
    * **3)** 그리고 이렇게 투영된 것을 [k-means algorithm](https://ko.wikipedia.org/wiki/K-%ED%8F%89%EA%B7%A0_%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98)를 사용하여 클러스터링한다.          
    * **4)** 동일한 클러스터에 속하는 모든 abstracts을 연결하고 각 cluster/topic에 대해 가장 자주 사용하는 단어를 계산한다.         



<details>
<summary>📜 Supplementary Table 5 and 6</summary>
<div markdown="1"> 
 
Supplementary Tables 5 and 6는 LDA and MatSciBERT로 topic modelling한 결과를 보여준다. 


각각 LDA와 MatSciBERT를 사용하여 얻은 상위 10개 topic를 보여준다.    
각 topic과 관련된 상위 10개 키워드도 표에 제공한다.     

**MatSciBERT 기반 주제 모델링의 주제와 키워드가** LDA에서 얻은 것보다 **더 일관성이 있다**는 것을 관찰한다. 
  


**[Supplementary Table 5: LDA]**   
* 키워드와 관련된 실제 주제는 그다지 관련있지 않다.  
* LDA의 Topic 9에는 프랑스어 키워드가 포함되어 있어 주제가 프랑스 출판물을 대표한다는 것을 시사한다.     
* 마찬가지로, 주제 5와 주제 3에는 주제를 명확하게 나타내지 않는 몇 가지 일반 키워드가 있다.        
![image](https://user-images.githubusercontent.com/76824611/226347675-a3397532-13ca-4ebc-8f6f-7d7ae182dca7.png)




**[Supplementary Table 6: MatSciBERT]**   
* MatSciBERT가 얻은 키워드는 도메인 전문가가 주제를 잘 식별할 수 있게 한다.    
* MatSciBERT는 topic modeling에 사용될 수 있으므로 고려된 문헌에서 다루는 주제에 대한 광범위한 개요를 제공한다.
![image](https://user-images.githubusercontent.com/76824611/226347755-4dc95ef7-7d44-4608-81dd-96f42124aef8.png)




 
</div>
</details>



<span style="background-color:#F5F5F5">**[이미지에서 정보 추출(Information extraction from images)]**</span>      
* 이미지는 materials의 구조와 특성에 관한 많은 양의 정보를 담고 있다.      
관련 이미지를 식별하는 proxy는 모든 이미지의 캡션을 통과하는 것이다      
그러나 각 캡션에는 여러 entitiy가 포함될 수 있으며, 관련 키워드를 식별하는 것은 어려운 작업일 수 있다.      
이 정도로 NER에서 fine-tuning된 MatSciBERT는 **그림 캡션에서 정보를 추출하는 데 매우 유용한 도구**가 될 수 있다.
* 여기서, 우리는 Matscholar NER 데이터 세트에서 fine-tuning된 MatSciBERT를 사용하여 [Venugopal et al](https://www.sciencedirect.com/science/article/pii/S2666389921001239)이 사용한 그림 캡션에서 entitiy를 추출했다.     
구체적으로, entities는 inorganic glasses과 관련된 주제에 대한 약 110,000개의 이미지 캡션에서 추출되었다. MatSciBERT를 사용하여 DSC(샘플 기술자)로 87,318개 엔티티, APL(응용)로 10,633개 엔티티, MAT(무기재료)로 145,324개, PRO(재료 특성)로 76,898개, CMT(특성화 방법)로 73,241개, SMT(합성 방법)로 33,426개, SPL(대칭/상 라벨)로 2676개 엔티티를 얻었다. 그림 3은 Matscholar 데이터 세트에서 제안된 7개 범주에서 추출된 상위 10개 엔티티를 보여준다. 각 범주와 관련된 상위 개체는 코팅(응용), XRD(특성화), 유리(샘플 설명자, 무기재료), 조성(재료 특성), 열(합성 방법) 및 육각형(대칭/상)입니다. 각 범주와 관련된 추가 세부 정보는 이러한 명명된 엔티티에서 얻을 수도 있습니다. 각각의 캡션은 하나 이상의 엔티티와 연관될 수 있다는 것에 유의해야 한다. 이러한 엔티티는 "코팅에 사용되는 안경의 XRD 측정 또는 "도핑된 안경의 방출 스펙트럼" 또는 "Ag를 포함한 생체 유리의 SEM 이미지"와 같은 특정 쿼리에 대한 관련 이미지를 얻는 데 사용될 수 있다.



또한, 그림 4는 Venugopal et al. (2021)10의 해당 수동 주석과 함께 이미지 캡션에서 선택된 캡션 중 일부를 보여준다. 각 캡션에 태그를 할당하는 작업은 인간 전문가들에 의해 수행되었다. 이전 작업에서는 이미지 캡션당 하나의 단어만 할당되었습니다. MatSciBERT NER 모델을 사용하여 선택한 5개의 캡션에 대해 여러 엔티티가 추출된다는 것을 보여준다. 이는 본 연구에서 제안된 LM을 사용하여 캡처할 수 있는 많은 양의 정보를 보여준다.






Here, we extracted entities from the figure captions used by
Venugopal et al. (2021)10 using MatSciBERT finetuned on the
Matscholar NER dataset. Specifically, entities were extracted from
~110,000 image captions on topics related to inorganic glasses.
Using MatSciBERT, we obtained 87,318 entities as DSC (sample
descriptor), 10,633 entities under APL (application), 145,324 as
MAT (inorganic material), 76,898 as PRO (material property),
73,241 as CMT (characterization method), 33,426 as SMT (synthesis
method), and 2,676 as SPL (symmetry/phase label). Figure 3 shows
the top 10 extracted entities under the seven categories proposed
in the Matscholar dataset. The top entities associated with each of
the categories are coating (application), XRD (characterization),
glass (sample descriptor, inorganic material), composition (material property), heat (synthesis method), and hexagonal (symmetry/
phase). Further details associated with each category can also be
obtained from these named entities. It should be noted that each
caption may be associated with more than one entity. These
entities can then be used to obtain relevant images for specific
queries such as “XRD measurements of glasses used for coating
or “emission spectra of doped glasses”, or “SEM images of
bioglasses with Ag”, to name a few.



Further, Fig. 4 shows some of the selected captions from the
image captions along with the corresponding manual annotation
by Venugopal et al. (2021)10. The task of assigning tags to each
caption was carried out by human experts. Note that only one
word was assigned per image caption in the previous work. Using
the MatSciBERT NER model, we show that multiple entities are
extracted for the selected five captions. This illustrates the large
amount of information that can be captured using the LM
proposed in this work.




(iv) Materials caption graph: In addition to the queries as
mentioned earlier, graph representations can provide in-depth
insights into the information spread in figure captions. For
instance, questions such as “which synthesis and characterization
methods are commonly used for a specific material?”, “what are
the methods for measuring a specific property?” can be easily
answered using knowledge graphs. Here, we demonstrate how
the information in figure captions can be represented using
materials caption graphs (MCG). To this extent, we first randomly
select 10,000 figure captions from glass-related publications.
Further, we extract the entities and their types from the figure
captions using the MatSciBERT finetuned on Matscholar NER
dataset. For each caption, we create a fully connected graph by
connecting all the entities present in that caption. These graphs
are then joined together to form a large MCG. We demonstrate
some insights gained from the MCGs below.


Figure 5 shows two subsets of graphs extracted from the MCGs.
In Fig. 5a, we identified two entities that are two-hop neighbors,
namely, Tg and anneal. Note that these entities do not share an
edge. In other words, these two entities are not found
simultaneously in any given caption. We then identified the
intersection of all the one-hop neighbors of both the nodes and
plotted the graph as shown in Fig. 5a. The thickness of the edge
represents the strength of the connection in terms of the number
of occurrences. We observe that there are four common one-hop
neighbors for Tg and anneal, namely, XRD, doped, glass, and
amorphous. This means that these four entities occur in captions
along with Tg and anneal, even though these two entities are not
directly connected in the captions used for generating the graph.
Figure 5a suggests that Tg is related to glass, amorphous, and
doped materials and that these materials can be synthesized by
annealing. Similarly, the structures obtained by annealing can be
characterized by XRD. From these results, we can also infer that Tg
is affected by annealing, which agrees with the conventional
knowledge in glass science.








Similarly, Fig. 5b shows all the entities connected to the node
XRD. To this extent, we select all the captions having XRD as CMT.
After obtaining all the entities in those captions, we randomly
sample 20 pairs and then plotted them as shown in Fig. 5b. Note
that the number of edges is 18 and the number of nodes is 19
because of one pair being (XRD, XRD) and two similar pairs (XRD,
glass). The node color represents the entity type, and the edge
width represents the frequency of the pair in the entire database
of entities extracted from the captions where “XRD” is present.
Using the graph, we can obtain the following information





1. XRD is used as a characterization method for different
material descriptors like glass, doped materials, nanofibers,
and films.

2. Materials prepared using synthesis methods (SMT) like
aging, heat-treatment, and annealing are also characterized
using XRD.

3. While studying the property (PRO) glass transition temperature (Tg), XRD was also performed to characterize the
samples.

4. In the case of silica glass ceramics (SGCs), phosphor, and
phosphor-in-glass (PiG) applications (APL), XRD is used
as CMT.

5. For different materials like ZnO, glasses, CsPBr3, yttria
partially stabilized zirconia (YPSZ), XRD is a major CMT
which is evident from the thicker edge widths.


Note this information covers a wide range of materials and
applications in materials literature. Similar graphs can be
generated for different entities and entity types using the MCG
to gain insights into the materials literature.




(v) Other applications such as relation classification: MatSciBERT
can also be applied for addressing several other issues such as
relation classification and question answering. The relation
classification task demonstrated in the present manuscript can
provide key information regarding several aspects in materials
science which are followed in a sequence. These would include
synthesis and testing protocols, and measurement sequences. This
information can be further used to discover an optimal pathway
for material synthesis. In addition, such approaches can also be
used to obtain the effect of different testing and environmental
conditions, along with the relevant parameters, on the measured
property of materials. This could be especially important for those
properties such as hardness or fracture toughness, which are
highly sensitive to sample preparation protocols, testing conditions, and the equipment used. Thus, the LM can enable the
extraction of information regarding synthesis and testing conditions that are otherwise buried in the text


At this juncture, it is worth noting that there are very few
annotated datasets available for the material corpus. This
contrasts with the biomedical corpus, where several annotated
datasets are available for different downstream tasks such as
relation extraction, question-answering, and NER. While the
development of materials science specific language model can
significantly accelerate the NLP-related applications in materials,
the development of annotated datasets is equally important for
accelerating materials discovery.




In conclusion, we developed a materials-aware language model,
namely, MatSciBERT, that is trained on materials science corpus
derived from journals. The LM, trained from the initial weights of
SciBERT, exploits the knowledge on computer science and
biomedical corpora (on which the original SciBERT was pretrained) along with the additional information from the materials
domain. We test the performance of MatSciBERT on several
downstream tasks such as document classification, NER, and
relation classification. We demonstrate that MatSciBERT exhibits
superior performance on all the datasets tested in comparison to
SciBERT. Finally, we discuss some of the applications through
which MatSciBERT can enable accelerated information extraction
from the materials science text corpora. To enable accelerated text
mining and information extraction, the pre-trained weights of
MatSciBERT are made publicly available at https://huggingface.co/
m3rg-iitd/matscibert.



----
----







