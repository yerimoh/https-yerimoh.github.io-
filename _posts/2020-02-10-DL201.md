---
title: "[23] CS231N: Lecture 3 Regularization and Optimization Regularization (1/2)"
date:   2020-02-10
excerpt: "Lecture 3 | Stochastic Gradient Descent, Momentum, AdaGrad, Adam, Learning rate schedules 요약"
category: [Deep Learning]
layout: post
tag:
- Deep Learning
order: 0

comments: true
---


# 목차
- [**손실함수**](#--손실함수--)
  * [손실함수 공식](#손실함수-공식)
- [**Multiclass SVM loss**](#--multiclass-svm-loss--)
  * [SVM Loss 작동 방식](#svm-loss-작동-방식)
  * [코드 구현](#코드-구현)
  * [예제 적용](#예제-적용)
  * [추가 질문](#추가-질문)
  * [개선: Regularization](#개선--regularization)
    + [Regularization의 종류](#regularization의-종류)
- [**Softmax Classifier**](#--softmax-classifier--)
  * [작동 방식](#작동-방식)
  * [예시 적용](#예시-적용)
  * [추가 질문](#추가-질문-1)
- [**SVM vs Softmax**](#--svm-vs-softmax--)







------

👀 , 🤷‍♀️, 📜    
위의 아이콘을 누르시면 코드, 개념 부가 설명을 보실 수 있습니다:)

------



[CS231N: Lecture 3](https://www.youtube.com/watch?v=h7iBpEHGVNc&list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk&index=3) 강의를 빠짐 없이 정리하였고, 어려운 개념에 대한 보충 설명까지 알기 쉽게 추가해 두었습니다. 


------
------




# **손실함수**
손실함수는 **"모델이 얼마나 잘 예측하지 못하는가"** 를 계산해주는 함수이다.     
* 즉, 우리 분류기가 얼마나 좋은지를 이야기해 주는 것이다.     
* 이것에 대해 알고리즘을 작성해서, 자동으로 어떤 W(모델의 가중치)가 최선인지 결정하도록 하는 것이다.     
* 우리는 모든 **특정 W(모델의 가중치)에 대해서 이 나쁨의 정도를 정량화**할 방법이 필요한데, 손실 함수는 W를 받아서, 점수를 보고 얼마나 정량적으로 나쁜지를 말해준다.          
* 일단 우리가 이 손실 함수 아이디어를 갖게 되면, 이것으로 우리는 주어진 어떤 W에 대해 얼마나 좋은지 나쁜지에 대해 정량화 할 수 있다     
* 정답에 오차가 있는가를 나타내 주는 함수, 오차를 나타내는 값으로 이 값이 **낮을수록 좋다**.      
* [더 알아보기](https://yerimoh.github.io/DL3/#%EC%86%90%EC%8B%A4-%ED%95%A8%EC%88%98loss-function)      

먼저 아래의 예를 보면,  
3개의 예제(입역 이미지)와 3개의 클래스(정답)가 있는 것을 알 수 있다.       
또한 나타나있는 값들은 모델이 그 클래스라고 예측한 값이다.       
![image](https://user-images.githubusercontent.com/76824611/169459704-a4f9d47d-f91e-49f3-93d1-2a1570ec9658.png)
그럼 이를 통해서 모델을 평가해보면,      
* **고양이:** 잘 예측 못함 (고양이 클래스(3.2)보다 자동차 클래스(5.1) 점수가 가장 높음)       
* **자동차:** 잘 예측함 (자동차 클래스(4.9) 점수가 가장 높음)      
* **개구리:** 심각하게 예측 못함 (개구리클래스의 점수(-3.1)가 가장 낮음)        

그런데 이렇게 각각을 개별로 보는 것은 모델을 평가하기에 한계가 있다.     

그러므로 이 이미지 분류를 위해 나쁨의 정도(손실)을 정량화할 기본적인 손실함수를 볼 것이다.


----

## 손실함수 공식   
그럼 위에서 언급한 손실함수를 정형화 해보겠다.    

**[데이터 셋]**        
먼저 아래와 같은 데이터 셋 주어진다고 있다고 해보자.    
![image](https://user-images.githubusercontent.com/76824611/169463981-79473e59-977a-4add-9e65-5a014b335b55.png)  
* x와 y로 이루어진 학습 데이터 셋을 가지고 있다고 가정함    
* **N:** 예제의 개수         
* **x:** 알고리즘으로의 입력(이미지 분류에서는 이미지의 픽셀 값)       
* **y:** 알고리즘이 예측하고 싶은 값(진짜 정답)(= 레이블, 타겟)     
CIFAR 10의 경우 정답 레이블이 10개 이므로 y는 0~9(혹은1~10)의 정수값을 갖는다.            


**[손실함수]**      
데이터 셋에 대한 손실은 예제에 다한 손실의 합으로 다음 공식과 같다.     
![image](https://user-images.githubusercontent.com/76824611/169467031-90e0c1a3-c57c-45b0-a39a-645ca80a0f54.png)
* **$$f():$$** 예측 함수  
   *  예제 x와 가중치 매트릭스 W를 받아서 y에 대한 예측 수행     
* **$$L_{i}$$**: 손실 함수       
   * 예측함수 f로부터 나오는 **예측 점수**와 **레이블 y의 참인 타겟을** 받아들여 모델의 손실 계산     
   * 학습 예제에 대해 그 예측이 얼마나 나쁜지에 대한 정량적인 값을 주는 함수임        
   * 계산 방법은 손실함수마다 다름
* **$$L$$**: 최종 손실값    
   * 우리의 데이터 셋 N개 예제에 걸쳐 전체 데이타 셋을 합친 것에 대한 이 손실들의 평균임.      



**[평가]**   
이 함수는 아주 일반적인 공식으로 Image classification 외에도 다양하게 확장 가능함.    
딥러닝 알고리즘의 목적은  X와 Y가 존재하고, 여러분이 만들 파라미터 W에 W가 얼마나 좋은지를 정량화하는 손실 함수를 만드는 것임      
W의 공간을 탐색하면서 의트레이닝 데이터의 Loss를 최소화하는 어떤 W를 찾게 될 것임.    


----
-----


# **Multiclass SVM loss**   
구체적인 손실 함수의 첫번째 예로, 이미지 분류로 작업하기 좋은 손실 함수임.    
이 손실함수의 기본 아이디어는 손실 $$L_i$$가 **$$y_i가$$ 참인 카테고리만 빼고** 모든 카테고리 **y에 대해서** 각 예제 하나하나에 대해 **손실 합**을 구하는 것이다.(이해 안되도 나중에 자세히 설명 할 것이다)

----


## SVM Loss 작동 방식    
"True인 카테고리" 를 제외한 "나머지 카테고리 Y"의 합을 구할 것이다.(맞지 않는 카테고리를 전부 합치는 것)      


1️⃣ **정답 점수와 오답 점수 비교**      
올바른 카테고리의 스코어와 올바르지 않은 카테고리의 스코어를 비교한다.      

2️⃣ **정답 점수+ margin점수가 더 큰 경우**   
만약 정답 카테고리 점수가 틀린 카테고리 점수보다 크다면(정답일 확률이 더 높으면), Loss = 0      
또한 마진이 있는 경우, 정답+ margin(이 예제에선 1)차이가 오답보다 크면(일정 오차 허용), Loss = 0     
위의 두 경우 모두 True인 스코어가 다른 false 카테고리보다 훨씬 더 크다는 것을 의미           


3️⃣ **오답점수가 더 큰 경우**            
(현재 카테고리의 점수 + 1) - (정답의 점수) 를 오차값(Loss)에 더해줌   


4️⃣ **이렇게 모든 카테고리를 돈다**     
정답을 제외한 모든 카테고리에 1,2,3을 적용한다.        
미지 내 정답이 아닌 카테고리의 모든 값들을 합치면 그 값이 바로 한 이미지의 최종 Loss가 된다.     

5️⃣ **평균**     
각 Loss의 평균을 구한다.     



<details>
<summary>📜 margin값인 + 1 을 사용하는 이유</summary>
<div markdown="1">

만약 현재 카테고리의 점수 그 자체를 비교한다면, 2등의 점수와 1등의 점수가 굉장히 **근사**하다 하더라도,     
**오차값은 무조건 0**, 즉 최고로 좋은 상태가 되어 있을 것이다.     
이는, 비록 정답은 맞혔다 하더라도, 운 좋게 맞췄다고 볼 수 있으므로 성능이 좋지 않다.       
그렇기 때문에, 더욱 확실히 정답을 맞히는 것을 목표로, +1을 더해주는 것이다.    
 
</div>
</details>  

---

## 식 정리      
위 과정을 반영한 수식을 보여주면,    
기본형은 위의 기본 손실함수와 같다.    
위의 기본형에 손실함수를 ```max()```로 구체화 한것이다
![image](https://user-images.githubusercontent.com/76824611/169474340-09dbf0fe-ead2-48f5-9d7f-cb2fe6aa4e14.png)


**[시각화]**      
또한 이 수식을 시각화하면,  
![image](https://user-images.githubusercontent.com/76824611/169476669-416c7244-2852-4296-a5b8-f6899c5ac508.png)
이 그래프는 hinge(경첩)(오른쪽 그림)과 비슷하다고 해서 hinge loss라고도 불린다.    
* **$$x$$축**: $$S_{Y_{i}}$$로 실제 정답 클래스의 스코어      
   * **$$S$$:** 분류기의 출력으로 나온 예측된 스코어      
   가령 1이 고양이고 2가 개면 $$S_{1}$$은 고양이 스코어 $$S_{2}$$는 개 스코어       
   * **$$Y_{i}$$**:  이미지의 실제 정답 카테고리(정답)      
   * **$$S_{Y_{i}}$$**: 트레이닝 셋의 i번째 이미지의 정답 클래스의 스코어      
* **$$y$$축**: Loss      
➡ 정답 카테고리의 점수가 올라갈수록 Loss가 선형적으로 줄어드는 것 확인 가능     
* **Safety margin**: 그래프에 표시된 1, 이 로스는 0이 된 이후에도 Safety margin 을 넘어설 때 까지 더 줄어듦   
➡ Loss가 0이 됐다는 건 클래스를 잘 분류했다는 뜻임       
 

----

## 코드 구현
Numpy를 사용하면 코드 몇줄이면 이 손실 함수를 코딩할 수 있다.     
여기 재미있는 기법을 하나 볼 수 있다.       
* ```margin[y] = 0```: max로 나온 결과에서 정답 클래스만 0으로 만들어 주는 것이다.       
➡ 이것은 굳이 전체를 순회할 필요가 없게 해주는 일종의 vectorized 기법이다.    
➡ 전체 합을 구할때 제외하고 싶은 부분만 0으로 만들어준다.    

```python
def L_i_vectorized(x, y, W):
  scores = W.dot(x)
  margins = np.maximum(0, scores - scores[y] + 1)
  margins[y] = 0
  loss_i = np.sum(margins)
  return loss_i
```

---

## 예제 적용
그렇다면 위의  Multiclass SVM loss을 우리 예제에 적용해 보겠다.    

우선 정답이 아닌 클래스를 순회합니다.

아래 예제를 보자.      

**1) cat 클래스 순회**   
* Cat은 정답 클래스이니, Car와  Flog 클래스를 순회한다.    
* **Car의 경우:** (Car 스코어) 5.1 - (Cat 스코어) 3.2 + 1(magin)을 계산하면 2.8이다.     
   * Car가 Cat보다 더 높으니까 Loss가 발생할 것이라는 것을 짐작 가능 하다.  
* **Flog의 경우:** (frog 스코어) -1.7 - (Cat 스코어)3.2 + 1(magin)을 계산하면 음수이다.        
   * 즉 음수일땐 0으로 대체된다 ```max(0, value)```      
* **고양이의 loss**     
    * 위의 계산을 합치면 2.9 + 0 = 2.9이다                
![image](https://user-images.githubusercontent.com/76824611/169480204-cca4768e-6d06-46a5-9e62-9e6ac597c359.png)

**2) Car, Flog 클래스 순회**      
* 1)과 같은 방법으로 순회하면 된다.    
* 계산과정은 똑같으므로 생략하겠다.    
![image](https://user-images.githubusercontent.com/76824611/169483469-3eb73cb8-e5ed-4b3f-84f6-a94b630629c0.png)  
* 계산 결과 우리가 처음에 직관으로 해석했던 것과 비슷한 결과()가 나왔다.    


**3) 최종 Loss 구하기**    
* 전체 트레이닝 셋의 최종 Loss는 각 트레이닝 이미지의 Loss들의 평균이므로 5.3정도 됨       
* L = (2.9 + 0 + 12.9)/3  = 5.27    


<details>
<summary>📜 Recap: 우리가 처음에 직관으로 해석했던 것</summary>
<div markdown="1">

* **고양이:** 잘 예측 못함 (고양이 클래스(3.2)보다 자동차 클래스(5.1) 점수가 가장 높음)       
* **자동차:** 잘 예측함 (자동차 클래스(4.9) 점수가 가장 높음)      
* **개구리:** 심각하게 예측 못함 (개구리클래스의 점수(-3.1)가 가장 낮음)    
 
</div>
</details>  


 


----


## 추가 질문   

**Q1:** **Car 스코어가 조금 변하면 Loss에는 무슨 일이 일어날까요?**      


<details>
<summary>📜 정답 보기</summary>
<div markdown="1">
  
Loss가 바뀌지 않음.    
다시 SVM loss를 상기해보면 이 loss는 오직 정답 스코어와 그 외의 스코어와의 **차이**만 고려함.       
따라서 이 경우에는 Car 스코어가 이미 다른 스코어들보다 **엄청 높기** 때문에 여기 스코어를 조금 바꾼다고 해도, 서로 간의 **간격(Margin)**은 여전히 **유지**될 것이고, 결국 Loss는 변하지 않는다.    
즉, 계속 0일 것이다.     
  
</div>
</details>  


**Q2:** **SVM Loss가 가질 수 있는 최댓/최솟값은?**      


<details>
<summary>📜 정답 보기</summary>
<div markdown="1">
  
**[최솟값 0]**     
정답 클래스의 스코어가 제일 크면 모든 트레이닝 데이터에서 loss가 0이 될테니까.    
또한 ```max(0, value)```이므로 0 밑으로 내려 갈 수 없다.          

**[최대값 무한대]**    
만약 정답 클래스 스코어가 엄청 낮은 음수 값을 가지고 있다고 생각해보면, 아마 Loss가 무한대 일 것임       
  
</div>
</details>  


 



**Q3:** **만약 모든 스코어 S가 거의 "0에 가깝고" 그리고 "값이 서로 거의 비슷하다면"Multiclass SVM에서 Loss가 어떻게 될 것 같습니까?**     


<details>
<summary>📜 정답 보기</summary>
<div markdown="1">
  
"클래스의 수 - 1"          
왜냐면 Loss를 계산할때 정답이 아닌 클래스를 순회합니다.      
즉 정답인 나 자신을 빼고 (-1) 순회하는 것이다.    

그렇다면 왜 클래스의 수냐? 이건 식을 보면 이해가 가능하다.    
위의 조건을 식에 대입해보면 ```max(0, 0에 가까운수 - 0에 가까운수 +1)```이다.    
게다가 값이 서로 비슷하므로 이 값은 ```max(0,1)``` 즉 1이 될 것이다.    
이는 클래스를 지날 떄 마다 1의 값을 얻는 다는 것이다.    
  
즉 이렇게 클래스의 수에 정답 값인 나 자신을 뺸 것이 적답이 되는 것이다.      
  
**[응용]**     
그렇다면 이 성질의 응용은 어떻게 할까?       
"디버깅 전략"으로 유용하다.     
여러분들이 이런 전략을 가지고 트레이닝을 시작한다면, 여러분들은 Loss가 어떻게 될지를 짐작할 수 있게 된다.     
➡  트레이닝을 처음 시작할때 Loss가 "클래스의 수 - 1"이 아니라면 아마 버그가 있는 것이고 고쳐야 할 것이다.    
  
  
  
</div>
</details>




**Q4:** **기존 SVM Loss는 정답인 클래스는 빼고 다 더했습니다. 그렇다면 정답인 것도 같이 더하면 어떻게될까요?**     


<details>
<summary>📜 정답 보기</summary>
<div markdown="1">
  
Loss에 1이 더 증가한다.         
왜냐하면 원래 값에 위의 질문과 같은 이유(```max(0, 정답-정답 +1)``` = ```max(0, 1)`` =1)로 그저 1만 더해질 뿐이며  값 자체의 의미는 차이가 없다(이경우에는 0이 아니라 1이 가장 낮은 값이므로 좋은 분류기겠다)         

그렇다면 우리가 정답 클래스만 빼고 계산하는 이유는?      
일반적으로 Loss가 0이 되야지만 일반적으로 Loss가 0이 되야지만 우리가 "아무것도 잃는 것이 없다"고 쉽게 해석할 수 있기 때문이다.            
Loss에 모든 클래스를 다 더한다고 해서 다른 분류기가 학습되는 것은 아니다.   
즉 그냥 0이 편하니까 관행이 되어버린 것이다.      
 
  
</div>
</details> 




**Q5:** **Loss에서 전체 합을 쓰는게 아니라 평균을 쓰면 어떻게 될까요?**      


<details>
<summary>📜 정답 보기</summary>
<div markdown="1">
  
영향을 미치지 않는다     
클래스의 수는 어짜피 정해져 있으니 평균을 취한다는건 그저 손실 함수를 리스케일 할 뿐이다.        
그러니 상관이 없을 것이다.      
단지 스케일만 변할 뿐이기 떄문이다.     
왜냐하면 우리는 스코어 값이 몇인지는 신경쓰지 않기 때문이다.         
  
  
</div>
</details> 



**Q6:** **Loss에서 전체 합을 쓰는게 아니라 제곱을 쓰면 어떻게 될까요?**      


<details>
<summary>📜 정답 보기</summary>
<div markdown="1">
  
결과는 달라질 것이다.          
제곱은 좋은것 과 나쁜것 사이의 트레이드 오프를 비 선형적인 방식으로 바꿔주는 것인데,         
일차방정식을 2차 방정식인 곡선으로 표현하는 것과 같다는 것이다.      
그렇게 되면 손실함수의 계산 자체가 바뀌게된다.          
실제로도 squared hinge loss를 종종 사용한다.        
이는 여러분들이 손실함수를 설계할때  쓸 수 있는 한가지 방법이 될 수 있다.       

만약 Loss에 제곱을 한다면 이제 "엄청 엄청 안좋은 것들" 은 정말로 "곱절로 안좋은 것" 이 된다.        
즉 훨씬 더 나빠진다는 것이다.     

반면에 hinge loss를 사용하게 되면.     
실제로 "조금 잘못된 것" 과 "많이 잘못된 것" 을 크게 신경쓰지 않게 되는 것이다.        
만약 "많이 잘못된 것" 이 있다면 우리는 Loss를 증가시키고 학습을 통해 Loss를 줄일 것인데,   
그 줄어드는 Loss의 량이 "조금 잘못된 것"이던  "많이 잘못된 것" 이던 큰 차이가 없을 것이다.     
  
**[손실함수의 선택]**     
둘 중 어떤 loss를 선택하느냐는 우리가 에러에 대해
얼마나 신경쓰고 있고, 그것을 어떻게 정량화 할 것인지에 달려있다.         
  
그리고 이 문제는 실제 여러분들이 손실함수를 만들때
고려해야만 하는 것입이다.    
  
왜냐하면 손실 함수라는 것이 여러분이 여러분들의 알고리즘에게    
"어떤 에러를 내가 신경쓰고 있는지" 그리고 "어떤 에러가 트레이드오프 되는 것인지" 를 알려주는 것이기 때문이다
  
그러니 실제로는 여러분들의 문제에 따라서 손실함수를
잘 설계하는 것은 엄청 중요하다고 할 수 있다.
  
</div>
</details> 




**Q7:** **W= 0인 정답을 찾았다고 해 보자. 이렇게 Loss가 0이 되게 하는 W가 유일하게 하나만 존재하는 것일까요?**   


<details>
<summary>📜 정답 보기</summary>
<div markdown="1">
  
당연히 아니다.          
정말 간단하게 생각해보면 찾은 w에 1,2,3,... 배를 해도 똑같이 0일 것이다.       
W=0 ➡  2W=0, 3W=0,... 이니까!       
그러므로 다른 w도 당연히 존재한다.        
특히나 좀 전에도 언급했듯이 W의 스케일은 변한다.          

W=0 ➡  2W=0의 경우를 조금 더 자세히 보면,        
만약 여러분에게 W와 2W가 있다면, 정답 스코어 와 정답이 아닌 스코어의 차이의 마진(margins)또한 두배가 될 것이다.       
그러니 모든 마진(margins)이 이미 1보다 더 크다면, 우리가 두배를 한다고 해도 여전히 1보다 클 것이고 Loss가 0 일 것이다.     
  
그런데 여기서 중요한점은 우리의 목표는 W= 0인 정답이 아니다.    
왜냐하면 이는 우리가 갖고있는 예제 데이터 셋(train dataset)에만 적합한 모델이기 때문이다.    
이는 오버피팅이라고 하는데 밑에서 구체적으로 설명하겠다.      
  
우리는 오버피팅의 문제가 있는 W= 0이 아닌 w가 0이 되는 근사값을 찾는 것이 목표이다.     
➡ 그 분류기는 테스트 데이터(test dataset)에 적용할 것이기 때문이다.      
  
</div>
</details>  




-----


## 개선: Regularization
마지막 질문의 문제인 **"우리의 목표는 W= 0인 정답이 아닌 w가 0이 되는 근사값을 찾는 것이다"** 를 자세히 설명해보고, 이에대한 해결책인 **정규화(Regularization)** 에 대해 자세히 보겠다.         


**[기존 Multiclass SVM의 문제점]**          
만약 우리가 아래와 같이 주어진 예제의 정답(동그라미)을 모두 지나는 완벽한 가중치(파란선)  W= 0을 발견했다고 해보자.      
위의 3문제를 다 맞춘 완벽한 가중치 말이다.      
![image](https://user-images.githubusercontent.com/76824611/169504084-f0ce92e8-09df-45ab-9efd-1a1b02b43c4e.png)

우리는 이 모델을 갖고 새로운 고양이, 자동차, 개구리를 봤을 때 알맞게 분류를 해야한다.     
그런데 새로운 그림들(test dataset)의 정답(네모)이 아래와 같이 분포되어있어 못 푸는 경우가 있을 수 있다.    
즉 학습데이터셋으로 훈련된 가중치가 **정규화(Regularization) 되지 않아**,   
학습데이터셋 자체의 문제만 풀수 있는 모델이였던 것이다.      
![image](https://user-images.githubusercontent.com/76824611/169504526-94f34a0a-358c-42fc-92da-f17b0494455f.png)

즉 우리는 이렇게 완벽하게 fit된  구불구불한 고차원의 W= 0(파란색 선)이 아닌 **W= 0에 근접한 정규화(Regularization)된** 가중치(초록색 직선)이 필요하다.      
즉 이렇게 정규화를 도와주는 식을 추가해야 test dataset(학습한 모델을 적용할 새로운 사진들)에 더 적합한 모델이 나오는 것이다.      
![image](https://user-images.githubusercontent.com/76824611/169504950-6aa155d9-6941-4e98-b29b-7e5b99698d86.png)


---


**[Multiclass SVM with Regularization]**       
![image](https://user-images.githubusercontent.com/76824611/169508548-68d3ae20-94e3-4931-a39a-b85a8591d40e.png)
* **Data Loss Term**          
  * 분류기가 트레이닝 데이터에 핏하게함     
  * 데이터 손실: 모델 예측은 학습 데이터와 맞아야 한다.       
* **Regularization**     
  * 정규화: 모델은 단순해야 테스트 데이터에서 동작한다는 원리로 추가     
  * Regularization은 대부분 R이라고 표현     
  *  λ(람다)  
      *  데이타 손실과 정규화 손실 간의 트래이드오프 (trade-off)의 정도를 정해줌    
      *  하이퍼파라미터로 이 모델을 실제로 훈련시킬 때 튜닝해야 하는 가장 중요한 것 중 하나임    

    
-----

### Regularization의 종류  

L2 regularization   
L1 regularization  
Elastic net (L1 + L2)   
Max norm regularization (might see later)   
Dropout (will see later)   
Fancier: Batch normalization, stochastic depth    

➕위의 개념들은 강의에서 자세히 나와있지 않아 추후에 더 자세히 추가하겠다➕


---
---


# **Softmax Classifier**
= Multinomial Logistic Regression      
그렇다면 또다른 손실함수를 소개해 보겠다.     
* Softmax Classifier는 딥러닝에 더 자주 쓰인다. [어떻게 쓰이는지 전체 맥락보기](https://yerimoh.github.io/DL2/)          
* 이 함수는 Multi-class SVM Loss에서 추출한 점수들의 추가적인 의미를 보여준다.       


**[Multi-class SVM Loss의 한계]**             
* 멀티클래스 SVM 손실에서는 이 점수에 대해 해석을 하지 않았다.      
* 우리가 분류를 할 때, 우리의 모델 f는 클래스에 대한 점수들인 10개의 숫자를 내 뱉고, 멀티클래스 SVM에선 이 점수에 대해선 별로 해석을 하지 않았다.       
* 우린 그냥 **참인 점수**를 원한다고 했고, **맞는 클래스**의 점수가 틀린 클래스보다 **커야 한다**고 했다.    
*  그 이상으론 이 점수들이 뭘 의미하는진 얘기하지 않았다.      



**[한계 makeup]**     
* 다항식 로지스틱 회귀 손실 함수에선, 이 점수들에 추가적인 의미를 부여한다.      
➡ 우리의 클래스에 대해 확률 분포를 계산하기 위해서 이 점수들을 사용할 것이다.    

-----

## 작동 방식 
우리는 소위 소프트맥스 (softmax) 함수를 쓸 거고, 우리의 모든 점수를 얻을 건데요.    

1️⃣ **지수화**      
![image](https://user-images.githubusercontent.com/76824611/169520358-f4d1bec2-9dbb-4aec-901d-63501c417b97.png)
* s: 앞에서 우리가 설명한 ```f(x)```를 통해 만든 점수들이다.   
* e: exp로 그래프는 아래와 같다        
* ![image](https://user-images.githubusercontent.com/76824611/169520658-6bc2102b-9492-4473-bcc3-bd611600abb8.png)      
* 우리는 점수를 지수화해서 양수로 만든다.        
  


2️⃣ **정규화**    
![image](https://user-images.githubusercontent.com/76824611/169520784-b1a8f17d-809c-4a3b-90d7-fcff8ce804e7.png)
* 그리고 이를 정규화 한다       
* 이 소프트맥스 함수로 우리가 점수들을 통과시키면, 우리는 이 **확률 분포**를 얻게 된다.(식을 보면 확률을 구하는 식이다)    
   * 여기서 우리는 클래스들에 대한 확률을 얻는데, 확률은 0부터 1사이의 수이다.        
   * 그리고 모든 클래스에 걸친 확률의 합은 당연히 1이다.       



* ![image](https://user-images.githubusercontent.com/76824611/169516494-67f011c8-6023-4c59-a846-5f58be08114f.png)   
* 이 지수들의 합으로 그것들을 다시 정규화를 한다.    
* 여기서 정규화의 방법으로는 log를 쓴다.    
* log를 쓰는 이유   
   * log가 단조 증가 함수이기 때문이다.        
   * ![image](https://user-images.githubusercontent.com/76824611/169516968-21016654-9efb-430d-a560-9c7260b1a79f.png)     
   * log를 최대화시키는 것이 그냥 확률값을 최대화 시키는 것보다 쉬워서 log를 씁니다.     
   * 왜냐하면 정답에서 멀어지면 정답률이 급격하게 떨어지기 때문이다.        


3️⃣ **손실값으로 전환**        
![image](https://user-images.githubusercontent.com/76824611/169520844-bc5013a2-bcb3-44a6-9e3f-6c92ce22748c.png)
**log 추가**             
* log를 쓰는 이유   
    * log가 단조 증가 함수이기 때문이다.        
    * ![image](https://user-images.githubusercontent.com/76824611/169516968-21016654-9efb-430d-a560-9c7260b1a79f.png)     
    * log를 최대화시키는 것이 그냥 확률값을 최대화 시키는 것보다 쉬워서 log를 씁니다.     
    * 왜냐하면 정답에서 멀어지면 정답률이 급격하게 떨어지기 때문이다.        

**(-)추가**      
* 그런데 위의 값은 "정답값"을 보여주는 것이다.     
* log 그래프만 봐도 알겠지만 정답일수록 그래프가 증가(점수가 증가)한다.    
* 그런데 우리는 손실값이 필요한 것이므로 위의 식에 (-)를 붙여준다.     
* 그렇게 되면 최종 값이 나온다.       
* -log(정답클래스확률)이 되는 것이다.    
   * 정답값일수록 loss값이 낮아지는 것을 확인할 수 있다(손실함수 목표 달성)      
   ![image](https://user-images.githubusercontent.com/76824611/169517798-cf823e1b-1ebb-4e19-b6ff-fa6c6a54453e.png)     
   * 즉 log가 얼마나 좋은지(점수)였으면 -log는 얼마나 구린지(loss, 손실)를 보여준다     


**[요약]**        
스코어가 있으면, softmax를 거치고, 나온 확률 값에 -log를 추가     
![image](https://user-images.githubusercontent.com/76824611/169518192-acad5503-cb67-40eb-8730-a0d7b42ce3d0.png)



----


## 예시 적용
아까전의 3개의 예제 중 고양이만 보겠다.   

**0) setting**     
* 우리는 선형 분류기로부터 나온 고양이에 대한 3개의 점수가 있다.      
* 이 점수들은 SVM 손실에서와 같다.      
* 그러나 이제 이 점수들을 그냥 손실 함수에 넣지 않을 것이다.     
![image](https://user-images.githubusercontent.com/76824611/169522003-34dc12c0-1298-46ef-9a63-c2b01fbcfd65.png)


1️⃣ **지수화**     
* 모두 지수화해서 모두 양수로 만든다
![image](https://user-images.githubusercontent.com/76824611/169522108-788374b7-79d0-4ff7-9ff8-5338af1c8af8.png)


2️⃣ **정규화**    
* 이걸 정규화해서 모두 더하면 1이 되도록 한다
![image](https://user-images.githubusercontent.com/76824611/169522221-c1cf31c6-7ebf-43b7-8bd3-68c64cd314ce.png)

3️⃣ **손실값으로 전환**    
* 그럼 우리 손실은 참인 클래스의 음수 로그가 된다.    
* 이게 소프트맥스 손실(다항 로지스틱 회귀)이다.      
![image](https://user-images.githubusercontent.com/76824611/169522431-1c1ff000-39f2-442e-863c-0e8cda9951ab.png)


-----

## 추가 질문
우리는 멀티클래스 SVM에 대해 직관을 얻도록 몇가지 질문을 했었는데,      
소프트맥스 손실와 대조해 보기 위해 같은 질문 몇 개를 생각해보자.     

 
**Q1:** **softmax loss의 최댓값과 최솟값을 얼마일까요?**      


<details>
<summary>📜 정답 보기</summary>
<div markdown="1">
  
**[최솟값은 0]**    
확률 분포를 한번 생각해 보자면, 우리는 정답 클래스의 확률은 1이되길 원하고,    
정답이 아닌 클래스는 0 이 되길 원한다.     
이런 식으로 생각해보면, log안에 있는 어떤 값은 결국 1이 되어야 한다.     
즉, 정답 클래스에 대한 Log 확률이기 때문에 Log(1) = 0 이고, -log(1) 또한 0이다.       
그러므로 고양이를 완벽히 분류했다면 Loss는 0이 될 것이다.      
  
그렇다면 Loss가 0이 되려면 실제 스코어는 어떤 값이어야 할까?    
아마 정답 스코어는 거의 무한대에 가깝게 극단적으로 높아야 할 것이다.
여기에서는 지수화를 하고 정규화를 하기 때문에,   
정답 클래스의 스코어는 +무한대 가 되어야 하고, 나머지는 -무한대 가 되어야 한다.      
컴퓨터는 무한대 계산을 잘 못하기 때문에,     
Loss가 0인 경우는 절대 없을 것이다.(유한 정밀도 때문에)      
  
하지만 이론적 해석을 가미하면      
0 은 "이론적으로 최소 Loss이다" 라고 보면 된다.     
  

**[최댓값은 무한대]**   
최대 손실은 최댓값이 없다.    
만약 정답 클래스의 확률이 0이고, 거기 -log를 취하면 [-log(0)],    
log(0)는 음의 무한대가 되고 따라서 -log(0)는 양의 무한대가 된다.     
하지만 이러한 경우도 위와 같은 이유로 발생하진 않지만 이론적으로 무한대라고 본다.     
  
의미를 더 잘 이해 시키기 위해 그래프를 참고하자.   
  
**점수 그래프(log)**    
![image](https://user-images.githubusercontent.com/76824611/169523586-e65fc2a1-512b-4dd2-bd43-970ab950239d.png)

**손실 그래프(-log)**
![image](https://user-images.githubusercontent.com/76824611/169523608-5ee7cd7b-0899-41d8-ae8c-df7fa8e321ea.png)
  
 
  
</div>
</details>  


**Q2:** **만약 S가 모두 0 근처에 모여있는 작은 수일때 Loss는 어떻게 될까요?**      


<details>
<summary>📜 정답 보기</summary>
<div markdown="1">

$$log(1/모든 클래스의 수)$$가 된다.     
c = 모든 클래스의 수라고 할 때,       
log는 분모와 분자를 뒤집을 수 있으니까 -log(1/C)는 log(C)가 된다.      
  
**[이용]**   
softmax를 사용할 때 첫 번째 interation에서 해볼만한 아주 좋은 디버깅 전략이다.     
log(c)가 아니면 뭔가 잘못된 것이다.           


  
</div>
</details>  



-----
-----


# **SVM vs Softmax**
Linear classification의 설정은 둘다 같은 조건이라는 전제 하에 두 손실함수를 비교해보자.     

**손실 함수의 차이점**: 바로 "얼마나 오차 값이 큰지" 를 측정하기 위해 **스코어를 해석하는 방식**이 조금 다르다.      
* **SVM:** 정답 스코어와, 정답이 아닌 스코어 간의 마진(margins)을 신경씀.     
* **softmax (crossentropy):**  확률을 구해서 -log(정답클래스) 에 신경씀.        




**[multi-class SVM loss]**      
* car클래스에서 car의 스코어가 다른 클래스보다 **훨씬 높았**음.      
* 그래서 **car스코어를 조금 바꾼**다고 해서 SVM Loss가 **변하지 않음**.    
➡ SVM loss는 오직 **정답**과 그 외 **클래스의 마진이 얼마나** 되는지 에만 관심이 있기 때문             

**[softmax loss]**       
* **정답 스코어가 충분히 높고**, 다른 클래스 스코어가 충분히 낮은 상태에서의 처리는 다음과 같음             
* softmax는 최대한 **정답 클래스에 확률을 몰아 넣**으려고 할 것이고,    
* 정답 클래스는 무한대로, 그 외의 클래스는 음의 무한대로 보내려 할 것임.           
➡ 언제나 확률은 1로 만드려고 노력하기 때문(하나가 크면 다른걸 적게 해야 함)      

즉,   
* **multi-class SVM loss:** 일정 선(margins)을 넘기만 하면 더이상 성능 개선에 신경쓰지 않음      
* **softmax loss**: softmax는 지속적으로 성능을 높이려 할 것임.      



-----

다음 포스트,  


[[23] CS231N: Lecture 3 Regularization and Optimization Regularization (2/2) 보러가기](https://yerimoh.github.io/DL202/)   









