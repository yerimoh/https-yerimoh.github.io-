---
title: "Named Entity Recognition and Normalization Applied to LargeScale Information Extraction from the Materials Science Literature 정리"
date:   2023-03-25
excerpt: "Named Entity Recognition and Normalization Applied to LargeScale Information Extraction from the Materials Science Literature paper review"
category: [Paper]
layout: post
tag:
- Paper
order: 0

comments: true
---



**[원 논문]**     
[Named Entity Recognition and Normalization Applied to LargeScale Information Extraction from the Materials Science Literature](https://pubs.acs.org/doi/pdf/10.1021/acs.jcim.9b00470)



-----


# ABSTRACT
**[문제]**  
materials science articles의 수는 지난 수십 년 동안 여러 배로 증가했음.    
➡ <span style="background-color:#FFE6E6">**new result를** 이전에 확립된 문헌과 **연결**하는 데 있어 materials discovery pipeline의 주요 **병목 현상**이 발생</span>한다.    

**[본 논문의 해결]**    
* 이 문제에 대한 잠재적인 해결책은,  
게시된 기사의 <span style="background-color:#fff5b1">**구조화되지 않은 원시 텍스트**를 **프로그래밍 쿼리를 허용하는 구조화된 데이터베이스 항목에 매핑**하는 것</span>임.      
* 이를 위해 materials science literature에서 <span style="background-color:#fff5b1">대규모 정보 추출을 위해 **named entity recognition(NER)이 있는 text mining**을 적용</span>함    
* NER 모델은 아래의 materials science document에서 아래의 **summary-level information을 추출**하도록 훈련되었다.     
    * inorganic material mentions    
    * sample descriptors     
    * phase labels       
    * material properties and applications        
    * any synthesis and characterization methods 
* 본 논문의 classifier는 87%의 정확도(f1)를 달성하고 327만 개의 materials science abstracts에서 정보를 추출하는 데 적용된다.      
* 본 논문은 8천만 개 이상의 <span style="background-color:#fff5b1">**materials-science-related named entities를 추출**하고, 각 **abstract의 내용은 구조화된 형식의 데이터베이스 항목으로 표현**</span>된다.       
* 본 논문은 단순한 데이터베이스 쿼리를 사용하여, "meta-questions"(까다로운 질문)에 답변할 수 있음을 보여준다.     


**[구현 링크]**     
* 모든 데이터와 기능은 [Github](http://matscholar.com) 및 [웹사이트](https://github.com/materialsintelligence/matscholar)에서 무료로 풀어둠    


-----

# 1. INTRODUCTION

현재, historical materials science 지식의 대부분은 비정형 텍스트임    
또한 data도 너무 많아 materials scientists들은 평생 동안 이 정보의 일부만 액세스 가능함.     


**[NER(Named Entity Recognition)]**     
* [NER](https://wikidocs.net/30682)은 신문 기사와 같은 비정형 텍스트에서 사람의 이름과 지리적 위치와 같은 **정보를 추출**하기 위한 텍스트 마이닝 기술로 개발됨    
* 이러한 방식으로 문서는 **문서에 포함된 정보를 기반으로 구조화된 형식으로 표현**가능      



**[entity normalization]**         
* 의미: process에서 각 entity를 **고유한 데이터베이스 식별자에 매핑**하는 것         
예를 들어,         
<center> “age hardening” </center>     
<center> “precipitation hardening” </center>      
위의 두 문장은 같은 의미임. 이렇게 다른 표현들을 같은 식별자에 매핑하는 것                 
* ⚠️ 이러한 동등성을 인식하도록 기계를 훈련시키는 것은 매우 어려움        
* ⚠️ materials science domain에 사용할 수 있는 resources가 없으며 entity normalization는 아직 보고되지 않음      




![image](https://user-images.githubusercontent.com/76824611/227841594-3b3396fb-d7a2-470c-9d5d-5b8e1b54abc3.png)



재료 과학 텍스트에서 요약 수준의 정보를 추출하려는 대규모 노력은 없었다.    
그러나 게시된 문서를 구조화된 데이터베이스 항목으로 표시한다면, Materials informatics researchers의 아래의 노력을 줄일 수 있다.      
* 수백 또는 수천 개의 materials에 대한 예측(관련논문 [1](https://journals.aps.org/prb/abstract/10.1103/PhysRevB.89.094104), [2](https://arxiv.org/pdf/1706.00192.pdf))               
* 출판된 문헌에 대한 large-scale questions       


**[본 논문]**      
* materials science 문헌에서 대규모 정보 추출을 위해 **entity normalization**와 함께 **NER을 적용**.      
* 327만 개 이상의  science journal articles에 정보 추출      
article의 abstract부분만 사용(가장 요약 되어있기 때문)      
* <span style="background-color:#fff5b1">**NER 모델**</span>     
    * 800개의 hand-annotated abstracts를 사용하여 훈련된 신경망임(overall f1 score of 87%)          
* <span style="background-color:#fff5b1">**Entity normalization**</span>     
    * **두 entities가 동의어인지 여부를 인식하는 방법을 학습**하는 supervised ML model사용 (f1 점수가 95%)          
    * Entity normalization는 **문서 쿼리에서 식별된 관련 항목의 수를 크게 증가**시킨다는 것을 발견했다.            
    * 각 **abstract**의 비정형 텍스트는 문서에 대한 **summary-level information**하는 **구조화된 데이터베이스 항목으로 변환**된다.            
* 위 두 방법으로 **large-scale information extraction**한 결과,       
researchers이 **이전에는 불가능했던 규모**로 출판된 문헌에 **액세스**하고 **활용**할 수 있는 방법을 보여준다.      
* 또한 다음 <span style="background-color:#fff5b1">**데이터 세트**를 공개</span>함    
    * **(i)** NER에 대한 교육 데이터로 사용할 [800 hand-annotated materials science abstracts](https://doi.org/10.6084/m9.figshare.8184428)          
    * **(ii)** named entities를 normalized 형태로 매핑하기 위한 세부 정보가 포함된 [JSON 파일](https://doi.org/10.6084/m9.figshare.8184365)             
    * **(iii)** extracted named entities, 3.2700만 개의 science articles에 대한 [corresponding digital object identifier (DOI)](https://doi.org/10.6084/m9.figshare.8184413)    
 * section 5에 요약된 것처럼 데이터와 훈련된 모델과 인터페이스하기 위한 공개 웹사이트와 API를 공개함     




---
---


# 2. METHODOLOGY

아래 그림은 named entity recognition에 대한 전체 Workflow임    
![image](https://user-images.githubusercontent.com/76824611/227841719-66adeaec-e0ea-4b61-ac09-ba777ba3cfa7.png)
**[STEP]**    
* **(i)** documents가 수집되어 corpus에 추가됨      
* **(ii)** 텍스트 preprocessed (tokenized and cleaned)       
* **(iii)** training 데이터의 경우, documents의 small subset에 레이블이 지정됨     
(SPL = symmetry/phase 레이블, MAT = 재료, APL = 응용 프로그램)         
* **(iv)** labeled documents는 레이블링되지 않은 텍스트에서 생성된 word embeddings(Word2vec)와 결합된 후,    
named entity recognition을 위한 neural network를 train시킴     
* **(v)** neural network에서 entities 추출     



※ Scikit-learn, Tensorflow, Keras python 라이브러리를 사용하여 훈련됨


## 2.1. Data Collection and Preprocessing. 

**[2.2.1 Document Collection]**     
* **materials science articles**(1900년에서 2018년 사이에 출판)의 **abstracts부분**을 text mining함     
* Elsevier’s Scopus에 의해 indexe된 1100개 이상의 관련 저널 목록을 만듦, 저널은 수집 사이트는 아래와 같음      
   * Scopus and ScienceDirect APIs 27    
   * the SpringerNature API,28     
   * web scraping for journals published by the Royal Society of Chemistry29       
   * Electrochemical Society.30     
* these article의 abstracts(associated metadata including title, authors, publication year,
journal, keywords, DOI, and url)은 각 고유한 ID를 할당받고 이중 MongoDB/ElasticSearch 데이터베이스에 개별 문서로 저장됨    
* 전체적으로 our corpus는 3.27 million abstracts를 포함한다.      







**[2.2.2. Text Preprocessing]**     
문서 전처리의 단계 아래와 같다.     
* **1)** ChemDataExtractor를 사용하여 토큰화 12     
   * **1-1)** raw text를 문장으로 분할    
   * **1-2)** 각 문장을 개별 토큰으로 분할하는 것을 포함함.      
* **2)** rule-based preprocessing steps       
   * 자세한 건 [Supporting information for](https://pubs.acs.org/doi/suppl/10.1021/acs.jcim.9b00470/suppl_file/ci9b00470_si_001.pdf)에 있음       
   * valid chemical formula로 식별된 토큰은 원소와 order of elements가 중요하지 않도록 정규화됨     
   (예: NiFe는 Fe50Ni50과 동일)    
   * Valence states of elements는 별도의 토큰으로 분할된다.(예: Fe(III)는 두 개의 별도 토큰, Fe와 (III)가 된다).       
   * 토큰이 화학식이나 원소 기호가 아니며, 첫 번째 문자만 대문자인 경우에는 단어를 소문자로 만듦.      
   * 단위가 있는 숫자는 종종 ChemDataExtractor를 사용하여 토큰화되지 않는 문제 존재             
   ➡ 처리 단계에서 공통 단위를 숫자에서 분할하고 모든 숫자를 특수 토큰 ```<nUm>```으로 변환하여 이 문제를 해결한다.     
   ➡ 이렇게 하면 단어 크기가 수만 개 줄어듦     


   

**[2.1.3. Document Selection]**     
* inorganic materials science 논문에 중점을 둠.(연구범위 밖 논문도 포함하긴함_       
* abstract에 꼭 merterial에 대한 용어가 하나 이상 언급되어야지 관련 논문이라고 간주함    
➡ 이러한 분류를 위해 NER 모델을 교육하기 전에 먼저 문서 선택을 위한 classifier를 교육함.    
* 논문 분류를 위한 classifier     
    * 이 모델은 abstract을 "관련" 또는 "관련 없음"으로 분류할 수 있는 이진 classifier다.     
    * train 데이터의 경우 무작위로 선택된 1094개의 abstract에 "관련" 또는 "관련 없음"이라는 레이블을 붙d인다.   
    * 레이블이 지정된 abstract는 classifier를 훈련하는 데 사용된다.      
    * 우리는  logistic regression에 기반한 linear classifier를 사용한   
    * 여기서 각 문서는  term frequency−inverse document frequency([tf−idf](https://wikidocs.net/31698)) 벡터로 설명된다.       
    * classifier가 5-fold cross-validation에서 89%accuracy($$f_1$$) 점수를 획득다.      
* 이렇게 구분해둔 meterial과 관련없는 paper에도 훈련하였다.    
➡ 이를 통해 현재 더 넓은 범위의 주제(예: 폴리머 문헌)에 최적화된 텍스트 마이닝 도구를 개발하고 있다.   


-----

   
   

## 2.2. Named Entity Recognition. 

NER을 사용하여 **문서를 요약**하는 데 사용할 수 있는,    
specific entity types을 추출하는 데 관심이 있다.       

현재까지 재료 과학에서 정보 표현을 위한 ontology 또는 schema를 정의하기 위한 [여러 노력](https://www.semanticscholar.org/paper/A-survey-on-knowledge-representation-in-materials-Zhang-Zhao/487255347e00dcfc252e966079d6a71fba87783e)이 있었다.      

본 연구에서는 각 문서에 대해 **연구된 내용**과 **연구 방법**을 알고자 한다.     

이 정보를 추출하기 위해 아래 **7가지 entity labels을 설계**한다.       
* 무기 재료(MAT)       
* 대칭/위상 레이블(SPL)     
* 샘플 설명자(DSC)     
* 재료 특성(PRO)     
* 재료 적용(APL)     
* 합성 방법(SMT)      
* 특성화 방법(CMT)    



이러한 labels의 선택은 잘 알려진 아래의 **materials science 사면체**에 의해 어느 정도 동기 부여된다.       
* "가공(processing)"     
* "구조(structure)"    
* "특성(properties)"     
* "성능(performance)" 


각 **태그에 대한 예**는 각 **태그에 주석을 달기 위한 규칙**에 대한 자세한 설명과 함께 [Supporting information(S.4)](https://pubs.acs.org/doi/suppl/10.1021/acs.jcim.9b00470/suppl_file/ci9b00470_si_001.pdf)에 제공된다.    

<details>
<summary>📜 Supporting information(S.4)</summary>
<div markdown="1">
   
The rules for annotating each entity type are shown below.

* **1. Material (MAT):**    
Any inorganic solid or alloy, any non-gaseous element (at RT),      
e.g., “BaTiO3”, “titania”, “Fe”.       
* **2. Symmetry/phase label (SPL):**       
Names for crystal structures/phases(정방구조 이런거),       
e.g., “tetragonal”, ‘fcc”, “rutile”, “perovskite”; or, any symmetry label such as “P bnm”, or “P nma”.    
* **3. Sample descriptor (DSC):**       
Special descriptions of the type/shape of the sample.(성질을 갖는 특이한 구조)         
Examples inlcude “single crystal”, “nanotube”, “quantum dot”.       
* **4. Property (PRO)**:     
Anything measurable that can have a unit and a value,(단위와 값을 가질 수 있는 측정 가능한 모든 것)      
e.g., “conductivity”, “band gap”;(전도성, 에너지갭 이런거)    
or, any qualitative property or phenomenon exhibited by a material,(물질에 의해 나타나는 모든 질적 특성 또는 현상)    
e.g., “ferroelectric”, “metallic”.     
* **5. Application (APL):**        
Any high-level application such as “photovoltaics(태양전지)”, or any specific device such as “field-effect transistor”.    
* **6. Synthesis method (SMT):**     
Any technique for synthesising a material,      
e.g., “pulsed laser deposition”, “solid state reaction”,      
or any other step in sample production such       
as “annealing” or “etching”.
* **7. Characterization method (CMT):**     
Any method used to characterize a material, experiment or theory:     
e.g., “photoluminescence”, “XRD”, ‘tight binding”, “DFT”.     
It can also be a name for an equation or model.     
such “Bethe-Salpeter equation”.  
   
   
   
Overall, we annotated 800 materials science abstracts. This consisted of 22,306 annotated
entities (out of 111380 tokens total).  
   
   
  
</div>
</details>  




위에서 설명한 태그 지정 체계를 사용하여 800개의 materials science abstracts에 **손으로 주석**을 달았다.     

우리는 이러한 abstracts에 주석을 달 수 있는 "정확한" 방법은 없다고 강조한다.      
그러나 레이블링 체계가 합리적이라는 것을 보장하기 위해 주석을단 재료공학자들과의 일치율을 파악한 결과 이는 87.4%였다.      
이 값은 두 주석자가 동일한 레이블을 할당한 토큰의 백분율로 계산되었다.    



주석의 경우 **IOB(Inside-Outside-Beginning)** 형식을 사용한다.   

예를 들어 아래와 같은 문장은 IOB로 아래와 같이 태깅한다.   



```python
Thin films of SrTiO3 were deposited     

# IOB tagging
(Thin; B-DSC)     ## DSC란 태그의 시작     
(films; I-DSC)    ## DSC란 태그의 안      
(of; O)           ## meterial entity과 상관없어서 outside     
(SrTiO3; B-MAT)   ## MAT란 태그의 시작       
(were; O)         ## meterial entity과 상관없어서 outside       
(deposited; O)    ## meterial entity과 상관없어서 outside     
```   
   
-----
   
## 2.3. Neural Network model. The neural network

**[본 모델 아키텍처의 base model]**        
* [[Lample 등의 아키텍처](https://arxiv.org/abs/1603.01360)](https://arxiv.org/abs/1603.01360)     
이 아키텍처의 개략도는 아래와 같다.    
![image](https://user-images.githubusercontent.com/76824611/228857748-f3d2cbbc-c1ac-41c3-a518-d6243eeb40d5.png)

본 모델의 **특징**은 아래와 같다.       



**[base model의 특징]**      
* **목표**    
**materials science knowledge이 인코딩되는 방식**으로 모델을 훈련하는 것이다.        
예를 들어 아래와 같은 것들을 가르치고 싶다는 것이다.           
```"alumina"```와 ```"SrTiO3"```라는 단어가 ```materials```를 나타냄      
```"sputtering"```과 ```"MOCVD"```는 ```synthesis methods```에 해당한다          
* **specific entity type에 해당하는 단어를 인식**하도록 기계에 가르치는 데 사용할 수 있는 **세 가지 주요 정보 유형**     
     * 1️⃣ 단어 표현 (word representation)     
     * 2️⃣ 로컬(문장 내) 문맥(local (within sentence) context)     
     * 3️⃣ 단어 모양 (word shape)    





1️⃣ **단어 표현 (word representation)**
* **단어 임베딩 사용:**   
   * 단어 임베딩은 각 단어를 고차원 공간에서 실수의 dense 벡터에 매핑한다.    
     유사한 의미를 가지거나 유사한 맥락에서 자주 사용되는 단어는 유사한 단어 임베딩을 가짐.     
   * 예를 들어, ```"sputtering"``` 및 ```"MOCVD"```와 같은 entities는 유사한 벡터 표현을 가질 것임.    
* train 중에, 모델은 이러한 단어 벡터를 ```synthesis methods```으로 연결하는 방법을 배움    
* 임베딩은 200차원이며 skip-gram 접근법을 기반으로 합니다.     
* 단어 임베딩 훈련에 대한 자세한 내용은 [Supporting Information(S.2)](https://www.semanticscholar.org/paper/A-survey-on-knowledge-representation-in-materials-Zhang-Zhao/487255347e00dcfc252e966079d6a71fba87783e)에 포함되어 있다.   




2️⃣ **로컬(문장 내) 문맥(local (within sentence) context)**        
* 모델은 문장을 단어의 시퀀스로 간주하고, 문장 내 각 단어의 로컬 컨텍스트를 고려한다.      
* 예를 들어, ```"The band gap of ___ is 4.5 eV"```라는 문장에서,   
 누락된 단어가 ```synthesis methods```이나 다른 entity가 아닌 ```material```라는 것이 문맥적으로 분명하다.      
* 이러한 context 정보를 포함하기 위해 sequence-to-sequence (many-to-many) 분류가 가능한 sequence 모델 유형인 **LSTM**을 사용     





3️⃣ **단어 모양 (word shape)**       
* 각 단어에 대한 **character-level 정보를 포함**함     
예를 들어, ```"SrTiO3"```와 같은 material formulas는 **대문자, 소문자 및 숫자 문자**를 **특정 순서로 포함**하는 **고유한 모양**을 가진다.     
이 단어 모양은 entity 분류에 도움이 되는 데 사용될 수 있다.    
* 마찬가지로 **prefixes와 suffixes**는 **entity 유형에 대한 유용한 정보를 제공**함.      
예를 들어, ```"strontium"```에서 suffix ```"ium"```은 일반적으로 원소 금속에 사용되므로,   
이 suffix가 있는 단어는 material 이름의 일부가 될 가능성이 높다.   
* 이 정보를 모델로 인코딩하기 위해 **character-level bidirectional LSTM을 사용**한다.         
**character-level bidirectional LSTM(100차원 벡터)의 최종 출력**은 **각 단어에 대한 단어 임베딩과 연결**됩니다.    
이러한 character-level LSTM의 inal vectors는 word representations으로 사용된다.   
<img width="277" alt="image" src="https://user-images.githubusercontent.com/76824611/228857841-d98ba989-9e8c-467f-8f3a-8e7d845edb83.png">  
* base 모델과 비교      
    * **word-level LSTM**(base 모델)의 경우 327만 개 이상의 abstracts에 대해 훈련된 **pretrained word embeddings을 사용**한다.    
    * **character-level LSTM**(현모델)의 경우 character embeddings은 pretrained되지 않지만 **모델 train 중에 학습**된다.      
* 모델의 출력 레이어는 일반적인 softmax layer가 아닌 **conditional random fields(CRF)** 분류기다.        
CRF는 sequence-level classifier이기 때문에 **출력 레이블의 강력한 상호 의존성을 더 잘 포착** 한다.        


---


   
## 2.4. Entity Normalization.    

After entity recognition, the final step is entity normalization. This is necessarily required as each entity may be written in numerous forms. For example, “TiO2”, “titania”, “AO2 (A = Ti)”, and “titanium dioxide” all refer to the same specific stoichiometry: TiO2. For document querying, it is important to store these entities in a normalized format, so that a query for documents that mention “titania” also returns documents that mention “titanium dioxide”. In order to normalize material mentions, we convert all material names into a canonical normalized formula. The normalized formula is alphabetized and divided by the highest common factor of the stoichiometry. In this way, “TiO2”, “titania”, and “titanium dioxide” are all normalized to “O2Ti”. In some cases, multiple stoichiometries are extracted from a single material mention; for example, “ZrxTi1−xO3 (x = 0, 0.5, 1)” is converted to “O2Ti”, “O4TiZr”, and “O2Zr”. When a continuous range is given, e.g, 0 ≥ x ≤ 1, we increment over this range in steps of 0.1. Material mentions are normalized using regular expressions and rule-based methods, as well as by making use of the PubChem lookup tables;37 final validity checks on the normalized formula are performed using the pymatgen library.38


entity recognition 후 마지막 단계는 **entity normalization**다.      
각 entity는 다양한 형태로 작성될 수 있기 때문에 필수적으로 필요합니다.   

예를 들어, ```"TiO2"```", ```"titania"```", ```"AO2(A = Ti)"``` 및 ```"titanium dioxide"```는 모두 **동일한  specific stoichiometry**을 나타낸다.     

문서 querying의 경우, ```"titania"```를 언급하는 문서에 대한 쿼리가 ```"이산화티타늄"```을 언급하는 문서도 반환하도록 표준화된 형식으로 이러한 엔티티를 저장하는 것이 중요합니다. 재료 언급을 정규화하기 위해 모든 재료 이름을 정규화된 공식으로 변환합니다. 정규화된 공식은 알파벳 순으로 표시되고 화학양론의 가장 높은 공통 인자로 나뉩니다. 이러한 방식으로 TiO2, 티타늄, 이산화 티타늄은 모두 O2Ti로 정규화됩니다. 예를 들어, ```"ZrxTi1-xO3(x = 0, 0.5, 1)"```를 ```"O2Ti```", "```O4TiZr"``` 및 ```"O2Zr"```로 변환하는 경우가 있습니다. 연속 범위(예: 0 µ x ≤ 1)가 주어지면 0.1 단계에서 이 범위에 걸쳐 증가합니다. 재료 언급은 정규식과 규칙 기반 방법을 사용하여 정규화되고 PubChem 조회 테이블을 사용하여 정규화됩니다. 정규화된 공식에 대한 37개의 최종 유효성 검사는 Pymatgen 라이브러리를 사용하여 수행됩니다.38


Normalization of other entity types is also crucial for comprehensive document querying. For example, “chemical vapor deposition”, “chemical-vapour deposition”, and “CVD” all refer to the same synthesis technique; i.e., they are synonyms for this entity type. In order to determine that two entities have the same meaning, we trained a classifier that is capable of determining whether or not two entities are synonyms.


다른 엔티티 유형의 정규화는 포괄적인 문서 쿼리에도 중요합니다. 예를 들어, "화학기상증착", "화학기상증착" 및 "CVD"는 모두 동일한 합성 기술을 나타냅니다. 즉, 이 엔티티 유형에 대한 동의어입니다. 두 엔티티가 동일한 의미를 가지고 있음을 결정하기 위해 두 엔티티가 동의어인지 여부를 결정할 수 있는 분류기를 훈련했습니다.


The model uses the word embeddings for each entity as features; after performing NER, each multiword entity is concatenated into a single word, and new word embeddings are trained such that every multiword entity has a single vector representation. Each synonym consists of an entity pair, so the features for the model are created by concatenating the word embeddings of the two entities in question. In addition to the word embeddings, which mostly capture the context in which an entity is used, several other handcrafted features are included (Supporting Information, S.5). To train the model, 10 000 entity pairs are labeled as being either synonyms or not (see the Supporting Information, S.6). Using this data, a binary random forest classifier is trained to be able to predict whether or not two entities are synonyms of one another.



이 모델은 각 엔티티에 대한 단어 임베딩을 특징으로 사용합니다. NER을 수행한 후, 각 다중 워드 엔티티는 단일 단어로 연결되고 새로운 단어 임베딩은 모든 다중 워드 엔티티가 단일 벡터 표현을 갖도록 훈련됩니다. 각 동의어는 엔터티 쌍으로 구성되므로 모델에 대한 피쳐는 해당 두 엔터티의 단어 임베딩을 연결하여 생성됩니다. 주로 엔티티가 사용되는 컨텍스트를 캡처하는 임베딩이라는 단어 외에도 몇 가지 다른 수작업 기능이 포함되어 있습니다(지원 정보, S.5). 모델을 교육하기 위해 10,000개의 엔티티 쌍은 동의어이거나 동의어가 아닌 것으로 레이블이 지정됩니다(지원 정보, S.6 참조). 이 데이터를 사용하여 이진 랜덤 포레스트 분류기는 두 엔티티가 서로 동의어인지 여부를 예측할 수 있도록 훈련됩니다.


Using the synonym classifier, each extracted entity can be normalized to a canonical form. Each entity is stored as its most frequently occurring synonym (we exclude acronyms as a normalized form); for example, “chemical vapor deposition”, “chemical-vapour deposition”, and “CVD” are all stored as “chemical vapor deposition”, as this is the most frequently occurring synonym that is not an acronym.

동의어 분류기를 사용하여 추출된 각 엔티티를 표준 형식으로 정규화할 수 있습니다. 각 엔티티는 가장 자주 발생하는 동의어로 저장됩니다(예: "화학기상증착", "화학기상증착" 및 "CVD"는 모두 "화학기상증착"으로 저장됩니다(예: "화학기상증착"은 약자가 아닌 가장 자주 발생하는 동의어입니다).
