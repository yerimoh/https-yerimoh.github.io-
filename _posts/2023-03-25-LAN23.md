---
title: "Named Entity Recognition and Normalization Applied to LargeScale Information Extraction from the Materials Science Literature 정리"
date:   2023-03-25
excerpt: "Named Entity Recognition and Normalization Applied to LargeScale Information Extraction from the Materials Science Literature paper review"
category: [Paper]
layout: post
tag:
- Paper
order: 0

comments: true
---



**[원 논문]**     
[SCIBERT: A Pretrained Language Model for Scientific Text](https://arxiv.org/pdf/1903.10676.pdf)

-----


# ABSTRACT
The number of published materials science
articles has increased manyfold over the past few decades.
Now, a major bottleneck in the materials discovery pipeline arises
in connecting new results with the previously established
literature. A potential solution to this problem is to map the
unstructured raw text of published articles onto structured
database entries that allow for programmatic querying. To this
end, we apply text mining with named entity recognition (NER)
for large-scale information extraction from the published
materials science literature. The NER model is trained to extract
summary-level information from materials science documents,
including inorganic material mentions, sample descriptors, phase
labels, material properties and applications, as well as any synthesis and characterization methods used. Our classifier achieves
an accuracy (f1) of 87%, and is applied to information extraction from 3.27 million materials science abstracts. We extract more
than 80 million materials-science-related named entities, and the content of each abstract is represented as a database entry in a
structured format. We demonstrate that simple database queries can be used to answer complex “meta-questions” of the
published literature that would have previously required laborious, manual literature searches to answer. All of our data and
functionality has been made freely available on our Github (https://github.com/materialsintelligence/matscholar) and website
(http://matscholar.com), and we expect these results to accelerate the pace of future materials science discovery


-----

# 1. INTRODUCTION
Presently, the vast majority of historical materials science
knowledge is stored as unstructured text across millions of
published scientific articles. The body of research continues to
grow rapidly; the magnitude of published data is now so large
that individual materials scientists will only access a fraction of
this information in their lifetime. With the increasing
magnitude of available materials science knowledge, a major
bottleneck in materials design arises from the need to connect
new results with the mass of previously published literature



Recent advances in machine learning and natural language
processing have enabled the development of tools capable of
extracting information from scientific text on a massive
scale.1−3 Of these tools, named entity recognition (NER),4 is
currently one of the most widely used. Historically, NER was
developed as a text-mining technique for extracting information, such as the names of people and geographic locations,
from unstructured text, such as newspaper articles.4 The task is
typically approached as a supervised machine learning
problem, in which a model learns to identify the keywords
or phrases in a sentence; in this way, documents may be
represented in a structured format based on the information
contained within them. In the past decade, NER has become
an important feature for text mining within the chemical
sciences.5,6


In addition to entity recognition, a major challenge lies in
mapping each entity onto a unique database identifier in a
process called entity normalization. This issue arises due to the
many ways in which a particular entity may be written. For
example, “age hardening” and “precipitation hardening” refer
to the same process. However, training a machine to recognize
this equivalence is especially challenging. A significant research
effort has been applied to entity normalization in the
biomedical domain; for example, the normalization of gene
names has been achieved by using external databases of known
gene synonyms.7 No such resources are available for the
materials science domain, and entity normalization has yet to
be reported.




In the field of materials science, there has been significant
effort to apply NER to extracting inorganic materials synthesis
recipes;8−11 furthermore, a number of chemistry-based NER
systems are capable of extracting inorganic materials
mentions.12−15 Some researchers have relied on chemical
NER in combination with lookup tables to extract mentions of
materials properties or processing conditions.16,17 However,
there has been no large-scale effort to extract summary-level
information from materials science texts. Materials informatics
researchers often make predictions for many hundreds or
thousands of materials,18,19 and it would be extremely useful
for researchers to be able to ask large-scale questions of the
published literature, such as, “For this list of 10 000 materials,
which have been studied as a thermoelectric, and which are yet
to be explored?” An experimental materials science researcher
might want to ask, “What is the most common synthesis
method for oxide ferroelectrics? And, give me a list of all
documents related to this query”. Currently, answering such
questions requires a laborious and tedious literature search,
performed manually by a domain expert. However, by
representing published articles as structured database entries,
such questions may be asked programmatically, and they can
be answered in a matter of seconds



In the present report, we apply NER along with entity
normalization for large-scale information extraction from the
materials science literature. We apply information extraction to
over 3.27 million materials science journal articles; we focus
solely on the article abstract, which is the most informationdense portion of the article and is also readily available from
various publisher application programming interfaces (e.g.,
Scopus). The NER model is a neural network trained using
800 hand-annotated abstracts and achieves an overall f1 score
of 87%. Entity normalization is achieved using a supervised
machine learning model that learns to recognize whether or
not two entities are synonyms with an f1 score of 95%. We find
that entity normalization greatly increases the number of
relevant items identified in document querying. The
unstructured text of each abstract is converted into a structured
database entry containing summary-level information about
the document: inorganic materials studied, sample descriptors
or phase labels, mentions of any material properties or
applications, as well as any characterization or synthesis
methods used in the study. We demonstrate how this type of
large-scale information extraction allows researchers to access
and exploit the published literature on a scale that has not
previously been possible. In addition, we release the following
data sets: (i) 800 hand-annotated materials science abstracts to
be used as training data for NER,20 (ii) JSON files containing
details for mapping named entities onto their normalized
form,21 and (iii) the extracted named entities, and corresponding digital object identifier (DOI), for 3.27 million materials
science articles.22 Finally, we have released a public facing
website and API for interfacing with the data and trained
models, as outlined in section 5.









































