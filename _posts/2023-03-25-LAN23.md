---
title: "Named Entity Recognition and Normalization Applied to LargeScale Information Extraction from the Materials Science Literature 정리"
date:   2023-03-25
excerpt: "Named Entity Recognition and Normalization Applied to LargeScale Information Extraction from the Materials Science Literature paper review"
category: [Paper]
layout: post
tag:
- Paper
order: 0

comments: true
---



**[원 논문]**     
[SCIBERT: A Pretrained Language Model for Scientific Text](https://arxiv.org/pdf/1903.10676.pdf)

-----


# ABSTRACT
**[문제]**  
materials science articles의 수는 지난 수십 년 동안 여러 배로 증가했음.    
➡ <span style="background-color:#FFE6E6">**new result를** 이전에 확립된 문헌과 **연결**하는 데 있어 materials discovery pipeline의 주요 **병목 현상**이 발생</span>한다.    

**[본 논문의 해결]**    
* 이 문제에 대한 잠재적인 해결책은,  
게시된 기사의 <span style="background-color:#fff5b1">**구조화되지 않은 원시 텍스트**를 **프로그래밍 쿼리를 허용하는 구조화된 데이터베이스 항목에 매핑**하는 것</span>임.      
* 이를 위해 materials science literature에서 <span style="background-color:#fff5b1">대규모 정보 추출을 위해 **named entity recognition(NER)이 있는 text mining**을 적용</span>함    
* NER 모델은 아래의 materials science document에서 아래의 **summary-level information을 추출**하도록 훈련되었다.     
    * inorganic material mentions    
    * sample descriptors     
    * phase labels       
    * material properties and applications        
    * any synthesis and characterization methods 
* 본 논문의 classifier는 87%의 정확도(f1)를 달성하고 327만 개의 materials science abstracts에서 정보를 추출하는 데 적용된다.      
* 본 논문은 8천만 개 이상의 <span style="background-color:#fff5b1">**materials-science-related named entities를 추출**하고, 각 **abstract의 내용은 구조화된 형식의 데이터베이스 항목으로 표현**</span>된다.       
* 본 논문은 단순한 데이터베이스 쿼리를 사용하여, "meta-questions"(까다로운 질문)에 답변할 수 있음을 보여준다.     


**[구현 링크]**     
* 모든 데이터와 기능은 [Github](http://matscholar.com) 및 [웹사이트](https://github.com/materialsintelligence/matscholar)에서 무료로 풀어둠    


-----

# 1. INTRODUCTION
Presently, the vast majority of historical materials science
knowledge is stored as unstructured text across millions of
published scientific articles. The body of research continues to
grow rapidly; the magnitude of published data is now so large
that individual materials scientists will only access a fraction of
this information in their lifetime. With the increasing
magnitude of available materials science knowledge, a major
bottleneck in materials design arises from the need to connect
new results with the mass of previously published literature



Recent advances in machine learning and natural language
processing have enabled the development of tools capable of
extracting information from scientific text on a massive
scale.1−3 Of these tools, named entity recognition (NER),4 is
currently one of the most widely used. Historically, NER was
developed as a text-mining technique for extracting information, such as the names of people and geographic locations,
from unstructured text, such as newspaper articles.4 The task is
typically approached as a supervised machine learning
problem, in which a model learns to identify the keywords
or phrases in a sentence; in this way, documents may be
represented in a structured format based on the information
contained within them. In the past decade, NER has become
an important feature for text mining within the chemical
sciences.5,6


In addition to entity recognition, a major challenge lies in
mapping each entity onto a unique database identifier in a
process called entity normalization. This issue arises due to the
many ways in which a particular entity may be written. For
example, “age hardening” and “precipitation hardening” refer
to the same process. However, training a machine to recognize
this equivalence is especially challenging. A significant research
effort has been applied to entity normalization in the
biomedical domain; for example, the normalization of gene
names has been achieved by using external databases of known
gene synonyms.7 No such resources are available for the
materials science domain, and entity normalization has yet to
be reported.




In the field of materials science, there has been significant
effort to apply NER to extracting inorganic materials synthesis
recipes;8−11 furthermore, a number of chemistry-based NER
systems are capable of extracting inorganic materials
mentions.12−15 Some researchers have relied on chemical
NER in combination with lookup tables to extract mentions of
materials properties or processing conditions.16,17 However,
there has been no large-scale effort to extract summary-level
information from materials science texts. Materials informatics
researchers often make predictions for many hundreds or
thousands of materials,18,19 and it would be extremely useful
for researchers to be able to ask large-scale questions of the
published literature, such as, “For this list of 10 000 materials,
which have been studied as a thermoelectric, and which are yet
to be explored?” An experimental materials science researcher
might want to ask, “What is the most common synthesis
method for oxide ferroelectrics? And, give me a list of all
documents related to this query”. Currently, answering such
questions requires a laborious and tedious literature search,
performed manually by a domain expert. However, by
representing published articles as structured database entries,
such questions may be asked programmatically, and they can
be answered in a matter of seconds



In the present report, we apply NER along with entity
normalization for large-scale information extraction from the
materials science literature. We apply information extraction to
over 3.27 million materials science journal articles; we focus
solely on the article abstract, which is the most informationdense portion of the article and is also readily available from
various publisher application programming interfaces (e.g.,
Scopus). The NER model is a neural network trained using
800 hand-annotated abstracts and achieves an overall f1 score
of 87%. Entity normalization is achieved using a supervised
machine learning model that learns to recognize whether or
not two entities are synonyms with an f1 score of 95%. We find
that entity normalization greatly increases the number of
relevant items identified in document querying. The
unstructured text of each abstract is converted into a structured
database entry containing summary-level information about
the document: inorganic materials studied, sample descriptors
or phase labels, mentions of any material properties or
applications, as well as any characterization or synthesis
methods used in the study. We demonstrate how this type of
large-scale information extraction allows researchers to access
and exploit the published literature on a scale that has not
previously been possible. In addition, we release the following
data sets: (i) 800 hand-annotated materials science abstracts to
be used as training data for NER,20 (ii) JSON files containing
details for mapping named entities onto their normalized
form,21 and (iii) the extracted named entities, and corresponding digital object identifier (DOI), for 3.27 million materials
science articles.22 Finally, we have released a public facing
website and API for interfacing with the data and trained
models, as outlined in section 5.









































