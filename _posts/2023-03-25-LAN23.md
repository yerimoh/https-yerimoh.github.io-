---
title: "Named Entity Recognition and Normalization Applied to LargeScale Information Extraction from the Materials Science Literature 정리"
date:   2023-03-25
excerpt: "Named Entity Recognition and Normalization Applied to LargeScale Information Extraction from the Materials Science Literature paper review"
category: [Paper]
layout: post
tag:
- Paper
order: 0

comments: true
---



**[원 논문]**     
[SCIBERT: A Pretrained Language Model for Scientific Text](https://arxiv.org/pdf/1903.10676.pdf)

-----


# ABSTRACT
**[문제]**  
materials science articles의 수는 지난 수십 년 동안 여러 배로 증가했음.    
➡ <span style="background-color:#FFE6E6">**new result를** 이전에 확립된 문헌과 **연결**하는 데 있어 materials discovery pipeline의 주요 **병목 현상**이 발생</span>한다.    

**[본 논문의 해결]**    
* 이 문제에 대한 잠재적인 해결책은,  
게시된 기사의 <span style="background-color:#fff5b1">**구조화되지 않은 원시 텍스트**를 **프로그래밍 쿼리를 허용하는 구조화된 데이터베이스 항목에 매핑**하는 것</span>임.      
* 이를 위해 materials science literature에서 <span style="background-color:#fff5b1">대규모 정보 추출을 위해 **named entity recognition(NER)이 있는 text mining**을 적용</span>함    
* NER 모델은 아래의 materials science document에서 아래의 **summary-level information을 추출**하도록 훈련되었다.     
    * inorganic material mentions    
    * sample descriptors     
    * phase labels       
    * material properties and applications        
    * any synthesis and characterization methods 
* 본 논문의 classifier는 87%의 정확도(f1)를 달성하고 327만 개의 materials science abstracts에서 정보를 추출하는 데 적용된다.      
* 본 논문은 8천만 개 이상의 <span style="background-color:#fff5b1">**materials-science-related named entities를 추출**하고, 각 **abstract의 내용은 구조화된 형식의 데이터베이스 항목으로 표현**</span>된다.       
* 본 논문은 단순한 데이터베이스 쿼리를 사용하여, "meta-questions"(까다로운 질문)에 답변할 수 있음을 보여준다.     


**[구현 링크]**     
* 모든 데이터와 기능은 [Github](http://matscholar.com) 및 [웹사이트](https://github.com/materialsintelligence/matscholar)에서 무료로 풀어둠    


-----

# 1. INTRODUCTION

현재, historical materials science 지식의 대부분은 비정형 텍스트임    
또한 data도 너무 많아 materials scientists들은 평생 동안 이 정보의 일부만 액세스 가능함.     


**[NER(Named Entity Recognition)]**     
* [NER](https://wikidocs.net/30682)은 신문 기사와 같은 비정형 텍스트에서 사람의 이름과 지리적 위치와 같은 **정보를 추출**하기 위한 텍스트 마이닝 기술로 개발됨    
* 이러한 방식으로 문서는 **문서에 포함된 정보를 기반으로 구조화된 형식으로 표현**가능      



**[entity normalization]**         
* 의미: process에서 각 entity를 **고유한 데이터베이스 식별자에 매핑**하는 것         
예를 들어,         
<center> “age hardening” </center>     
<center> “precipitation hardening” </center>      
위의 두 문장은 같은 의미임. 이렇게 다른 표현들을 같은 식별자에 매핑하는 것                 
* ⚠️ 이러한 동등성을 인식하도록 기계를 훈련시키는 것은 매우 어려움        
* ⚠️ materials science domain에 사용할 수 있는 resources가 없으며 entity normalization는 아직 보고되지 않음      




![image](https://user-images.githubusercontent.com/76824611/227841594-3b3396fb-d7a2-470c-9d5d-5b8e1b54abc3.png)



재료 과학 텍스트에서 요약 수준의 정보를 추출하려는 대규모 노력은 없었다.    
그러나 게시된 문서를 구조화된 데이터베이스 항목으로 표시한다면, Materials informatics researchers의 아래의 노력을 줄일 수 있다.      
* 수백 또는 수천 개의 materials에 대한 예측(관련논문 [1](https://journals.aps.org/prb/abstract/10.1103/PhysRevB.89.094104), [2](https://arxiv.org/pdf/1706.00192.pdf))               
* 출판된 문헌에 대한 large-scale questions       


**[본 논문]**      
* materials science 문헌에서 대규모 정보 추출을 위해 **entity normalization**와 함께 **NER을 적용**.      
* 327만 개 이상의  science journal articles에 정보 추출      
article의 abstract부분만 사용(가장 요약 되어있기 때문)      
* <span style="background-color:#fff5b1">**NER 모델**</span>     
    * 800개의 hand-annotated abstracts를 사용하여 훈련된 신경망임(overall f1 score of 87%)          
* <span style="background-color:#fff5b1">**Entity normalization**</span>     
    * **두 entities가 동의어인지 여부를 인식하는 방법을 학습**하는 supervised ML model사용 (f1 점수가 95%)          
    * Entity normalization는 **문서 쿼리에서 식별된 관련 항목의 수를 크게 증가**시킨다는 것을 발견했다.            
    * 각 **abstract**의 비정형 텍스트는 문서에 대한 **summary-level information**하는 **구조화된 데이터베이스 항목으로 변환**된다.            
* 위 두 방법으로 **large-scale information extraction**한 결과,       
researchers이 **이전에는 불가능했던 규모**로 출판된 문헌에 **액세스**하고 **활용**할 수 있는 방법을 보여준다.      
* 또한 다음 <span style="background-color:#fff5b1">**데이터 세트**를 공개</span>함    
    * **(i)** NER에 대한 교육 데이터로 사용할 [800 hand-annotated materials science abstracts](https://doi.org/10.6084/m9.figshare.8184428)          
    * **(ii)** named entities를 normalized 형태로 매핑하기 위한 세부 정보가 포함된 [JSON 파일](https://doi.org/10.6084/m9.figshare.8184365)             
    * **(iii)** extracted named entities, 3.2700만 개의 science articles에 대한 [corresponding digital object identifier (DOI)](https://doi.org/10.6084/m9.figshare.8184413)    
 * section 5에 요약된 것처럼 데이터와 훈련된 모델과 인터페이스하기 위한 공개 웹사이트와 API를 공개함     




---
---


# 2. METHODOLOGY
![image](https://user-images.githubusercontent.com/76824611/227841719-66adeaec-e0ea-4b61-ac09-ba777ba3cfa7.png)
Figure 1. Workflow for named entity recognition. The key steps are as follows: (i) documents are collected and added to our corpus, (ii) the text is
preprocessed (tokenized and cleaned), (iii) for training data, a small subset of documents are labeled (SPL = symmetry/phase label, MAT =
material, APL = application), (iv) the labeled documents are combined with word embeddings (Word2vec26) generated from unlabeled text to
train a neural network for named entity recognition, and finally (v) entities are extracted from our text corpus.


Scikit-learn, Tensorflow, Keras python 라이브러리를 사용하여 훈련됨


## 2.1. Data Collection and Preprocessing. 

### 2.1.1. Document Collection. 


This work focuses on text mining the
abstracts of materials science articles. Our aim is to collect a
majority of all English-language abstracts for materials-focused
articles published between the years 1900 and 2018. To do
this, we create a list of over 1100 relevant journals indexed by
Elsevier’s Scopus and collect articles published in these
journals that fit these criteria via the Scopus and ScienceDirect
APIs,27 the SpringerNature API,28 and web scraping for
journals published by the Royal Society of Chemistry29 and the
Electrochemical Society.30 The abstracts of these articles (and
associated metadata including title, authors, publication year,
journal, keywords, DOI, and url) are then each assigned a
unique ID and stored as individual documents in a dual
MongoDB/ElasticSearch database. Overall, our corpus contains more than 3.27 million abstracts.

재료 과학 논문의 요약. 우리의 목표는 1900년에서 2018년 사이에 출판된 자료 중심의 기사를 위해 모든 영어 초록의 대부분을 수집하는 것입니다. 이를 위해, 우리는 Elsvier의 Scopus에 의해 색인화된 1100개 이상의 관련 저널 목록을 만들고 Scopus 및 ScienceDirect API, 27 SpringerNature API, 28 및 왕립화학회와 전기화학회에서 발행한 저널에 대한 웹 스크래핑을 통해 이러한 기준에 맞는 저널에 게재된 기사를 수집합니다.30 이러한 기사의 요약(및 제목, 저자, 출판 연도, 저널, 키워드, DOI 및 url을 포함한 관련 메타데이터)은 각각 고유한 ID를 할당받고 이중 MongoDB/ElasticSearch 데이터베이스에 개별 문서로 저장됩니다. 전체적으로, 우리의 말뭉치는 327만 개 이상의 추상체를 포함하고 있습니다.



### 2.1.2. Text Preprocessing. 
The first step in document
preprocessing is tokenization, which we performed using
ChemDataExtractor.12 This involves splitting the raw text into
sentences, followed by the splitting of each sentence into
individual tokens. Following tokenization, we developed
several rule-based preprocessing steps. Our preprocessing
scheme is outlined in detail in the Supporting Information
(S.1); here, we provide a brief overview. Tokens that are
identified as valid chemical formulas are normalized, such that
the order of elements and common multipliers do not matter
(e.g., NiFe is the same as Fe50Ni50); this is achieved using
regular expression and rule based techniques. Valence states of
elements are split into separate tokens (e.g., Fe(III) becomes
two separate tokens, Fe and (III)). Additionally, if a token is
neither a chemical formula nor an element symbol, and if only
the first letter is uppercase, we lowercase the word. This way
chemical formulas as well as abbreviations stay in their
common form, whereas words at the beginning of sentences as
well as proper nouns are converted to lowercase. Numbers
with units are often not tokenized correctly with ChemDataExtractor. We address this in the processing step by
splitting the common units from numbers and converting all
numbers to a special token ```<nUm>```. This reduces the
vocabulary size by several tens of thousand words.
   
문서 전처리의 첫 번째 단계는 ChemDataExtractor를 사용하여 수행한 토큰화입니다.12 이것은 원시 텍스트를 문장으로 분할한 다음 각 문장을 개별 토큰으로 분할하는 것을 포함합니다. 토큰화 후, 우리는 몇 가지 규칙 기반 전처리 단계를 개발했습니다. 당사의 전처리 체계는 지원 정보(S.1)에 자세히 설명되어 있습니다. 여기서 간략한 개요를 제공합니다. 유효한 화학 공식으로 식별된 토큰은 원소와 공통 승수의 순서가 중요하지 않도록 정규화됩니다(예: NiFe는 Fe50Ni50과 동일). 이는 정규식 및 규칙 기반 기술을 사용하여 달성됩니다. 원소의 원자가 상태는 별도의 토큰으로 분할됩니다(예: Fe(III)는 두 개의 별도 토큰, Fe(III)와 (III)가 됩니다). 또한 토큰이 화학식이나 원소 기호가 아니며 첫 번째 문자만 대문자인 경우에는 단어를 소문자로 만듭니다. 이러한 방식으로 약어뿐만 아니라 화학 공식은 공통적인 형태로 유지되는 반면, 문장의 시작 부분에 있는 단어와 고유 명사는 소문자로 변환됩니다. 단위가 있는 숫자는 종종 ChemDataExtractor를 사용하여 토큰화되지 않습니다. 처리 단계에서 공통 단위를 숫자에서 분할하고 모든 숫자를 특수 토큰 <nUm>으로 변환하여 이 문제를 해결합니다. 이렇게 하면 단어 크기가 수만 개 줄어듭니다.

   
### 2.1.3. Document Selection. 
   For this work, we focus on
inorganic materials science papers. However, our materials
science corpus contains some articles that fall outside the scope
of the present work; for example, we consider articles on
polymer science or biomaterials to not be relevant. In general,
we only consider an abstract to be of interest (i.e., useful for
training and testing our NER algorithm) if the abstract
mentions at least one inorganic material along with at least one
method for the synthesis or characterization of that material.
For this reason, before training an NER model, we first train a
classifier for document selection. The model is a binary
classifier capable of labeling abstracts as “relevant” or “not
relevant”. For training data, we label 1094 randomly selected
abstracts as “relevant” or “not relevant”; of these, 588 are
labeled as “relevant”, and 494 are labeled “not relevant”.
Details and specific rules used for relevance labeling are
included in the Supporting Information (S.3). The labeled
abstracts are used to train a classifier; we use a linear classifier
based on logistic regression,31 where each document is
described by a term frequency−inverse document frequency
(tf−idf) vector. The classifier achieves an accuracy (f1) score   
of 89% based on 5-fold cross-validation. Only documents
predicted to be relevant are considered as training/testing data
in the NER study; however, we perform NER over the full 3.27
million abstracts regardless of relevance. We are currently
developing text-mining tools that are optimized for a greater
scope of topics (e.g., the polymer literature).

이 작업을 위해, 우리는 무기 재료 과학 논문에 중점을 둡니다. 그러나, 우리의 재료 과학 코퍼스는 현재 연구의 범위 밖에 있는 몇 가지 기사를 포함하고 있습니다. 예를 들어, 우리는 폴리머 과학이나 생체 재료에 대한 기사는 관련이 없다고 생각합니다. 일반적으로, 우리는 추상이 해당 물질의 합성 또는 특성화를 위한 적어도 하나의 방법과 함께 적어도 하나의 무기 물질을 언급하는 경우에만 관심 있는 것으로 간주합니다(즉, NER 알고리듬을 훈련하고 테스트하는 데 유용합니다). 이러한 이유로 NER 모델을 교육하기 전에 먼저 문서 선택을 위한 분류기를 교육합니다. 이 모델은 추상을 "관련" 또는 "관련 없음"으로 분류할 수 있는 이진 분류기입니다. 교육 데이터의 경우 무작위로 선택된 1094개의 추상체에 "관련" 또는 "관련 없음"이라는 레이블을 붙입니다. 이 중 588개는 "관련 없음", 494개는 "관련 없음"이라는 레이블을 붙입니다. 관련성 라벨링에 사용된 세부사항 및 특정 규칙은 지원 정보(S.3)에 포함되어 있습니다. 레이블이 지정된 추상화는 분류기를 훈련하는 데 사용됩니다. 우리는 로지스틱 회귀 분석에 기반한 선형 분류기를 사용합니다. 여기서 각 문서는 용어 주파수 역 문서 빈도(tf-idf) 벡터로 설명됩니다. 분류기가 정확도(f1) 점수를 획득합니다
5배 교차 조사를 기준으로 89%입니다. NER 연구에서 관련성이 있을 것으로 예상되는 문서만 교육/테스트 데이터로 간주되지만, 우리는 관련성에 관계없이 전체 327만 개의 추상화에 대해 NER을 수행합니다. 우리는 현재 더 넓은 범위의 주제(예: 폴리머 문헌)에 최적화된 텍스트 마이닝 도구를 개발하고 있습니다.
   
   

## 2.2. Named Entity Recognition. Using NER, we are
interested in extracting specific entity types that can be used to
summarize a document. To date, there have been several
efforts to define an ontology or schema for information
representation in materials science (see ref 32 for a review of
these efforts); in the present work, for each document we wish
to know what was studied, and how it was studied. To extract
this information, we design seven entity labels: inorganic
material (MAT), symmetry/phase label (SPL), sample
descriptor (DSC), material property (PRO), material
application (APL), synthesis method (SMT), and characterization method (CMT). The selection of these labels is
somewhat motivated by the well-known materials science
tetrahedron: “processing”, “structure”, “properties”, and
“performance”. Examples for each of these tags are given in
the Supporting Information (S.4), along with a detailed
explanation regarding the rules for annotating each of these
tags
   
   
   
   
   Using the tagging scheme described above, 800 materials
science abstracts are annotated by hand; only abstracts that are
deemed to be relevant based on the relevance classifier
described earlier are annotated. We choose abstracts to
annotate by randomly sampling from relevant abstracts so as
to ensure that a diverse range of inorganic materials science
topics are covered. The annotations are performed by a single
materials scientist. We stress that there is no necessarily
“correct” way to annotate these abstracts; however, to ensure
that the labeling scheme is reasonable, a second materials
scientist annotated a subset of 25 abstracts to assess the
interannotator agreement, which was 87.4%. This was
calculated as the percentage of tokens for which the two
annotators assigned the same label.



For annotation, we use the inside−outside−beginning
(IOB) format.33 This is necessary to account for multiword
entities, such as “thin film”. In this approach, there are special
tags representing a token at the beginning (B), inside (I), or
outside (O) of an entity. For example, the text fragment “Thin
films of SrTiO3 were deposited” would be labeled as (token;
IOB-tag) pairs in the following way: (Thin; B-DSC), (films; IDSC), (of; O), (SrTiO3; B-MAT), (were; O), (deposited; O).
Before training a classifier, the 800 annotated abstracts are
split into training, development (validation), and test sets. The
development set is used for optimizing the hyperparameters of
the model, and the test set is used to assess the final accuracy
of the model on new data. We use an 80%−10%−10% split,
such that there are 640, 80, and 80 abstracts in the training,
development, and test sets, respectively
   
   
   
## 2.3. Neural Network model. The neural network
architecture for our model is based on that of Lample et
al.;34 a schematic of this architecture is shown in Figure 2a. We
explain the key features of the model below.   



The aim is to train a model in such a way that materials
science knowledge is encoded; for example, we wish to teach a
computer that the words “alumina” and “SrTiO3” represent
materials, whereas “sputtering” and “MOCVD” correspond to
synthesis methods. There are three main types of information
that can be used to teach a machine to recognize which words
correspond to a specific entity type: (i) word representation,
(ii) local (within sentence) context, and (iii) word shape.



For (i), word representation, we use word embeddings.
Word embeddings map each word onto a dense vector of real
numbers in a high-dimensional space. Words that have a
similar meaning, or are frequently used in a similar context, will
have a similar word embedding. For example, entities such as
“sputtering” and “MOCVD” will have similar vector
representations; during training, the model learns to associate
these word vectors as synthesis methods. The word
embeddings are generated using the Word2vec approach of
Mikolov et al.;26 the embeddings are 200-dimensional and are
based on the skip-gram approach. Word embeddings are
generated by training on our corpus of 3.27 million materials
science abstracts. More information about the training of word
embeddings is included in the Supporting Information (S.2).


For (ii), context, the model considers a sentence as a
sequence of words, and it takes into account the local context
of each word in the sentence. For example, in the sentence
“The band gap of ___ is 4.5 eV”, it is quite clear that the
missing word is a material, rather than a synthesis method or
some other entity, and this is obvious from the local context
alone. To include such contextual information, we use a
recurrent neural network (RNN), a type of sequence model
that is capable of sequence-to-sequence (many-to-many)
classification. As traditional RNNs suffer from problems in
dealing with long-range dependencies, we use a variant of the
RNN called long short-term memory (LSTM).35 In order to
capture both forward and backward context, we use a
bidirectional LSTM; in this way, one LSTM reads the sentence
forward and the other reads it backward, with the results being
combined.



For (iii), word shape, we include character-level information
about each word. For example, material formulas like “SrTiO3”
have a distinct shape, containing uppercase, lowercase, and
numerical characters, in a specific order; this word shape can
be used to help in entity classification. Similarly, prefixes and
suffixes provide useful information about entity type; for
example, the suffix “ium”, for example in “strontium”, is
commonly used for elemental metals, so a word that has this
suffix has a good chance of being part of a material name. In
order to encode this information into the model, we use a
character-level bidirectional LSTM over each word [Figure
2b]. The final outputs from the character-level LSTM (100
dimensional vectors) are concatenated with the word
embeddings for each word; these final vectors are used as
the word representations for the word-level LSTM [Figure 2a].



For the word-level LSTM, we use pretrained word
embeddings that have been trained on our corpus of over
3.27 million abstracts. For the character-level LSTM, the
character embeddings are not pretrained, but are learned
during the training of the model.




The output layer of the model is a conditional random fields
(CRF) classifier, rather than a typical softmax layer. Being a
sequence-level classifier, the CRF is better at capturing the
strong interdependencies of the output labels.36




The model has a number of hyperparameters, including the
word- and character-level LSTM size, the character embedding
size, the learning rate, and drop out. The NER performance
was optimized by repeatedly training the model with randomly
selected hyperparameters; the final model chosen was the one
with the highest accuracy when assessed on the development
set
   
   
## 2.4. Entity Normalization.    
After entity recognition, the
final step is entity normalization. This is necessarily required as
each entity may be written in numerous forms. For example,
“TiO2”, “titania”, “AO2 (A = Ti)”, and “titanium dioxide” all
refer to the same specific stoichiometry: TiO2. For document
querying, it is important to store these entities in a normalized
format, so that a query for documents that mention “titania”
also returns documents that mention “titanium dioxide”. In
order to normalize material mentions, we convert all material
names into a canonical normalized formula. The normalized
formula is alphabetized and divided by the highest common
factor of the stoichiometry. In this way, “TiO2”, “titania”, and
“titanium dioxide” are all normalized to “O2Ti”. In some cases,
multiple stoichiometries are extracted from a single material
mention; for example, “ZrxTi1−xO3 (x = 0, 0.5, 1)” is converted
to “O2Ti”, “O4TiZr”, and “O2Zr”. When a continuous range is
given, e.g, 0 ≥ x ≤ 1, we increment over this range in steps of
0.1. Material mentions are normalized using regular
expressions and rule-based methods, as well as by making
use of the PubChem lookup tables;37 final validity checks on
the normalized formula are performed using the pymatgen
library.38



Normalization of other entity types is also crucial for
comprehensive document querying. For example, “chemical
vapor deposition”, “chemical-vapour deposition”, and “CVD”
all refer to the same synthesis technique; i.e., they are
synonyms for this entity type. In order to determine that two
entities have the same meaning, we trained a classifier that is
capable of determining whether or not two entities are
synonyms.



The model uses the word embeddings for each entity as
features; after performing NER, each multiword entity is
concatenated into a single word, and new word embeddings
are trained such that every multiword entity has a single vector
representation. Each synonym consists of an entity pair, so the
features for the model are created by concatenating the word
embeddings of the two entities in question. In addition to the
word embeddings, which mostly capture the context in which
an entity is used, several other handcrafted features are
included (Supporting Information, S.5). To train the model,
10 000 entity pairs are labeled as being either synonyms or not
(see the Supporting Information, S.6). Using this data, a binary
random forest classifier is trained to be able to predict whether
or not two entities are synonyms of one another.



Using the synonym classifier, each extracted entity can be
normalized to a canonical form. Each entity is stored as its
most frequently occurring synonym (we exclude acronyms as a
normalized form); for example, “chemical vapor deposition”,
“chemical-vapour deposition”, and “CVD” are all stored as
“chemical vapor deposition”, as this is the most frequently
occurring synonym that is not an acronym.




