---
title: "Deep learning: Hyperparameter와 Parameters"
date:   2020-02-18
excerpt: "하이퍼 파라미터와 파라미터 비교하기"
category: [Deep Learning]
layout: post
tag:
- Deep Learning
order: 0

comments: true
---



# 파라미터 Parameter
우리는 대부분 **매개변수**라고 부름     
파라미터는 **모델 내부에서 결정**되는 변수입니다.     
 
**[ex]**     
* weight coefficient (가중치 계수)   
* bias (편향)      
* 모델 내부에서 데이터를 통해 구해지는 값: weight coefficient, bias   

## 특징
* 모델의 성능을 결정한다.    
* 학습된 모델의 일부로 저장된다    


---

# 하이퍼파라미터 Hyper parameter
하이퍼 파라미터는 모델링할 때 **사용자가 직접 세팅**해주는 값을 뜻합니다.   

**[ex]**      
* learning rate   
* epoch   
* iteration   
* 가중치 초기화   


## 특징
* 모델링을 할 때, 사용자가 직접 세팅해야 하는 하이퍼파라미터가 상당히 많음        
* 하이퍼 파라미터는 정해진 **최적의 값이 없음**            



## 튜닝
* 그리드 탐색   
* 베이지안 최적화    
* 휴리스틱    

등의 방법을 통해서 값을 튜닝할 수 있다


------
-----


# 적절한 하이퍼파라미터 값 찾기
**하이퍼파라미터**: 예를 들어각 층의 뉴런 수, 배치 크기, 매개변수 갱신 시의 **학습률**과 **가중치 감소** 등을 말함     
* 모델의 성능에 큰 영향     
* 그 값을 결정하기까지는 많은 시행착오를 겪음.       
  
**정의**: 파라미터가 매게변수이므로 이는 **초 매개변수**   

**적용**    
**1)** dropout: 하이퍼파라미터는 **뉴런들을 out**시킬 비율
* 확률이 낮으면 효과 얻지X     
* 값이 크면 underfitting     


## 검증 데이터
**하이퍼파라미터의 성능을 평가 시**: 시험데이터(test용 not학습)를 사용 X          
**[이유]**     
시험 데이터를 사용하여 조정 시 하이퍼파라미터 값이 시험 데이터에 오버피팅되기 때문           
* 하이퍼파라미터 값의 ‘좋음’을 시험 데이터로 확인      
* 하이퍼파라미터의 값이 시험 데이터에만 적합하도록 조정      
* 범용 성능이 떨어짐      

**[결론]**     
검증 데이터(validation data) 필요     
하이퍼파라미터를 조정시 하이퍼파라미터 전용 확인 데이터    
* 훈련 데이터: 매개변수(가중치와 편향)의 학습에 이용      
* 검증 데이터: 하이퍼파라미터의 성능을 평가하는 데 이용    
* 시험 데이터: 신경망의 범용 성능 평가      

## 하이퍼파라미터 최적화
하이퍼파라미터의 ‘최적 값’이 존재하는 범위를 조금씩 줄여가는 것      
**범위를 조금씩 줄이려면**     
**1)** 대략적인 범위를 설정하고    
**2)** 그 범위에서 무작위로 하이퍼파라미터 값을 골라냄(샘플링)      
**3)** 2단계에서 샘플링한 하이퍼파라미터 값을 사용하여 학습하고, 검증 데이터로 정확도를 평가합니다(단, 에폭은 작게 설정합니다).      
**4)** 2,3단계를 특정 횟수(100회 등) 반복하며,     
그 정확도의 결과를 보고 하이퍼파라미터의 범위를 좁힘         

신경망의 하이퍼파라미터 최적화에서는,    
그리드 서치(grid search) 같은 ~~규칙적인 탐색~~보다는 **무작위로 샘플링**해 탐색하는 편이 좋은 결과       
* 최종 정확도에 미치는 영향력이 하이퍼파라미터마다 다르기 때문        

**[하이퍼파라미터의 범위]**     
‘대략적으로’ 지정하는 것이 효과적      
* <실제> 로그 스케일(log scale) 로 지정       
   * 0.001에서 1,000 사이(10 -3 ~10 3 )와 같이 ‘10의 거듭제곱’ 단위로 범위를 지정    

하이퍼파라미터를 최적화할 때는 딥러닝 학습에는 오랜 시간(예컨대 며칠이나 몇 주 이상)이 걸림    
-> 따라서 나쁠 듯한 값은 일찍 포기해라      
=> 학습을 위한 에폭을 작게 하여, 1회 평가에 걸리는 시간을 단축하는 것이 효과적      











































