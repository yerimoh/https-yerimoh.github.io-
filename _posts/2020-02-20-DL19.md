---
title: "[17] Deep learning 2: 어텐션 Attention"
date:   2020-02-20
excerpt: " "
category: [Deep Learning]
layout: post
tag:
- Deep Learning
order: 0

comments: true
---


# 목차




---

👀, 🤷‍♀️ , 📜    
이 아이콘들을 누르시면 코드, 개념 부가 설명을 보실 수 있습니다:)

---
----

# INTRO
* seq2seq의 가능성    
* RNN의 가능성을 한걸음 더 깊이 탐구   

어텐션은 최근의 딥러닝 분야에서 틀림없이 중요한 기술 중 하나     

---
----

# 어텐션의 구조
seq2seq를 한층 더 강력하게 하는 어텐션 메커니즘       
* seq2seq는 (우리 인간처럼) **필요한 정보 에만 ‘주목’** 할 수 있게 됨.      
* 지금까지의 seq2seq가 안고 있던 문제도 해결가능       

---

## Encoder 개선
**‘고정 길이의 벡터’**     
아무리 긴 문장이 입력되더라도 항상 똑같은 길이의 벡터에 밀어 넣어야 함    
* 이렇게 하면 한계가 찾아옴.     
* 필요한 정보가 벡터에다 담기지 못함.    

![image](https://user-images.githubusercontent.com/76824611/131093958-4f903f39-b8b3-4824-baac-9042e4259c5b.png)

**[개선]**    
* Encoder 개선: 지금까지 **LSTM 계층의 마지막 은닉 상태만** 을 Decoder에 전달     
  * **But**: Encoder **출력의 길이**는 **입력 문장의 길이**에 따라 바꿔주는 게 좋음.     

* **시각별 LSTM 계층의 은닉 상태 벡터를 모두 이용**: 각 시각 (각 단어 )의 은닉 상태 벡터를 모두 이용하면 입력된 단어와 같은 수의 벡터를 얻을 수 있음

![image](https://user-images.githubusercontent.com/76824611/131094707-a590283a-dd18-487b-bb05-28ec12432346.png)
위의 예에서는 5개의 단어가 입력되었고, 이때 Encoder는 5개의 벡터를 출력.        
이것으로 Encoder는 **‘하나의 고정 길이 벡터’라는 제약으로부터 해방**      
딥러닝 프레임워크에서는 RNN 계층(혹은 LSTM 계층과 GRU 계층 등)을 초기화할 때,      
* ‘모든 시각의 은닉 상태 벡터 반환’      
* ‘마지막 은닉 상태 벡터만 반환’ 중 선택 가능       

<details>
<summary>📜 시각별 LSTM 계층의 은닉 상태의 정보 내용</summary>
<div markdown="1">

각 시각의 은닉 상태에는 **직전에 입력된 단어에 대한 정보**가 많이 포함되어 있음         

ex) 예컨대 “고양이” 단어를 입력했을 때의 LSTM 계층의 출력(은닉 상태)은 직전에 입력한 “고양이”라는 단어의 영향을 가장 크게 받음. 

➡ 이 은닉 상태 벡터는 “고양이”의 **‘성분’이 많이 들어간 벡터**라고 생각 가능

**즉, Encoder가 출력하는 hs 행렬**   
* **각 단어에 해당하는 벡터들의 집합**     
* 단어의 수 만큼 벡터를 포함    
  * 각각의 벡터안에는 해당 단어에 대한 정보를 많이 포함함     
  
![image](https://user-images.githubusercontent.com/76824611/131096447-f1cbe5ef-9379-4a8e-8ace-dba1d46c93e3.png)

  
</div>
</details>   

**WARNING**   
Encoder는 왼쪽에서 오른쪽으로 처리하므로, 방금 전의 “고양이” 벡터에는 정확히 총 3개 단어 (“나”, “는”, “고양이”)의 정보가 담겨있음.    
그런데 전체의 균형을 생각하여 “고양이” 단어의 ‘주 변’ 정보를 균형 있게 담아야 할 때도 있을 텐데, 그런 경우엔 시계열 데이터를 양방향으로 처리하는 양방향 RNN (혹은 양방향 LSTM )이 효과적(아직 안배움)

**[평가]**      
단지 Encoder의 은닉 상태를 모든 시각만큼 꺼냈을 뿐이지만,     
이 작은 개선 덕분에 Encoder는 **입력 문장의 길이에 비례한 정보를 인코딩** 가능.      

---

### Decoder 개선 ①
**Encoder, Decoder 관계**       
1) 각 단어에 대응하는 LSTM 계층의 은닉 상태 벡터를 hs로 모아 출력     
2) 그리고 이 hs가 Decoder에 전달되어 시계열 변환이 이뤄짐       
 
![image](https://user-images.githubusercontent.com/76824611/131098467-0e6ed691-a213-4686-88db-9f582822b517.png)

**[개선 전 seq2seq]**      
Encoder의 **마지막 은닉 상태** 벡터만을 Decoder에 넘김.      
* Encoder의 LSTM 계층의 ‘마지막’ 은닉 상태를 Decoder의 LSTM 계층의 ‘첫’ 은닉 상태로 설정      
 
![image](https://user-images.githubusercontent.com/76824611/131100132-87bb25c5-3340-46fe-9819-d520a80a8b8e.png)

이 hs 전부를 활용할 수 있도록 Decoder를 개선    

**[개선점]**      
**‘입력과 출력의 여러 단어 중 어떤 단어끼리 서로 관련되어 있는가**’라는 대응 관계를 seq2seq에게 학습시킴        
Ex) ‘나’는 ‘I’와 ‘고양이’는 ‘cat’과 관련있음         

<details>
<summary>📜 얼라인먼트 alignment </summary>
<div markdown="1">
  

단어(혹은 문구)의 대응 관계를 나타내는 정보           
기계 번역의 역사를 보면 ‘고양이 = cat’과 같은 단어의 대응 관계 지식을 이용하는 연구는 많이 이뤄져 왔음      

지금까지는 얼라인먼트를 주로 사람이 수작업으로 만듦     
 그러나 어텐션 기술은 얼라인먼트라는 아이디어를 seq2seq에 자동으로 도입하는 데 성공.     
   
</div>
</details>   


**[어텐션]**       
**어텐션**: **필요한 정보**에만 **주목**하여 그 정보로부터 시계열 변환을 수행하는 것     
* ‘도착어 단어’와 대응 관계에 있는 ‘출발어 단어’의 정보를 골라내는 것       
* 그리고 그 정보를 이용하여 번역을 수행하는 것.       

즉 우리의 목표인 어텐션의 전체 틀을 보자면,
![image](https://user-images.githubusercontent.com/76824611/131103033-f8e7b980-f215-4351-9944-85226fccda9b.png)
* ‘어떤 계산’을 수행하는 계층을 추가   
  * ‘어떤 계산’이 받는 입력(2개)      
     * hs: Encoder로부터 받음       
     * 시각별 LSTM 계층의 은닉 상태      
* 여기에서 필요한 정보만 골라 위쪽의 Affine 계층으로 출력       
* 지금까지와 똑같이 Encoder의 마지막 은닉 상태 벡터는 Decoder의 첫 번째 LSTM 계층에 전달      

**[위 신경망의 목표]**   
**얼라인먼트 추출**           
* 각 시각에서 Decoder에 입력된 단어와 **대응 관계인 단어의 벡터**를 hs에서 골라내겠다는 뜻.           
   * ex) Decoder가 “I”를 출력할 때, hs에서 “나”에 대응하는 벡터를 선택     
* 이러한 ‘선택’ 작업을 ‘어떤 계산’으로 해내겠다는 것      

⛔ **problem**          
선택하는 작업(여러 대상으로부터 몇 개를 선택하는 작업)은 **미분 불가**             

**WARNING** 신경망의 학습은 (일반적으로) 오차역전파법으로 이뤄짐.    
따라서 미분 가능한 연산으로 신경망을 구축하면 오차역전파법의 틀 안에서 학습을 수행 가능     
반대로 미분 가능한 연산을 이용 하지 않으면 (기본적으로는) 오차역전파법을 사용 불가    

⭕ **solution**     
‘선택한다’라는 작업을 미분 가능한 연산으로 대체 방법   
1) ‘하나를 선택’하는 게 아니라, **‘모든 것을 선택’**       
2) 이 때 **각 단어의 중요도(기여도)** 를 나타내는 **‘가중치’**를 별도로 계산       
* 각 단어의 중요도를 나타내는 ‘가중치’(기호 a )를 이용        
* a는 확률분포처럼 각 원소가 0.0~1.0 사이의 스칼라(단일 원소)이며, 모든 원소의 총합은 1.         
 
![image](https://user-images.githubusercontent.com/76824611/131106034-a8743a64-4aee-4c26-97d6-9f4d7cb1e9d8.png)

3) 맥락 벡터© 구하기      
* 각 단어의 중요도를 나타내는 **가중치 a**와 **각 단어의 벡터 hs**의 **가중합 weighted sum** 로부터 우리가 원하는 벡터**(맥락 벡터(c))**를 얻음. 

![image](https://user-images.githubusercontent.com/76824611/131106120-746ed843-74e4-45ee-a108-4a104d77f62c.png)
* ex) “나”에 대응하는 가중치가 0.8    
* 맥락 벡터 c에 “나” 벡터의 성분이 많이 포함되어 있다는 것     
* 즉, **“나” 벡터를 ‘선택’**하는 작업을 이 가중합으로 대체 가능.      
* 예컨대 “나”에 대응하는 가중치가 1이고 그 외에는 0이라면, “나” 벡터를 ‘선택’한다고 해석 가능          


**[코드 구현]**       
* Encoder가 출력하는 hs와 각 단어의 가중치 a를 적당하게 작성      
* 그 가중합을 구하는 구현    
* 다차원 배열의 형상에 주의         

<details>
<summary>👀코드 보기</summary>
<div markdown="1">
  
```python
import numpy as np
T, H = 5, 4
hs = np.random.randn(T, H) 
a = np.array([0.8, 0.1, 0.03, 0.05, 0.02])

ar = a.reshape(5, 1).repeat(4, axis=1)
print(ar.shape)
# (5, 4)

t = hs * ar
print(t.shape)
# (5, 4)

c = np.sum(t, axis=0)
print(c.shape)
# (4,)
```
  
</div>
</details>

<details>
<summary>📜 코드 설명 보기</summary>
<div markdown="1">
  

(코드 설명)    
* 시계열의 길이를 T = 5    
* 은닉 상태 벡터의 원소 수를 H = 4    
T와H로 가중합을 구하는 과정을 보여줌.     
  
``` ar = a.reshape (5, 1 ).repeat (4, axis=1 ) ```    
형상이 (5,)인 a를 복사하여, (5, 4 )짜리 배열을 만드는 것   
1) 그래서 원래 형상이 (5,)인 a를 a.reshape (5, 1 )을 거쳐    
2) (5, 1 ) 형상으로 성형한 다음,     
3) 이 배열의 한 축을 네 번 반복하여 형상이 (5, 4 )인 배열을 생성      
  
```x.repeat (rep, axis ) ```      
다차원 배열의 원소를 복사하여 새로운 다차원 배열을 생성          
*  x: 넘파이 다차원 배열일 때   
* rep: 복사를 반복하는 횟수       
* axis: 반복하는 축(차원)을 지정    
* ex) x의 형상이 (X, Y, Z )일 때, x. repeat (3, axis=1 )    
  * 실행 하면 x에서 인덱스가 1인 축(1차원 방향)이 복사되어  형상이 (X, 3 * Y, Z )인 다차원 배열이 만들어짐

![image](https://user-images.githubusercontent.com/76824611/131106762-cbd503d4-8e87-469f-acf6-35853a04283a.png)
➡ repeat ( ) 메서드 대신 넘파이의 브로드캐스트 사용 가능



```T = hs*ar```  
![image](https://user-images.githubusercontent.com/76824611/131107510-410b551d-6a24-4e13-a30b-5ef8ce5ceb20.png)
* 구현 효율을 생각하면 repeat ( ) 메서드보단 **넘파이의 브로드캐스트** 이용      
* 다만, 이렇게 하면 다차원 배열의 원소가 복사(반복)되고 있다고 점이 우리 눈에 보이지 않으니 유의     
* 이 계산의 역전파는 repeat노드에 해당(1.3.4 계산 그래프)     

```c = np.sum (hs * ar, axis=0 ) ```    
합을 구함    
* axis 인수: 어느 축(차원) 방향으로 합을 계산할지를 지정.      


WARNING_ 가중합 계산은 ‘행렬 곱’을 사용하는 편이 가장 간단하고 효율적.    
앞의 예로 말하자면 np.matmul (a, hs )라는 한 줄만으로 원하는 결과를 얻을 수 있음.     
다만, 이 방법은 하나의 데이터(샘플) 만 처리하며, 미니배치 처리로 확장 어려움      
  
</div>
</details>
  
즉 이코드에서 구현한 처리를 간단히 보면, 
![image](https://user-images.githubusercontent.com/76824611/131108313-a63783e2-03bf-400f-8075-84035ac30de4.png)



**[미니배치 처리용 가중합 구현]**      
* hs와 a는 무작위로 생성  

<details>
<summary>👀코드 보기</summary>
<div markdown="1">
  
```python
N, T, H = 10, 5, 4
hs = np.random.randn(N, T, H) 
a = np.random.randn(N, T) 
ar = a.reshape(N, T, 1).repeat(H, axis=2) 
# ar = a.reshape(N, T, 1) # 브로드캐스트를 사용하는 경우

t = hs * ar
print(t.shape)
# (10, 5, 4)

c = np.sum(t, axis=1)
print(c.shape)
# (10, 4)
```
  
</div>
</details>

지금까지의 정리도 겸해, 가중합 계산,
![image](https://user-images.githubusercontent.com/76824611/131108487-22287995-33ad-432d-b768-b71e8c8e677e.png)
 
1) Repeat 노드를 사용해 a를 복제.     
2) ‘×’ 노드로 원소별 곱을 계산    
3)  Sum 노드로 합을 구함    

**[역전파 구현]**   
1) Repeat의 역전파는 Sum   
2) Sum의 역전파는 Repeat  

계산 그래프를 계층으로 구현(Weight Sum 계층)      
<details>
<summary>👀코드 보기</summary>
<div markdown="1">
  
```python
class WeightSum:
  def __init __(self):
    self.params, self.grads = [], [] 
    self.cache = None


  def forward(self, hs, a):
    N, T, H = hs.shape

    ar = a.reshape(N, T, 1).repeat(H, axis=2) 
    t = hs * ar
    c = np.sum(t, axis=1)

    self.cache = (hs, ar) 
    return c

  def backward(self, dc):
    hs, ar = self.cache 
    N, T, H = hs.shape

    dt = dc.reshape(N, 1, H).repeat(T, axis=1) # sum 의 역전파
    dar = dt * hs 
    dhs = dt * ar 
    da = np.sum(dar, axis=2) # repeat 의 역전파
    return dhs, da
```

이 계층은 학습하는 매개변수가 없음    
➡  self.params = []로 설정. 
  
</div>
</details>


----


### Decoder 개선 ②
각 단어의 중요도를 나타내는 **가중치 a**가 있다면, 가중합을 이용해 ‘맥락 벡터’를 얻을 수 있음.    

**[a를 구하는 법]**   
**(intro)**    
우선 Decoder 의 첫 번째(시각) LSTM 계층이 은닉 상태 벡터를 출력할 때까지의 처리부터 보면      
![image](https://user-images.githubusercontent.com/76824611/131109836-d3bc60ce-b011-49c1-a08a-1178cb45f913.png)
**(목표)**      
h가 hs의 각 단어 벡터와 얼마나 ‘비슷한가’를 수치로 나타내는 것    

**(solution)**          
벡터의 ‘내적’을 이용.    
내적의 계산     
두벡터 $$a=(a_1 ,a_2 ,…,a_n )$$와 $$b=(b_1 ,b_2 ,…,b_n )$$의 내적을 구해보면,    
$$a·b = a_1* b_1 + a_2* b_2 + … + a_n* b_n$$    

**직관적인 의미**    
* ‘두 벡터가 얼마나 같은 방향을 향하고 있는가’   
* 따라서 두 벡터의 ‘유사도’를 표현하는 척도로 내적을 이용하는 것은 자연스러운 선택임     

내적을 이용해 벡터 사이의 유사도를 산출할 때까지의 처리   
![image](https://user-images.githubusercontent.com/76824611/131110419-bd355ad7-7420-4f3d-af22-d116b2e4dd56.png)
1) 벡터의 내적을 이용해 h와 hs의 각 단어 벡터와의 유사도를 구함      

2) s는 그 결과     
* s는 정규화하기 전의 값    
* ‘점수 score ’라고도 함    

3) 계속해서 s를 정규화하기 위해서는 일반적으로 소프트맥스 함수를 적용       
![image](https://user-images.githubusercontent.com/76824611/131110583-f27748e9-23f7-4d83-ac09-024edd4beb78.png)

4) 가중치를 나타내는 a 구하기 완료     
 
<details>
<summary>👀코드 보기</summary>
<div markdown="1">
  
```python
import sys
sys.path.append('..') 
from common.layers import Softmax 
import numpy as np

N, T, H = 10, 5, 4
hs = np.random.randn(N, T, H) 
h = np.random.randn(N, H) 
hr = h.reshape(N, 1, H).repeat(T, axis=1) 
# hr = h.reshape(N, 1, H) # 브로드캐스트를 사용하는 경우

t = hs * hr
print(t.shape)
# (10, 5, 4)

s = np.sum(t, axis=2)
print(s.shape)
# (10, 5)

softmax = Softmax() a = softmax.forward(s)
print(a.shape)
# (10, 5)
```
  
</div>
</details>

이 구현은 미니배치 처리를 수행할 때의 코드임

![image](https://user-images.githubusercontent.com/76824611/131110790-47f00075-7587-4a07-9b0f-c8b97134bce9.png)

**[계산 그래프 구현 AttentionWeight]**
* Repeat 노드
* 원소별 곱을 뜻하는×노드
* Sum 노드
* Softmax 계층으로 구성됩니다. 

<details>
<summary>👀코드 보기</summary>
<div markdown="1">
  
```python
class AttentionWeight:
    def __init__(self):
        self.params, self.grads = [], []
        self.softmax = Softmax()
        self.cache = None

    def forward(self, hs, h):
        N, T, H = hs.shape

        hr = h.reshape(N, 1, H)#.repeat(T, axis=1)
        t = hs * hr
        s = np.sum(t, axis=2)
        a = self.softmax.forward(s)

        self.cache = (hs, hr)
        return a

    def backward(self, da):
        hs, hr = self.cache
        N, T, H = hs.shape

        ds = self.softmax.backward(da)
        dt = ds.reshape(N, T, 1).repeat(H, axis=2)
        dhs = dt * hr
        dhr = dt * hs
        dh = np.sum(dhr, axis=1)

        return dhs, dh
```
  
</div>
</details>

----

### Decoder 개선 ③
**[지금까지 Decoder 개선안]**         
* Attention Weight 계층     
 * Encoder가 출력하는 각 단어의 벡터 hs에 주목하여 해당 단어의 **가중치 a**를 구함     
* Weight Sum 계층     
 * 계층이 **a와 hs의 가중합**을 구하고, 그 결과를 맥락 벡터 c로      

이제 이 두 계층을 하나로 결합(Attention 계층)
![image](https://user-images.githubusercontent.com/76824611/131111425-7641bb76-73dc-4137-8c28-c2c9024b7c03.png)
 

Attention 계층
![image](https://user-images.githubusercontent.com/76824611/131111498-2d5d74ae-fa73-44a7-bda4-c2b334c26282.png)
* Encoder가 건네주는 정보 **hs에서 중요한 원소에 주목** 하여, 그것을 바탕으로 **맥락 벡터**를 구해 **위쪽 계층으로 전파**          
* (우리의 경우, 위쪽에는 Affine 계층이 기다리고 있음)    

  
<details>
<summary>👀Attention 계층을 구현한 코드 보기</summary>
<div markdown="1">
  
```python
class Attention:
    def __init__(self):
        self.params, self.grads = [], []
        self.attention_weight_layer = AttentionWeight()
        self.weight_sum_layer = WeightSum()
        self.attention_weight = None

    def forward(self, hs, h):
        a = self.attention_weight_layer.forward(hs, h)
        out = self.weight_sum_layer.forward(hs, a)
        self.attention_weight = a
        return out

    def backward(self, dout):
        dhs0, da = self.weight_sum_layer.backward(dout)
        dhs1, dh = self.attention_weight_layer.backward(da)
        dhs = dhs0 + dhs1
        return dhs, dh
```
이 코드는 2개의 계층(Weight Sum 계층과 Attention Weight 계층)에 의한 순전파와 역전파를 수행할 뿐.     
* ```attention_weight``` : 이때 각 단어의 가중치를 나중에 참조할 수 있도록 이 인스턴스 변수에 저장.  
  
</div>
</details>


![image](https://user-images.githubusercontent.com/76824611/131112167-a1cc2e33-df0d-4602-84bd-6a005f1543a1.png)
 

LSTM 계층의 은닉 상태 벡터를 Affine 계층에 입력.      
* Decoder에 어텐션 정보를 ‘추가’할 수 있기 때문     

![image](https://user-images.githubusercontent.com/76824611/131112575-0083e367-41ff-4700-8c34-cbda4a76fe87.png)
* Decoder에 Attention 계층이 구한 맥락 벡터 정보를 ‘추가’ 한 것    
* Affine 계층에는 기존과 마찬가지로 LSTM 계층의 은닉 상태 벡터를 주고, 여기에 더해 Attention 계층의 맥락 벡터까지 입력

* (앞에서도 설명한 것처럼) 두 벡터를 ‘연결한 벡터’를 Affine 계층에 입력한다는 뜻

➕ 위의 시계열 방향으로 펼쳐진 다수의 Attention 계층을 Time Attention 계층으로 모아 구현     
* Time Attention 계층은 다수의 Attention 계층을 모았을 뿐   
  
![image](https://user-images.githubusercontent.com/76824611/131112891-3d143ab0-2593-4949-b583-91b1ba9b5ce2.png)

---
  
# 어텐션을 갖춘 seq2seq 구현
* AttentionEncoder    
* AttentionDecoder    
* AttentionSeq2seq    

**[Encoder 구현]**   
앞 장에서 구현한 Encoder 클래 스와 거의 같음       
* Encoder 클래스의 ```forward ( )``` 메서드: LSTM 계층의 마지막 은닉 상태 벡터만을 반환         
* AttentionEncoder: 이번에는 모든 은닉 상태를 반환     

<details>
<summary>👀코드 보기</summary>
<div markdown="1">
  
```python
# coding: utf-8
import sys
sys.path.append('..')
from common.time_layers import *
from ch07.seq2seq import Encoder, Seq2seq
from ch08.attention_layer import TimeAttention


class AttentionEncoder(Encoder):
    def forward(self, xs):
        xs = self.embed.forward(xs)
        hs = self.lstm.forward(xs)
        return hs

    def backward(self, dhs):
        dout = self.lstm.backward(dhs)
        dout = self.embed.backward(dout)
        return dout 
```
  
</div>
</details>

**[Decoder 구현]**
![image](https://user-images.githubusercontent.com/76824611/131113287-612bd886-c2d4-4464-9409-e8c533522599.png)
Softmax 계층(정확히는 Time Softmax with Loss 계층)의 앞까지를 Decoder로 구현

* 순전파의 ```forward ( )```   
* 역전파의 ```backward ( )```      
* 새로운 단어열(혹은 문자열)을 생성하는 ```generate ( )``` 메서드도 추가.     

<details>
<summary>👀코드 보기</summary>
<div markdown="1">
  
```python
class AttentionDecoder:
    def __init__(self, vocab_size, wordvec_size, hidden_size):
        V, D, H = vocab_size, wordvec_size, hidden_size
        rn = np.random.randn

        embed_W = (rn(V, D) / 100).astype('f')
        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')
        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')
        lstm_b = np.zeros(4 * H).astype('f')
        affine_W = (rn(2*H, V) / np.sqrt(2*H)).astype('f')
        affine_b = np.zeros(V).astype('f')

        self.embed = TimeEmbedding(embed_W)
        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True)
        self.attention = TimeAttention()
        self.affine = TimeAffine(affine_W, affine_b)
        layers = [self.embed, self.lstm, self.attention, self.affine]

        self.params, self.grads = [], []
        for layer in layers:
            self.params += layer.params
            self.grads += layer.grads

    def forward(self, xs, enc_hs):
        h = enc_hs[:,-1]
        self.lstm.set_state(h)

        out = self.embed.forward(xs)
        dec_hs = self.lstm.forward(out)
        c = self.attention.forward(enc_hs, dec_hs)
        out = np.concatenate((c, dec_hs), axis=2)
        score = self.affine.forward(out)

        return score

    def backward(self, dscore):
        dout = self.affine.backward(dscore)
        N, T, H2 = dout.shape
        H = H2 // 2

        dc, ddec_hs0 = dout[:,:,:H], dout[:,:,H:]
        denc_hs, ddec_hs1 = self.attention.backward(dc)
        ddec_hs = ddec_hs0 + ddec_hs1
        dout = self.lstm.backward(ddec_hs)
        dh = self.lstm.dh
        denc_hs[:, -1] += dh
        self.embed.backward(dout)

        return denc_hs

    def generate(self, enc_hs, start_id, sample_size):
        sampled = []
        sample_id = start_id
        h = enc_hs[:, -1]
        self.lstm.set_state(h)

        for _ in range(sample_size):
            x = np.array([sample_id]).reshape((1, 1))

            out = self.embed.forward(x)
            dec_hs = self.lstm.forward(out)
            c = self.attention.forward(enc_hs, dec_hs)
            out = np.concatenate((c, dec_hs), axis=2)
            score = self.affine.forward(out)

            sample_id = np.argmax(score.flatten())
            sampled.append(sample_id)
```
  
</div>
</details>

이 구현은 Time Attention 계층이 새롭게 사용되는 것을 제외하면 앞 장의 Decoder 클래스와 크게 다르지 않음      
* ```forward ( )``` 메서드에서 Time Attention 계층의 출력과 LSTM 계층의 출력을 연결한다는 점만 주의    
* 두 출력을 연결할 때는 ```np.concatenate ( )``` 메서드를 사용       

**[seq2seq 구현]**     
Encoder 대신 AttentionEncoder 클래스   
Decoder 대신 AttentionDecoder 클래스를 사용    
* 따라서 앞 장의 Seq2seq 클래스를 상속하고       
* 초기화 메서드를 수정하는 것만으로 AttentionSeq2seq 클래스를 구현 가능    


<details>
<summary>👀코드 보기</summary>
<div markdown="1">
  
```python
class AttentionSeq2seq(Seq2seq):
    def __init__(self, vocab_size, wordvec_size, hidden_size):
        args = vocab_size, wordvec_size, hidden_size
        self.encoder = AttentionEncoder(*args)
        self.decoder = AttentionDecoder(*args)
        self.softmax = TimeSoftmaxWithLoss()

        self.params = self.encoder.params + self.decoder.params
        self.grads = self.encoder.grads + self.decoder.grads 
```
  
</div>
</details>

----

# 어텐션 평가
**날짜 형식**을 변경하는 문제    
* 데이터 크기가 작고       
* 어느 쪽인가를 맞추는 인위적인 문제)로 어텐션을 갖춘 seq2seq의 효과를 확인해보려 함    

**[날짜 형식 변환 문제]**     
 “september 27, 1994” 등의 날짜 데이터를 “1994-09-27” 같은 표준 형식으로 변환     
![image](https://user-images.githubusercontent.com/76824611/131113671-9eb988af-55aa-4b87-99e5-6cc3be52f951.png)

**(채택 이유)**    
* 입력되는 날짜 데이터에는 다양한 변형이 존재하여 겉보기만큼 간단하지 않음.     
* 문제의 입력(질문)과 출력(답변) 사이에 알기 쉬운 대응 관계가 있기 때문     
* 어텐션이 각각의 원소에 올바르게 주목하고 있는지를 확인 가능      

![image](https://user-images.githubusercontent.com/76824611/131113759-e39a80ca-ced7-43e0-825a-f1fe06312e13.png)
* 입력 문장의 길이를 통일하기 위해 공백 문자로 패딩,    
* 입력과 출력의 구분 문자로는 ```_```(밑줄)을 사용     
* 그리고 이 문제에서는 출력의 문자 수는 일정하기 때문에 출력의 끝을 알리는 ~~구분 문자~~는 따로 사용 안함      



**[어텐션을 갖춘 seq2seq의 학습]**     
그럼, 날짜 변환용 데이터셋으로 AttentionSeq2seq를 학습시킴
<details>
<summary>👀코드 보기</summary>
<div markdown="1">
  
```python
import sys
sys.path.append('..')
import numpy as np
import matplotlib.pyplot as plt
from dataset import sequence
from common.optimizer import Adam
from common.trainer import Trainer
from common.util import eval_seq2seq
from attention_seq2seq import AttentionSeq2seq
from ch07.seq2seq import Seq2seq
from ch07.peeky_seq2seq import PeekySeq2seq


# 데이터 읽기
(x_train, t_train), (x_test, t_test) = sequence.load_data('date.txt')
char_to_id, id_to_char = sequence.get_vocab()

# 입력문장 반전
x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]

# 하이퍼 파라미터 설정
vocab_size = len(char_to_id)
wordvec_size = 16
hidden_size = 256
batch_size = 128
max_epoch = 10
max_grad = 5.0

model = AttentionSeq2seq(vocab_size, wordvec_size, hidden_size)
# model = Seq2seq(vocab_size, wordvec_size, hidden_size)
# model = PeekySeq2seq(vocab_size, wordvec_size, hidden_size)

optimizer = Adam()
trainer = Trainer(model, optimizer)

acc_list = []
for epoch in range(max_epoch):
    trainer.fit(x_train, t_train, max_epoch=1,
                batch_size=batch_size, max_grad=max_grad)

    correct_num = 0
    for i in range(len(x_test)):
        question, correct = x_test[[i]], t_test[[i]]
        verbose = i < 10
        correct_num += eval_seq2seq(model, question, correct,
                                    id_to_char, verbose, is_reverse=True)

    acc = float(correct_num) / len(x_test)
    acc_list.append(acc)
    print('val acc %.3f%%' % (acc * 100))


model.save_params() 
```
  
</div>
</details>
        
**다른 점**        
* 학습 데이터가 날짜 데이터라는 것       
* 모델로 AttentionSeq2seq를 사용한다는 것.     
* 입력 문장을 반전시키는 기법(Reverse )도 적용     

그런 다음 학습을 수행하면서, 에폭마다 테스트 데이터를 사용하여 정답률을 측정      

이때 처음 10 문제의 결과는 (질문 문장과 정답도 함께) 터미널에 출력   

**(결과)**   
![image](https://user-images.githubusercontent.com/76824611/131115931-1ebe1e74-79dc-4011-af7d-174f677efb73.png)
위에서 보듯 어텐션을 갖춘 seq2seq는 학습을 거듭할수록 점점 똑똑해짐      
얼마 지나지 않아 문제 대부분을 정확히 맞춤        
 
그리고 테스트 데이터로 얻은 정답률   
 
아주 좋은 결과  

**(개선 전과 비교)**
![image](https://user-images.githubusercontent.com/76824611/131116078-8510f0ff-b910-4ad7-8668-e8ee4e8297b5.png)
 


**[어텐션 시각화]**     
어텐션이 시계열 변환을 수행할 때,      
어느 원소에 주의를 기울이는지를 눈으로 살펴보려는 시도.     
* Attention 계층은 각 시각의 어텐션 가중치를 인스턴스 변수로 보관하고 있으므로, 이를 시각화하기란 아주 간단      

우리 구현에서는 Time Attention 계층에 있는 인스턴스 변수 attention_weights에 각 시각의 어텐션 가중치가 저장됨.      
* 이것을 사용하면 입력 문장과 출력 문장의 단어 대응 관계를 2차원 맵으로 그릴 수 있음     
* 이번 절에서는 학습이 끝난 AttentionSeq2seq로 날짜 변환을 수행할 때의 어텐션 가중치를 시각화      
 
**(결과)**
![image](https://user-images.githubusercontent.com/76824611/131116183-7e1f9695-ff93-4ba4-994c-240a9dea5e34.png)
 
ex) seq2seq가 최초의 “1”을 출력할 때는 입력 문장의 “1” 위치에 표시.         
여기서 주목할 점은 년·월·일의 대응 관계     
* 세로축(출력)의 “1983”과 “26”이 가로축(입력)의 “1983”과 “26”에 훌륭하게 대응    
* 월을 뜻하는 “08”에 입력 문장의 “AUGUST”가 대응     
* seq2seq 는 “August”가 “8월”에 대응한다는 사실을 데이터만 가지고 학습해낸 것    

---
  
# 어텐션에 관한 남은 이야기

## 양방향 RNN 
이번 절은 seq2seq의 Encoder에 초점을 둠     
**[원래 Encoder]**     
![image](https://user-images.githubusercontent.com/76824611/131116460-8dca9910-93d3-400e-ac08-cfa074f3293d.png)
* LSTM의 각 시각의 은닉 상태 벡터는 hs로 모아짐.     
* Encoder가 출력하는 hs의 각 행에는 그 행에 대응하는 단어의 성분이 많이 포함되어 있음     

**[주목할 점]**    
우리는 글을 왼쪽에서 오른쪽으로 읽음      
* “고양이”에 대응하는 벡터에 “나”, “는”, “고양이”까지 총 세 단어의 정보가 인코딩되어 들어감.   
* 여기에서 전체적인 균형을 생각하면, “고양이” 단어의 **‘주변’ 정보를 균형 있게** 담고 싶을 것임     

**WARNING**     
이번 번역 문제에서 우리는 시계열 데이터(번역해야 할 문장)를 한꺼번에 건네줌.      
따라서 문장을 오른쪽부터 읽도록(처리하도록) 할 수도 있음     

**[개선]** 양방향 LSTM (양방향 RNN)     
그래서 LSTM을 양방향으로 처리하는 방법을 생각가능   
![image](https://user-images.githubusercontent.com/76824611/131116557-4c14670f-e57a-4152-990f-d9161e914e4c.png)
양방향 LSTM에서는 지금까지의 LSTM 계층에 더해 **역방향으로 처리 하는 LSTM 계층도 추가**

**각 시각**: 이 두 LSTM 계층의 은닉 상태를 연결 시킨 벡터를 최종 은닉 상태로 처리(‘연결’ 외에도, ‘합’하거나 ‘평균’내는 방법 등도 존재).

이처럼 양방향으로 처리함으로써, 각 단어에 대응하는 은닉 상태 벡터에는 좌와 우 양쪽 방향 으로부터의 정보를 집약가능     
* 균형 잡힌 정보가 인코딩 됨   

**[구현]**    
2개의 LSTM 계층(우리의 경우는 Time LSTM 계층)을 사용하여 각각의 계층에 주는 단어의 순서 조정     

**1)** LSTM 계층 하나는 지금까지와 똑같음        
* 입력 문장을 ‘왼쪽부터 오른쪽으로’ 처리하는 일반적인 LSTM 계층         

  
**2)** 또 하나의 LSTM 계층에는 입력 문장의 단어들을 **반대 순서**로 나열.     
* 만약 원래 문장이 “A B C D”였다면 “D C B A”로 순서를 바꾸는 것   
* 두 번째 LSTM 계층은 입력문을 ‘오른쪽에서 왼쪽으로’ 처리하게 됨   
  
**3)** 마지막으로 이 두 LSTM 계층의 출력을 연결하기만 하면 양방향 LSTM 계층이 완성    

common/time_layers.py의 TimeBiLSTM 클래스로 구현

Attention 계층 사용 방법
앞 절까지 사용해온 어텐션을 갖춘 seq2seq의 계층 구성
  

* Attention 계층을 LSTM 계층과 Affine 계층 사이에 삽입. 
* Attention 계층을 이용하는 장소가 반드시 이 그림과 같을 필요는 없음

Attention 계층의 다른 사용 예
 
이렇게 구성하면 LSTM 계층이 맥락 벡터의 정보를 이용할 수 있음
* 우리가 구현한 모델은 Affine 계층이 맥락 벡터를 이용
[개선 후 영향]
그 답은 해보지 않으면 모름.
현실은 실제 데이터를 사용해 검증할 수밖에 없음
다만, 앞의 두모델은 모두 맥락 벡터를 잘 활용하는 구성이라서 큰 차이가 없을지도 모름

[구현]
또한, 구현 관점에서는 전자의 구성(LSTM 계층과 Affine 계층 사이에 Attention 계층을 삽입) 쪽이 구현하기 쉬움. 
그리고 전자의 구성에서는 Decoder의 데이터 흐름이 아래에서 위로 가는 한 방향이기 때문에 Attention 계층을 쉽게 모듈화할 수 있습니다. 실제로도 우리는 Time Attention 계층으로 간단히 모듈화 가능

seq2seq 심층화와 skip 연결
번역 등 현실에서의 애플리케이션들은 풀어야 할 문제가 훨씬 복잡함
-> 어텐션을 갖춘 seq2seq에도 더 높은 표현력이 요구됨. 

[solution]
우선 생각해야 할 것은 RNN 계층(LSTM 계층)을 깊게 쌓는 방법. 
층을 깊게 쌓으면,
* 표현력 높은 모델을 만들 수 있음
* 어텐션을 갖춘 seq2seq도 다르지 않음. 

(어텐션을 갖춘 seq2seq를 깊게 하면?)
3층 LSTM 계층을 사용한 어텐션을 갖춘 seq2seq
 
위의 모델에서는 Encoder와 Decoder로 3층 LSTM 계층을 사용
* 이 예처럼 Encoder와 Decoder에서는 같은 층수의 LSTM 계층을 이용하는 것이 일반적

한편, Attention 계층의 사용법은 여러 변형이 있을 수 있음
여기에서는,
1) Decoder의 LSTM 계층의 은닉 상태를 Attention 계층에 입력하고, 
2) Attention 계층의 출력인 맥락 벡터를 Decoder의 여러 계층(LSTM 계층과 Affine 계층)으로 전파

+ 이 외에도 여러 개의 Attention 계층을 사용하거나, Attention의 출력을 다음 시각의 LSTM 계층으로 입력하는 등 다양한 변형이 가능
+ 또한, 앞 장에서 설명한 것처럼 계층을 깊게 할 경우에는 **일반화 성능을 떨어뜨리지 않는 것이 중요**
* 이목적으로는 드롭아웃과 가중치 공유 등의 기술이 효과적

[skip 연결, skip connection]
(=‘잔차 연결 residual connection ’ or ‘숏컷 short-cut ’)
층을 깊게 할 때 사용되는 중요한 기법 
계층을 넘어 ‘선을 연결’하는 단순한 기법
 
skip 연결은 ‘계층을 건너뛰는 연결’
* 이때 skip 연결의 접속부 에서는 2개의 출력이 ‘더해’짐
* 이 덧셈(정확하게는 원소별 덧셈)이 핵심. 
* 덧셈은 역전파 시 기울기를 ‘그대로 흘려’보냄
* skip 연결의 기울기가 아무런 영향을 받지 않고 모든 계층으로 흐름
* 따라서 층이 깊어져도 기울기가 소실(혹은 폭발)되지 않고 전파되어, 결과적으로 좋은 학습을 기대 가능

NOTE_ RNN 계층의 역전파에서는 **시간 방향**에서 기울기 소실 혹은 폭발 대응법. 
* 기울기 소실: LSTM과 GRU 등의 ‘게이트가 달린 RNN’으로 대응
* 기울기 폭발: ‘기울기 클리핑’으로 대응

한편, RNN의 **깊이 방향 기울기 소실**
: skip 연결이 효과적

> 어텐션 응용
지금까지 우리는 어텐션을 seq2seq에만 적용함
하지만 이 아이디어 자체는 범용적이고 더 많은 가능성을 지님

구글 신경망 기계 번역(GNMT)
기계 번역의 역사를 살펴보면.
1)‘규칙 기반 번역’
2)‘용례 기반 번역’
3)‘통계 기반 번역’
**4) 신경망 기계 번역 Neural Machine Translation (NMT)**

NOTE_ 신경망 기계 번역이라는 용어는 기존의 통계 기반 번역과 대비되는 형태로 사용되다가, 최근에는 seq2seq를 사용한 기계 번역의 총칭으로서 사용됨

(GNMT의 계층 구성)
 
GNMT도 이번 장에서 구현한 어텐션을 갖춘 seq2seq와 마찬가지로 Encoder와 Decoder,Attention로 구성
(차이점)
번역 정확도를 높이기 위한 여러 개선이 더해짐. 
* 예컨대 LSTM 계층의 다층화
* 양방향 LSTM (Encoder 의 첫 번째 계층만)
* skip 연결
* 또한, 학습 시간을 단축하기 위해 다수의 GPU로 분산 학습을 수행
(쓰임)
* 낮은 빈도의 단어 처리
* 추론 고속화를 위한 양자화 등

(평가)
 

NOTE_ GNMT를 실제로 구현하려면 대량의 데이터와 대량의 컴퓨팅 자원이 필요
한 개인이 실현할 수 있는 수준은 아님







트랜스포머 Transformer
[intro_RNN의 단점]
어텐션을 갖춘 seq2seq의 구성에는 반드시 RNN이 등장했음. 
하지만 RNN에도 단점 존재
* 그중 하나가 병렬 처리
(RNN)
이전 시각에 계산한 결과를 이용하여 순서대로 계산
따라서 RNN의 계산을 시간 방향으로 병렬 계산하기란 (기본적으로는) 불가능
* 딥러닝 학습이 GPU를 사용한 병렬 계산 환경에서 이뤄진다는 점을 생각하면 큰 단점임

현재 RNN을 없애는 연구(혹은 병렬 계산할 수 있는 RNN 연구) 활발. 

그 중 유명한 것이 「Attention is all you need」라는 논문 [52 ] 에서 제안한 기법인 트랜스포머 Transformer 모델

NOTE_ 트랜스포머 외에도 RNN을 제거하는 연구 많음
* RNN 대신 합성곱 계층을 이용하는 연구 [54]
: 이 연구의 자세한 내용은 여기에서 다루지 않지만, 기본적으로는 RNN 대신 합성곱 계층을 이용해 seq2seq를 구성. 
: 이렇게 하면 계산을 병렬화할 수있습니다.

[트랜스포머 Transformer 모델]
이 모델은 **‘RNN이 아닌’ 어텐션을 사용해 처리**
트랜스포머는 어텐션으로 구성, 
* 그중 셀프어텐션 Self-Attention 이라는 기술을 이용

(Self-Attention)
하나의 시계열 데이터를 대상으로 한 어텐션으로, 
‘하나의 시계열 데이터 내에서’ 각 원소가 다른 원소들과 어떻게 관련되는지를 살펴보자는 취지

우리의 Time Attention 계층을 예로 설명하면, 셀프어텐션은,
 
지금까지 우리는 어텐션에서 ‘번역’과 같이 2개의 시계열 데이터 사이의 대응 관계를 구해올 때,
* Time Attention 계층: 원래 쓰던것
* 서로 다른 두 시계열 데이터가 입력됨 
* Self-Attention: 트랜스포머
* 두 입력선이 모두 하나의 시계열 데이터로부터 나옴
* 이렇게 하면 **하나의 시계열 데이터** 내에서의 원소 간 대응 관계가 구해짐

(트랜스포머의 계층 구성)
 
트랜스포머에서는 ~~RNN~~ 대신 어텐션을 사용
* Encoder 와 Decoder 모두에서 셀프어텐션을 사용함을 알 수 있음
* Feed Forward 계층
* 피드포워드 신경망 (시간 방향으로 독립적으로 처리하는 신경망 )을 나타냄
* 정확하게는 은닉층이 1개이고 활성화 함수로 ReLU를 이용한 완전연결계층 신경망을 이용. 
* Nx: 회색 배경으로 둘러쌓인 계층들을 N겹 쌓았다는 뜻

(응용)
* 실제로는 이 그림의 아키텍처에 더해 skip 연결과 계층 정규화 Layer Normalization [8] 등도 이용
* 다수의 어텐션을 (병렬로) 이용하거나 시계열 데이터의 위치 정보를 인코딩하는 위치 인코딩 Positional Encoding 같은 기법도 볼 수 있음


뉴럴 튜링 머신(NTM)
우리 인간은 복잡한 문제를 풀 때 ‘종이’와 ‘펜’을 사용하는 일이 많음
* 종이와 펜이라는 외부의 ‘저장 장치’ 덕분에 우리의 능력이 확장
* 신경망 에도 이와 같은 ‘외부 메모리’를 이용하여 새로운 힘 부여 가능. 

즉, 주제는 바로 **외부 메모리를 통한 확장**

NOTE_ 
* RNN이나 LSTM: 내부 상태를 활용하여 시계열 데이터를 기억
* 그러나 그 내부 상태는 길이가 고정이라서 채워 넣을 수 있는 정보량이 제한적
* 그래서 RNN 외부에 기억 장치(메 모리)를 두고 필요한 정보를 거기에 적절하게 기록하는 방안을 착안해낸 것

어텐션을 갖춘 seq2seq에서는 Encoder가 입력 문장을 인코딩합니다. 그리고 인코딩된 정보를 어텐션을 통해 Decoder가 이용했죠. 

여기서 주목할 것은 (역시) 어텐션의 존재
* 이 어텐션을 통해 Encoder와 Decoder는 (컴퓨터에서 말하는) ‘메모리 조작’ 같은 작업을 수행 하는 것. 
* 즉, Encoder가 필요한 정보를 메모리에 쓰고, Decoder는 그 메모리로부터 필요한 정보를 읽어 들인다고 해석 가능

이렇게 생각하면 컴퓨터의 메모리 조작을 신경망에서도 재현할 수 있을 것 같음. 
* RNN의 외부에 정보 저장용 메모리 기능을 배치하고, 
* 어텐션을 이용하여 그 메모리로부터 필요한 정보를 읽거나 쓰는 방법. 
* 실제로 이러한 연구가 몇 가지 이뤄 지고 있고, 그중 유명한 연구가 뉴럴 튜링 머신 Neural Turing Machine (NTM ) [55 ] 

NTM의 큰 틀
 
컨트롤러 모듈: 그림 한가운데 위치
* 정보를 처리하는 모듈
* 신경망(혹은 RNN )을 이용

그림을 보면, 이 컨트롤러는 차례차례 흘러 들어오는 ‘0’ 혹은 ‘1’ 데이터를 처리하여 새로운 데이터를 출력

큰 종이(=메모리)
* 이 컨트롤러의 바깥에 위치 
* 이 메모리 덕분에 컨트롤러는 컴퓨터(혹은 튜링 머신)와 같은 능력을 얻음
* 그 능력
* ‘큰 종이’에 필요한 정보를 쓰거나 불필요한 정보를 지우는 능력
* 필요한 정보를 다시 읽어 들이는 능력
* 형태: 두루마리
*  각 노드가 필요한 위치의 데이터를 읽고 쓸 수 있다는 뜻
*  원하는 목적지로 이동 가능

이처럼,
* NTM은 외부 메모리를 읽고 쓰면서 시계열 데이터를 처리. 
* 그리고 또 하나 재미 있는 사실은 이러한 메모리 조작을 ‘미분 가능’한 계산으로 구축
*  따라서 메모리 조작 순서도 데이터로부터 학습 가능.

NOTE_ 
* 일반적인 컴퓨터: 사람이 작성한 지시(프로그램)에 따라 동작
* NTM: 데이터로부터 프로그램을 학습합니다
* ‘알고리즘의 입력과 출력’으로부터 ‘알고리즘 자체(로직)’를 학습할 수 있다는 뜻

NTM의 계층 구성
 
* LSTM 계층:‘컨트롤러’가 되어 NTM의 주된 처리를 수행. 
* Write Head 계층: 각 시각에서 LSTM 계층의 은닉 상태를 받아서 필요한 정보를 메모리에 씀
* Read Head 계층: 메모리로부터 중요한 정보를 읽어 들여 다음 시각의 LSTM 계층으로 전달

(Write Head 계층과 Read Head 계층의 메모리를 조작 방법) 
여기에도 어텐션을 사용

Remind_ 
어텐션을 사용: 메모리의 특정 번지에 담긴 데이터를 읽거나 쓰려할 때, 우리는 데이터를 ‘선택’해야 하는데, 이 선택 작업 자체는 미분불가 문제를 해결하기 위해.
모든 번지에 담긴 데이 터를 선택하도록 하고, 각 데이터의 기여도를 나타내는 ‘가중치’를 이용. 
이렇게 함으로써 ‘선택 한다’라는 작업을 미분 가능한 계산으로 대체할 수 있습니다.


NTM은 컴퓨터의 메모리 조작을 모방하기 위해서 2개의 어텐션을 이용
*  콘텐츠 기반 어텐션
* 지금까지 본 어텐션과 같음 
* 입력으로 주어진 어느 벡터(질의 query 벡터)와 비슷한 벡터를 메모리로부터 찾아내는 용도로 이용
* 위치 기반 어텐션은 
*  이전 시각에서 주목한 메모리의 위치(=메모리의 각 위치에 대한 가중치)를 기준으로 그 전후로 이동(시프트)하는 용도로 사용됨 
* 1차원의 합성곱 연산으로 구현
* 메모리 위치를 시프트하는 이 기능을 사용하면 메모리 위치를 하나씩 옮겨가며 읽어 나가는 컴퓨터 특유의 움직임을 쉽게 재현가능

이처럼 외부 메모리를 자유롭게 이용하게 됨으로써 NTM은 큰 힘을 손에 넣게 됩니다. 
* 긴 시계열을 기억하는 문제와 
* 정렬(=수들을 크기 순으로 나열) 등의 문제 해결 가능

또한, NTM은 외부 메모리를 사용함으로써 알고리즘을 학습하는 능력을 얻음

8.6 정리
이번 장에서 배운 내용
● 번역이나 음성 인식 등, 한 시계열 데이터를 다른 시계열 데이터로 변환하는 작업에서는 시계열 데이터 사이의 대응 관계가 존재하는 경우가 많다.
● 어텐션은 두 시계열 데이터 사이의 대응 관계를 데이터로부터 학습한다.
● 어텐션에서는 (하나의 방법으로서) 벡터의 내적을 사용해 벡터 사이의 유사도를 구하고, 그 유사도를 이용한 가중합 벡터가 어텐션의 출력이 된다.
● 어텐션에서 사용하는 연산은 미분 가능하기 때문에 오차역전파법으로 학습할 수 있다.
● 어텐션이 산출하는 가중치(확률)를 시각화하면 입출력의 대응 관계를 볼 수 있다.
● 외부 메모리를 활용한 신경망 확장 연구 예에서는 메모리를 읽고 쓰는 데 어텐션을 사용했다.





