---
title: "[22] CS231N: Lecture 2 Image Classification"
date:   2020-02-16
excerpt: "Lecture 1 | Introduction to Convolutional Neural Networks for Visual Recognition 요약"
category: [Deep Learning]
layout: post
tag:
- Deep Learning
order: 0

comments: true
---


# 목차




----


# Image Classification
[지난 강의](https://yerimoh.github.io/DL22/)에서 Image Classification에 대해 간략히 말했다.      

Image Classification은 컴퓨터비전 분야에서는 Core Task 에 속함


Image Classification 방법
1) 우선 입력 이미지를 받음   
2) 이미지을 보고 어떤 카테고리에 속할지 고름

## TASK
예시로 여기 귀여운 고양이사진이 한 장 있음

그리고 시스템에는 우리가 미리 정해놓은 정답 레이블, 즉 카테고리 집합이 있음   
➡️ 카테고리에는 가령 개, 고양이, 트럭, 비행기 등이 있을 수 있다.

이제 컴퓨터가 해야 할 일은 이미지을 보고 어떤 카테고리에 속할지 고르는 것임   
➡️ 우리의 시각체계는 이와 같은 시각인식 테스크에 고도화 되어 있기 때문에 쉬워보임    
➡️ 하지만 기계에계는 정말 어려운 일임

![image](https://user-images.githubusercontent.com/76824611/162123486-b24daa6d-1136-4680-8f36-b202567c8927.png)


## PROBLEM: 의미적론적인 차이(Semantic gap)  
컴퓨터에게 이미지는 아주 큰 격자 모양의 숫자집합으로밖에 보이지 않기 때문    
아래와 같이 가령 800x600 이미지 같이 말이죠   
그리고 각 픽셀은 세 개의 숫자(red, green, blue)로 표현함   
➡️ 다시 말하자면, 컴퓨터에게 이미지란 단지 거대한 숫자 집합에 불과함    
➡️ 이 거대한 숫자집합에서 "고양이"를 인식하는 것은 상당히 어려워 보임
![image](https://user-images.githubusercontent.com/76824611/162123773-6c53cf39-657f-4490-a7a7-504011ce5731.png)

위의 문제들을 의미적론적인 차이(Semantic gap)라고 함.   
* **의미적론적인 차이(Semantic gap)**
  * **의미**: "고양이"라는 레이블은 우리가 이 이미지에 붙힌 의미상의 레이블임, 즉 이미지가 고양이사진이라는 사실과 실제 컴퓨터가 보는 픽셀 값과는 큰 차이가 있음     
  * **문제**: 고양이가 가만히 있지만은 아닌데 이미지에 아주 미묘한 변화만 주더라도 픽셀 값들은 모조리 변하게 되어 이미지 분류가 어려워짐       
  하지만 픽셀값이 모조리 달라져도 같은 고양이임     
  * **개선점**: 우리가 만든 알고리즘은 이런 것들에 강인해야 함.     
  ![image](https://user-images.githubusercontent.com/76824611/162124426-1f7a2324-8a70-4f1a-978f-a779b239d3fb.png)


<details>
<summary>📜 이미지 분류 시 문제점 더 보기</summary>
<div markdown="1">
  
![image](https://user-images.githubusercontent.com/76824611/162125784-1569d217-2cfa-483a-9edf-4b1d6fbfde4e.png)
![image](https://user-images.githubusercontent.com/76824611/162125809-901bd940-3eec-42b0-a09b-2beca5ece3ec.png)
![image](https://user-images.githubusercontent.com/76824611/162125817-2798ad62-5ee4-46d4-ab23-8c530abe845f.png)
![image](https://user-images.githubusercontent.com/76824611/162125828-5a649381-d429-490a-af72-efe135a483ee.png)
![image](https://user-images.githubusercontent.com/76824611/162125835-ae440005-e114-466f-bd8d-4b3c29f36d34.png)
![image](https://user-images.githubusercontent.com/76824611/162125841-596512fa-b102-413c-86df-0e1ce4692948.png)
![image](https://user-images.githubusercontent.com/76824611/162125851-28085241-3b8a-454c-8f66-6bddcd3546f0.png)
 
  
</div>
</details>  
  


위와 같은 challengef를 모두 해결해내는 것은 기적에 가깝다고 봄.    



하지만 만약 일부 제한된 상황을 가정한다면, 정말 잘 동작 할 뿐만 아니라, 인간의 정확도와도 맞먹는 프로그램이 존재할 수도 있음

수행 시간도 수백ms 밖에 걸리지 않음

앞으로의 수업에서 어떤 요소들이 이를 가능하게 만들었는지 살펴 볼 것임


---
----



# Nearest neighbor Classifier
이 NN 알고리즘은 상당히 단순한 Classifier임.    

**[Train Step]**   
아무 일도 하지 않음     
➡️ 단지 모든 학습 데이터를 기억함.

**[Pridict Step]**   
Pridict Step에서는 새로운 이미지가 들어오면,   
새로운 이미지와 기존의 학습 데이터를 비교해서 가장 **유사한 이미지로 레이블링을 예측**합니다.    

![image](https://user-images.githubusercontent.com/76824611/162126814-ef50ea7f-7f4b-48bd-ba16-2d85242f0b4b.png)


**[평가]**   
아주 단순하지만 Data-driven Approach로서 아주 좋은 알고리즘입니다.     



<details>
<summary>📜 Data-driven Approach 더 알아보기</summary>
<div markdown="1">
  
데이터 기반 접근 방식은 의사 결정이 관찰보다는 하드 데이터의 분석 및 해석을 기반으로 하는 경우입니다. 데이터 기반 접근 방식은 솔루션과 계획이 직감, 감정 및 일화적인 증거가 아닌 사실적 정보 집합에 의해 지원되도록 합니다. 데이터 주도의 의미는 통찰력과 솔루션을 도출하기 위해 데이터를 수집하고 분석하는 관행입니다.    

데이터 기반 접근 방식은 과거 및 현재 정보를 사용하여 미래를 예측하는 데 도움이 됩니다. 데이터가 없으면 잘못된 가정을 하고 편향된 의견에 휘둘릴 위험이 있습니다. 오늘날 기업은 시장에서 우수성을 달성하기 위해 빅 데이터 분석, 진단 모델링 및 데이터 처리를 수행합니다.    
  
[출처: harappa.education]
  
  
</div>
</details>  



좀 더 구체적으로 살펴보기 위해 CIFAR-10 데이터셋을 사용해 보겠다.   


<details>
<summary>📜 CIFAR-10 데이터셋 더 알아보기</summary>
<div markdown="1">
  
Cifar-10은 Machine Learning에서 자주 쓰는 연습용(테스트용) 데이터셋입니다.

CIFAR-10에는 비행기, 자동차, 새, 고양이 등 10가지 클래스가 있습니다.


10가지 각 카테고리가 있고 총 50,000여개의 학습용 이미지가 있습니다.

50,000여개의 데이터는 각 카테고리에 균일하게 분포하고 있죠.

그리고 알고리즘 테스트용 10,000여개의 테스트 이미지가 있습니다.
  
</div>
</details>  





## NN with CIFAR-10
자 그러면 CIFAR-10 데이터셋을 이용한 NN예제를 살펴보겠다.

**[CIFAR-10]**    
테스트 이미지: 오른쪽 칸의 맨 왼쪽 열    
오른쪽 방향: 학습 이미지 중 테스트 이미지와 유사한 순으로 정렬   
테스트 이미지와 학습 이미지를 비교해 보면, 눈으로 보기에는 상당히 비슷해 보임(그렇다고 다 맞는건 아님)    
![image](https://user-images.githubusercontent.com/76824611/162139238-2ced025b-2f8e-4ccd-943b-b2a9ba317fb5.png)



이미지가 clean하진 않지만 두 번째 행을 확대하여 자세히 보면 두번쨰 행의 이미지는 개이다.          
그리고 가장 가까운 이미지(1등)도 개 입니다.   
하지만 2등, 3등을 살펴보면 "사슴"이나 "말"같아 보이는 잘못된 이미지들도 보인다   
➡️ 개는 아니지만 눈로 보기에는 아주 비슷해 보임    
![image](https://user-images.githubusercontent.com/76824611/162140320-04bb52f8-42fb-460b-82f4-ff93f1b4099b.png)


**[NN 적용]**   
이 이미지에 NN 알고리즘을 적용하면,   
트레이닝 셋에서 **"가장 가까운 샘플"** 을 찾게됨  
➡️ 그렇게 찾은 "가장 가까운 샘플"의 레이블을 알 수 있음  
➡️ 이 샘플들은 "학습 데이터"이기때문   


### L1 Distance   
NN의 목표: 위 사진의 오른쪽 처럼 테스트 이미지와 비슷한 이미지들이 여러장 있을 때, 어떻게 비교를하려 가장 비슷한 이미지를 찾는냐이다.      

테스트 이미지 하나를 모든 학습 이미지들과 비교할 때 여러가지 비교 방법들이 있는데 이 비교방법들은 "어떤 비교 함수를 사용할지"에 따라 여러 종류로 나뉨

앞선 예제에서는 L1 Distance(= Manhattan distance)를 사용함.        

**[작동 방법]**    
![image](https://user-images.githubusercontent.com/76824611/162143271-fdbc9d91-001e-4b31-bf9f-1ec9d458c5fa.png)
이미지를  Pixel-wise로 비교한다   
가령 4x4 테스트 이미지가 있다고 가정해보면, 
1) 테스트/트레이닝 이미지의 같은 자리의 픽셀을 서로 빼고 절댓값을 취함.
2) 이렇게 픽셀 간의 **차이 값을 계산**하고 모든 픽셀의 수행 결과를 모두 더함.    
![image](https://user-images.githubusercontent.com/76824611/162143728-a22fb93c-b8de-49df-b313-082f9cce8f67.png)
지금 예제의 경우에는 두 이미지간에 "456" 만큼 차이가 난다는 것을 알 수 있다.      
Image Classification 문제에서 이 방법의 효율성이 높지 않지만 연습용으론 해볼만 하다


### 코드 구현
NN Classifier를 구현한 Python 코드는 상당히 짧고 간결함.
➡️ NumPy에서 제공하는 Vectorizaed operations을 이용했기 때문      



```python
import numpy as np

class NearestNeighbor(object):
  def __init__(self):
    pass
   
  # 앞서 말했듯, NN의 경우 Train 함수가 상당히 단순함
  # 단지 학습 데이터를 기억하는 것임(memorize trainning data)
  def train(self, X, y):
    """ X is N x D where each row is an example. Y is 1-dimension of size N """
    # the nearest neighbor classifier simply remembers all the training data
    self.Xtr = X
    self.ytr = y


  # Test 함수에서는 이미지를 입력으로 받음
  # output size와 input size를 맞춰줘야함
  # L1 Distance로 비교함
  # 학습 데이터들 중 테스트 이미지와 가장 유사한 이미지들을 찾아냄
  def predict(self, X):
    """ X is N x D where each row is an example we wish to predict label for """
    num_test = X.shape[0]
    # lets make sure that the output type matches the input type
    Ypred = np.zeros(num_test, dtype = self.ytr.dtype)

    # loop over all test rows
    for i in range(num_test):
      # find the nearest training image to the i'th test image
      # using the L1 distance (sum of absolute value differences)
      distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = 1)
      min_index = np.argmin(distances) # get the index with smallest distance
      Ypred[i] = self.ytr[min_index] # predict the label of the nearest example

    return Ypred
```



첫째, Trainset의 이미지가 총 N개라면
Train/Test 함수의 속도는 어떻게 될까요?

179
00:18:12,233 --> 00:18:17,878
우선 Train time은 상수시간 O(1) 일테죠
데이터를 기억만 하면 됩니다.

180
00:18:17,878 --> 00:18:22,703
포인터만 잘 사용해서 복사를 하면, 데이터 크기와 상관없이
상수시간으로 끝마칠 수 있습니다.

181
00:18:22,703 --> 00:18:31,099
하지만 Test time에서는 N개의 학습 데이터 전부를
테스트 이미지와 비교해야만 합니다.

182
00:18:31,099 --> 00:18:33,766
상당히 느린 작업입니다.

183
00:18:34,991 --> 00:18:38,641
상당히  "뒤집어진"  것이죠
(Train TIme < Test  TIme)

184
00:18:38,641 --> 00:18:45,326
실제로 우리는 "Train Time은 조금 느려도 되지만"
"Test Time에서는 빠르게 동작"하길 원합니다

185
00:18:45,326 --> 00:18:49,882
가령 여러분이 데이터 센터에서
어떤 Classifier를 학습시키고 있다고 생각해보면

186
00:18:49,882 --> 00:18:54,640
Classifier의 좋은 성능을 보장하기 위해서
Train Time에 많은 시간을 쏟을 수도 있겠죠.

187
00:18:54,640 --> 00:18:57,566
하지만 이 Classifier의 "Test Time" 을 생각해보면

188
00:18:57,566 --> 00:19:02,248
이 모델이 핸드폰이나, 브라우저와 등
Low Power Device에서 동작해야 할 수도 있습니다.

189
00:19:02,248 --> 00:19:07,075
이런 상황에서는 Classifier가 Test Time에서
어느정도 빠른 성능을 보장해야 할 것입니다.

190
00:19:07,075 --> 00:19:11,826
그런 관점에서 NN 알고리즘은
정 반대의 경우입니다.

191
00:19:11,826 --> 00:19:18,286
 CNN 같은 parametic model들은
NN과는 정 반대입니다.

192
00:19:18,286 --> 00:19:24,936
Train TIme은 엄청 오래 걸릴지 모르나
Test Time은 엄청 빠릅니다.

193
00:19:24,936 --> 00:19:30,816
그렇다면 NN알고리즘을 실제로 적용해 본다면 어떻게 생겼을까요?

194
00:19:30,816 --> 00:19:36,130
 NN의 "decision regions" 을 한번 그려 보았습니다.

195
00:19:36,130 --> 00:19:47,547
2차원 평면 상의 각 점은 학습 데이터 입니다. 그리고
점의 색은 클래스 레이블(카테고리) 입니다.

196
00:19:47,547 --> 00:19:53,921
이 예제에서는 클래스가 5개군요. 왼쪽 구석에는
파란색이 있고 오른쪽 구석에는 보라색이 있습니다.

197
00:19:53,921 --> 00:20:02,560
2차원 평면 내의 모든 좌표에서
각 좌표가 어떤 학습 데이터와 가장 가까운지 계산합니다.

198
00:20:02,560 --> 00:20:06,954
그리고 각 좌표를 해당 클래스로 칠했습니다.

199
00:20:06,954 --> 00:20:14,979
NN 분류기는 공간을 나눠서
각 레이블로 분류합니다.

200
00:20:14,979 --> 00:20:18,320
하지만 이 분류기는
그닥 좋지 않습니다.

201
00:20:18,320 --> 00:20:24,676
이 그림을 보면 NN 분류기에서 발생 가능한
문제들을 살펴볼 수 있습니다.

202
00:20:24,676 --> 00:20:31,591
가령 가운데를 보시면, 대부분이 초록색 점들인데
중간에 노란 점이 끼어있습니다.

203
00:20:31,591 --> 00:20:40,087
NN 알고리즘은 "가장 가까운 이웃" 만을 보기 때문에, 녹색
무리 한 가운데 노란색 영역이 생겨 버립니다. 좋은 일은 아니죠

204
00:20:40,087 --> 00:20:44,081
사실은 노란색이 아닌 초록색 영역이어야만 합니다.

205
00:20:44,081 --> 00:20:50,225
그리고 유사하게 초록색 영역이
파란색 영역을 침범하고 있습니다.

206
00:20:50,225 --> 00:20:55,180
이 또한 초록색 점이 끼어들어서 그렇습니다.
아마 이 점은 잡음(noise)이거나 가짜(spurious)일테죠

207
00:20:55,180 --> 00:21:01,606
이러한 문제들이 발생하기 때문에 NN의 조금 더
일반화된 버전인 k-NN 알고리즘이 탄생하였습니다.

208
00:21:01,606 --> 00:21:08,021
단순하게 가장 가까운 이웃만 찾기보다는
조금 더 고급진 방법을 도입할 것입니다.

209
00:21:08,021 --> 00:21:15,057
Distance metric을 이용해서 가까운 이웃을 K개의 만큼
찾고, 이웃끼리 투표를 하는 방법입니다.

210
00:21:15,057 --> 00:21:18,733
그리고 가장 많은 특표수를 획득한 레이블로 예측합니다.

211
00:21:18,733 --> 00:21:24,148
투표를 하는 다양하고 복잡한 방법들이 있을 수 있습니다.
거리별 가중치를 고려하는 등 말이죠.

212
00:21:24,148 --> 00:21:29,810
하지만 가장 잘 동작하면서도 가장 쉬운 방법은
득표수만 고려하는 방법입니다.

213
00:21:29,810 --> 00:21:35,899
보이는 세 예제는 동일한 데이터를 사용한
k-nn 분류기들입니다.

214
00:21:35,899 --> 00:21:43,792
각각 K=1/3/5 에서의 결과입니다.
우선, K=3 의 경우를 살펴봅시다.

215
00:21:43,792 --> 00:21:50,966
앞서 초록색 영역에 자리 잡았던 노란색 점 때문에
생긴 노란 지역이 깔끔하게 사라졌습니다.

216
00:21:50,966 --> 00:21:55,852
이제는 중앙은 초록색이
깔끔하게 점령했습니다.

217
00:21:55,852 --> 00:22:02,454
그리고 왼쪽의 빨강/파랑 사이의 뾰족한 경계들도 점차
부드러워지고 있습니다. 다수결의 힘이죠.

218
00:22:02,454 --> 00:22:12,064
자 그럼 K=5의 경우를 살펴보겠습니다.
파란/빨간 영역의 경계가 이제는 아주 부드럽고 좋아졌습니다.

219
00:22:12,064 --> 00:22:20,771
대게 NN분류기를 사용하면, K는 적어도 1보다는 큰 값으로 사용합니다.

220
00:22:20,771 --> 00:22:26,064
왜냐하면  K가 1보다 커야 결정 경계가 더 부드러워지고
더 좋은 결과를 보이기 때문입니다.

221
00:22:29,252 --> 00:22:30,159
질문있나요?

222
00:22:30,159 --> 00:22:34,279
[질문하는 학생]

223
00:22:34,279 --> 00:22:38,133
질문은 "레이블링이 안된 흰색 지역은 어떻게 처리하는지?" 입니다.

224
00:22:38,133 --> 00:22:45,521
흰색 영역은 k-nn이 "대다수"를 결정할 수 없는 지역입니다.
물론 흰색 영역을 매꿀 수 있는 더 좋은 방법들도 있습니다.

225
00:22:45,521 --> 00:22:50,472
어떤 식으로든 추론을 해보거나, 임의로 정할 수도 있습니다.

226
00:22:50,472 --> 00:22:55,668
하지만 여기에서는 단순한 예제라서 가장 가까운 이웃이
존재하지 않으면 단순하게 흰색으로 칠했습니다.

227
00:23:00,005 --> 00:23:06,616
여러분이 Computer Vision을 공부하는 동안에
다양한 관점을 유연하게 다루는 능력은 매우 유용합니다.

228
00:23:06,616 --> 00:23:13,049
그 중 하나는 바로 이미지를 고차원 공간에 존재하는 하나의 점이라고
생각하는 것입니다. 반대로 이미지를 이미지 자체로 볼 수도 있겠죠

229
00:23:13,049 --> 00:23:23,395
이미지의 픽셀들을 하나의 고차원 벡터로 생각하는 관점이죠.
이 두 관점을 자유롭게 오갈 수 있는 능력은 아주 유용합니다.

230
00:23:23,395 --> 00:23:29,443
이미지를 다루는 문제에서 k-nn을 사용하는
전략은 그닥 좋은 방법이 아닙니다.

231
00:23:29,443 --> 00:23:38,288
잘 분류되었는지 아닌지를 초록/빨간색으로 표기했습니다.
성능이 별로 안 좋습니다.

232
00:23:38,288 --> 00:23:47,264
K값을 높히면 어떻까요? 가장 가까운 이웃 뿐만 아니라
Top-3/Top-5 혹은 모든 행(Row)을 사용하면 어떨까요?

233
00:23:47,264 --> 00:23:55,325
더 많은 이웃들이 투표에 참여하면 각종 잡음들에
조금 더 강인해 질 것임을 추측할 수 있습니다.

234
00:23:57,070 --> 00:24:05,727
k-nn을 사용할 때 결정해야 할 한 가지 사항이 더 있습니다.
바로 서로 다른 점들을 어떻게 비교할 것인지 입니다.

235
00:24:05,727 --> 00:24:15,126
지금까지는 L1 Distance을 이용했습니다.
"픽셀 간 차이 절대값의 합" 입니다.

236
00:24:15,126 --> 00:24:24,491
하지만 L2, 즉 Euclidean distance를 사용해도 되겠죠
"제곱 합의 제곱근"을 거리로 이용하는 방법입니다.

237
00:24:24,491 --> 00:24:28,727
어떤 "거리 척도(distance metric)" 을 선택할지는
아주 흥미로운 주제입니다.

238
00:24:28,727 --> 00:24:35,386
왜냐하면 서로 다른 척도에서는 해당 공간의
근본적인 기하학적 구조 자체가 서로 다르기 떄문입니다.

239
00:24:35,386 --> 00:24:45,020
왼쪽에 보이는 사각형은 사실 L1 Distance의 관점에서는 원입니다.
생긴 모습은 원점을 기준으로 하는 사각형의 모양이죠

240
00:24:45,020 --> 00:24:51,017
 L1의 관점에서는 사각형 위의 점들이 모두
원점으로부터 동일한 거리만큼 떨어져 있습니다.

241
00:24:51,017 --> 00:24:57,241
반면 L2, Euclidean distance 의 관점에서는 원입니다.
우리가 예상했던 바로 그 원입니다.

242
00:24:57,241 --> 00:25:05,135
이 두 가지 거리 척도간에는 아주 흥미로운 차이점이 있습니다.
L1은 어떤 좌표 시스템이냐에 따라 많은 영향을 받습니다.

243
00:25:05,135 --> 00:25:10,201
가령 기존의 좌표계를 회전시키면
L1 distance가 변합니다.

244
00:25:10,201 --> 00:25:18,281
반면 L2 Distance의 경우에는 좌표계와 아무 연관이 없습니다.

245
00:25:18,281 --> 00:25:24,791
만약 특징 벡터의 각각 요소들이 개별적인 의미를
가지고 있다면(e.g. 키 몸무게)

246
00:25:24,791 --> 00:25:27,935
L1 Distance가 더 잘 어울릴 수도 있습니다.

247
00:25:27,935 --> 00:25:37,531
하지만 특징 벡터가 일반적인 벡터이고, 요소들간의 실질적인 의미를 잘 모르는
경우라면, 아마도 L2 Distance가 조금은 더 잘 어울릴 수 있습니다.

248
00:25:37,531 --> 00:25:46,343
여기에서 주목할 점은 k-nn에 다양한 거리 척도를 적용하면
k-nn으로 다양한 종류의 데이터를 다룰 수 있다는 점입니다.

249
00:25:46,343 --> 00:25:51,410
벡터나 이미지 외에도 말이죠. 가령 문장을 분류하는 문제가 있다고 해봅시다.

250
00:25:51,410 --> 00:25:57,716
k-nn 분류기로 이 문제를 다루려면
어떤 거리 척도를 사용할지만 정해주면 됩니다.

251
00:25:57,716 --> 00:26:03,831
두 문장 간의 거리를 측정할 수 있는 어떤 것이든 사용하면 됩니다.

252
00:26:03,831 --> 00:26:12,701
거리 척도만 정해주면 어떤 종류의 데이터도 다룰 수 있습니다.

253
00:26:12,701 --> 00:26:20,283
k-nn은 아주 단순한 알고리즘입니다. 하지만 새로운 문제를
접했을 때  간단히 시도해 볼만한 아주 좋은 알고리즘입니다.

254
00:26:21,805 --> 00:26:28,441
자 그러면 어떤 거리 척도를 사용하는지에 따라서
실제 기하학적으로 어떻게 변하는지 알아봅시다.

255
00:26:28,441 --> 00:26:38,087
양 쪽 모두 동일한 데이터입니다. 다만 왼쪽은 L1 Distance를
오른쪽은 L2 Distance를 사용했습니다.

256
00:26:38,087 --> 00:26:44,093
결과를 보시면 거리 척도에 따라서 결정 경계의 모양
자체가 달라짐을 알 수 있습니다.

257
00:26:44,093 --> 00:26:49,337
왼쪽의 L1 Distance를 살펴보면 결정 경계가
"좌표 축"에 영향을 받는 경향을 알 수 있습니다.

258
00:26:49,337 --> 00:26:53,451
L1 Distance가 좌표 시스템의 영향을 받기 때문입니다.

259
00:26:53,451 --> 00:27:00,294
반면 L2 Distance는 좌표 축의 영향을 받지 않고 결정
경계를 만들기 때문에 조금 더 자연스럽습니다.

260
00:27:04,161 --> 00:27:14,618
지금까지의 모든 예제는 저의 웹 데모사이트에서 가져왔습니다.
여러분은 여기에서 여러분만의 k-nn 분류기를 설계할 수 있습니다.

261
00:27:14,618 --> 00:27:23,854
이 프로텍터 스크린으로 보여드리기가 참 어렵군요
집에가서 한번 해보시기 바랍니다.

262
00:28:07,103 --> 00:28:09,679
좋습니다 말썽이 좀 있었습니다

263
00:28:09,679 --> 00:28:13,496
오늘은 웹 데모를 생략하겠습니다만
꼭 한번 해보시기 바랍니다.

264
00:28:13,496 --> 00:28:26,029
상당히 재미있습니다. K와  리 척도를 바꿔보면서 어떻게
결정 경계가 만들어지는지에 대한 직관을 얻으시길 바랍니다.

265
00:28:30,641 --> 00:28:37,178
여러분이 k-nn을 사용하려고 한다면
반드시 선택해야 하는 몇 가지 항목이 있습니다.

266
00:28:37,178 --> 00:28:41,520
앞서 K에 대해서 이야기했습니다.
L1/L2와 같은 거리 척도 또한 다뤘죠

267
00:28:41,520 --> 00:28:47,286
그렇다면 어떻게 하면 "내 문제"와 "데이터"에
꼭 맞는 모델을 찾을 수 있을까요?

268
00:28:47,286 --> 00:28:53,937
K와 거리척도를 "하이퍼 파라미터" 라고 합니다.

269
00:28:53,937 --> 00:29:01,313
하이퍼파라미터는 Train time에 학습하는 것이 아니므로
여러분이 학습 전 사전에 반드시 선택해야만 합니다.

270
00:29:01,313 --> 00:29:05,623
데이터로 직접 학습시킬 방법이 없습니다.

271
00:29:05,623 --> 00:29:10,260
그렇다면 하이퍼파라미터를 어떻게 정해야 할까요?

272
00:29:10,260 --> 00:29:12,277
하이퍼 파라미터를 정하는 일은
문제의존적(problem-dependent)입니다.

273
00:29:12,277 --> 00:29:20,950
가장 간단한 방법은 데이터에 맞게 다양한
하이퍼파라미터 값을 시도해 보고 가장 좋은 값을 찾습니다.

274
00:29:20,950 --> 00:29:22,404
질문있나요?

275
00:29:22,404 --> 00:29:26,071
[질문하는 학생]

276
00:29:29,589 --> 00:29:34,447
질문은 "어떤 경우에 L1 Distance가
L2 Distance보다 더 좋은지" 입니다.

277
00:29:34,447 --> 00:29:36,800
그것은 문제의존적(problem-dependent)입니다.

278
00:29:36,800 --> 00:29:41,204
어떤 경우에  L1/L2를 써야 하는지
결정하는 것은 어렵겠지만

279
00:29:41,204 --> 00:29:50,185
 L1은 좌표계에 의존적이므로 여러분의 데이터가
좌표계에 의존적인지를 판단하는 것이 판단 기준이 될 수 있습니다.

280
00:29:50,185 --> 00:29:55,513
여러분에게 어떤 특징 벡터가 있고 각 요소가
어떤 특별한 의미를 지니고 있다면

281
00:29:55,513 --> 00:30:03,976
가령 직원들을 분류하는 문제가 있을 때, 데이터의 각 요소가
직원들의 다양한 특징에 영향을 줄 수 있습니다.

282
00:30:03,976 --> 00:30:08,778
가령 봉급, 근속년수와 같은 예가 될 수 있겠습니다.

283
00:30:08,778 --> 00:30:15,850
이처럼 각 요소가 특별한 의미를 가지고 있다면
L1 을 사용하는것이 좀 더 괜찮을 지도 모릅니다.

284
00:30:15,850 --> 00:30:19,989
하지만 일반적으로는 하이퍼파라미터 선택은
어떤 문제와 데이터인지에 의존적입니다.

285
00:30:19,989 --> 00:30:24,381
하이퍼파라미터는 단지 여러가지 시도를 해보고
좋은 것을 선택하는 것이 좋습니다.

286
00:30:28,381 --> 00:30:34,238
하지만 하이퍼파라미터 값들을 실험해 보는 작업도 다양합니다.

287
00:30:34,238 --> 00:30:38,268
"다양한 하이퍼 파라미터를 시도해 보는 것" 과
"그중 최고를 선택하는 것" 이 무슨 뜻일까요?

288
00:30:38,268 --> 00:30:42,911
가장 먼저 떠올릴 수 있는 아이디어는
아주 단순합니다.

289
00:30:42,911 --> 00:30:47,691
"학습데이터의 정확도와 성능"를 최대화하는
하이퍼파라미터를 선택하는 것이죠.

290
00:30:47,691 --> 00:30:52,137
사실 정말 끔찍한 방법입니다.
절대로 이렇게 해서는 안됩니다.

291
00:30:52,137 --> 00:31:00,157
가령 NN 분류기의 경우 K = 1 일 때
학습 데이터를 가장 완벽하게 분류합니다.

292
00:31:01,124 --> 00:31:04,420
앞서 말씀드린 전략대로라면(트레이닝 데이터의 정확도를 올리는)
항상 K = 1 일 때가 최고입니다.

293
00:31:04,420 --> 00:31:13,184
하지만 앞선 예제에서도 보았듯이, 실제로는 K를 더 큰 값으로 선택하는 것이
학습 데이터에서는 몇 개 잘못 분류할 수는 있지만

294
00:31:13,184 --> 00:31:17,915
학습 데이터에 없던 데이터에 대해서는
더 좋은 성능을 보일 수 있습니다.

295
00:31:17,915 --> 00:31:24,463
궁극적으로 기계학습에서는 학습 데이터를 얼마나 잘 맞추는지는
중요하지 않습니다. 우리가 학습시킨 분류기가

296
00:31:24,463 --> 00:31:27,051
한번도 보지 못한 데이터를 얼마나 잘 예측하는지가 중요하죠

297
00:31:27,051 --> 00:31:30,495
그러므로 학습 데이터에만 신경쓰는 것은 최악입니다.
비추입니다.

298
00:31:30,495 --> 00:31:38,390
또 다른 아이디어가 있습니다. 전체 데이터셋 중 학습 데이터를 쪼개서
일부를 테스트 데이터로 사용하는 것입니다.

299
00:31:38,390 --> 00:31:53,716
학습 데이터로 다양한 하이퍼파라미터 값들을 학습을 시키고 테스트
데이터에 적용시켜본 다음, 하이퍼파라미터를 선택하는 방법이죠

300
00:31:54,582 --> 00:32:01,087
이 방법이 조금 더 합리적인 것 같지만 사실은,
이 방법 또한 아주 끔찍한 방법입니다. 절대 하면 안됩니다.

301
00:32:01,087 --> 00:32:06,515
다시한번 기계학습의 궁극적인 목적을 말씀드리자면
한번도 보지 못한 데이터에서 잘 동작해야 합니다.

302
00:32:06,515 --> 00:32:14,523
테스트셋으로는 한번도 보지 못했던 데이터에서의
알고리즘의 성능을 측정할 수 있어야 합니다.

303
00:32:14,523 --> 00:32:23,363
그런데 만약 학습시킨 모델들 중
테스트 데이터에 가장 잘 맞는 모델을 선택한다면

304
00:32:23,363 --> 00:32:31,663
우리는 그저 "테스트 셋에서만"  잘 동작하는
하이퍼파라미터를 고른 것일 수 있습니다.

305
00:32:31,663 --> 00:32:38,280
그렇게 되면,  더이상 테스트 셋에서의 성능은 한번도 보지못한
데이터에서의 성능을 대표할 수는 없습니다.

306
00:32:38,280 --> 00:32:44,672
그러니 이 또한 하지 말아야 합니다. 좋은 생각이 아닙니다.
그렇게 하면 곤경에 빠질 것입니다.

307
00:32:44,672 --> 00:32:49,192
훨씬 더 일반적인 방법은 데이터를 세 개로 나누는 것입니다.

308
00:32:50,185 --> 00:32:57,305
데이터의 대부분은 트레이닝 셋으로 나누고, 일부는
밸리데이션 셋, 그리고 나머지는 테스트 셋으로 나눕니다

309
00:32:57,305 --> 00:33:03,500
그리고 다양한 하이퍼파라미터로 "트레이닝 셋" 을 학습시킵니다.

310
00:33:03,500 --> 00:33:11,621
그리고 "벨리데이션 셋" 으로 검증을 합니다. 그리고 벨리데이션 셋에서
가장 좋았던 하이퍼파라미터를 선택합니다.

311
00:33:11,621 --> 00:33:16,627
그리고 최종적으로 개발/디버깅 등 모든 일들을 다 마친 후에

312
00:33:16,627 --> 00:33:23,401
 벨리데이션 셋에서 가장 좋았던 분류기를 가지고
테스트 셋에서는  "오로지 한번만" 수행합니다.

313
00:33:23,401 --> 00:33:27,139
이 마지막 수치가 여러분의 논문과 보고서에 에 삽입될 것입니다.

314
00:33:27,139 --> 00:33:32,393
그 숫자가 여러분의 알고리즘이 한번도 보지 못한 데이터에
얼마나 잘 동작해 주는지를 실질적으로 말해줄 수 있는 것입니다.

315
00:33:32,393 --> 00:33:38,847
그리고 실제로 벨리데이션 데이터와 테스트 데이터를
엄격하게 나눠놓는 것은 상당히 중요합니다.

316
00:33:38,847 --> 00:33:45,653
가령, 우리는 연구 논문을 작성할때
테스트 셋을 거의 마지막 쯤에야 한번 사용합니다.

317
00:33:45,653 --> 00:33:54,159
저는 논문을 쓸때 마감 일주일 전 부터만
테스트 셋을 사용합니다.

318
00:33:54,159 --> 00:34:00,102
우리는 정직하게 연구를 수행했고 논문의 수치를 공정하게 측정했다는
것을 보장하기 위해서죠. 상당히 중요합니다.

319
00:34:00,102 --> 00:34:03,883
여러분은 여러분의 테스트 데이터를 잘 통제해야만 합니다.

320
00:34:06,468 --> 00:34:10,840
또 다른 하이퍼파라미터 선택 전략은
크로스 벨리데이션(교차 검증) 입니다.

321
00:34:10,840 --> 00:34:17,317
사실 이 방법은 작은 데이터셋일 경우 많이 사용하고
딥러닝에서는 많이 사용하진 않습니다.

322
00:34:17,317 --> 00:34:25,534
이 아이디어는, 우선 테스트 데이터를 정해놓습니다.
테스트 데이터는 아주 마지막에만 사용할 것입니다.

323
00:34:25,534 --> 00:34:35,515
그리고 나머지 데이터는 트레이닝/벨리데이션 으로 딱 나눠 놓는 대신에
트레이닝 데이터를 여러 부분으로 나눠줍니다.

324
00:34:35,516 --> 00:34:41,415
이런 식으로 번갈아가면서 벨리데이션 셋을 지정해 줍니다.

325
00:34:41,415 --> 00:34:45,498
이 예제에서는 5-Fold Cross Validation을 사용하고 있습니다.

326
00:34:45,498 --> 00:34:51,928
처음 4개의 fold에서 하이퍼 파라미터를 학습시키고
남은 한 fold에서 알고리즘을 평가합니다.

327
00:34:51,928 --> 00:35:00,293
그리고 1,2,3,5 fold에서 다시 학습시키고 4 fold로 평가합니다.
이런식으로 계속 순환합니다.

328
00:35:00,293 --> 00:35:07,511
이런 방식으로 최적의 하이퍼파라미터를 확인할 수 있을 것입니다.

329
00:35:07,511 --> 00:35:18,652
이런 방식은 거의 표준이긴 하지만 실제로는 딥러닝같은 큰 모델을 학습시킬
때는 학습 자체가 계산량이 많기 때문에 실제로는 잘 쓰지 않습니다.

330
00:35:18,652 --> 00:35:19,519
질문 있나요?

331
00:35:19,519 --> 00:35:23,186
[질문하는 학생]

332
00:35:29,515 --> 00:35:35,728
질문은 "구체적으로 트레이닝 셋과 벨리데이션 셋의 차이가 무엇인지" 입니다.

333
00:35:35,728 --> 00:35:46,974
k-NN의 예를 들어보자면 트레이닝 셋은
우리가 레이블을 기억하고 있는 이미지들 입니다.

334
00:35:46,974 --> 00:35:52,451
어떤 이미지를 분류하려면 트레이닝 데이터의
모든 이미지들과 비교하게 되겠죠

335
00:35:52,451 --> 00:36:03,184
그리고 가장 근접한 레이블을 선택합니다.
알고리즘은 트레이닝 셋 자체를 기억할 것입니다.

336
00:36:03,184 --> 00:36:08,062
이제는 벨리데이션 셋을 가져와서
트레이닝 셋과 비교합니다.

337
00:36:08,062 --> 00:36:16,815
그리고 이를 통해서 벨리데이션 셋에서는 분류기가
얼마만큼의 정확도가 나오는지 확인합니다.

338
00:36:16,815 --> 00:36:28,473
이것이 바로 트레이닝/벨리데이션 셋의 차이점 입니다. 트레이닝 셋의
레이블을 볼 수 있지만 벨리데이션 셋의 레이블은 볼 수 없습니다.

339
00:36:28,473 --> 00:36:34,043
벨리데이션 셋의 레이블은 알고리즘이
얼마나 잘 동작하는지를 확인할 때만 사용합니다.

340
00:36:34,043 --> 00:36:34,907
질문있나요?

341
00:36:34,907 --> 00:36:38,574
[학생이 질문]

342
00:36:44,373 --> 00:36:55,955
질문은 "테스트 셋이 한번도 보지 못한 데이터를 대표할 수 있는지" 입니다.
이것은 실제도 문제가 될 수 있습니다

343
00:36:55,955 --> 00:37:01,863
기본적인 통계학적 가정이 하나 있는데 여러분의 데이터는 독립적이며,
유일한 하나의 분포에서 나온다는 가정입니다 (i.i.d assumption)

344
00:37:01,863 --> 00:37:12,948
그러니 모든 데이터는 동일한 분포를 따른다고 생각해야 합니다.
물론 실제로는 그렇지 않은 경우가 많습니다.

345
00:37:12,948 --> 00:37:20,951
테스트 셋이 한번도 보지 못한 데이터를 잘 표현하지
못하는 경우를 경험하게 되실 것입니다.

346
00:37:20,951 --> 00:37:25,473
그리고 이런 류의 문제는 datasets crators와
dataset curators가 생각해 볼 문제입니다.

347
00:37:25,473 --> 00:37:28,626
하지만,가령 제가 데이터 셋을 만들때
하는 한가지 일은

348
00:37:28,626 --> 00:37:34,252
데이터를 수집할 때, 일관된 방법론을 가지고
대량의 데이터를 한번에 수집하는 전략을 사용합니다.

349
00:37:34,252 --> 00:37:38,690
그다음에 무작위로 트레이닝 데이터와
테스트 데이터를 나줘줍니다.

350
00:37:38,690 --> 00:37:43,024
한가지 주의해야 할 점은
데이터를 지속적으로 모으고 있는 경우입니다.

351
00:37:43,024 --> 00:37:51,613
먼저 수집한 데이터들을 트레이닝 데이터로 쓰고, 이후에 모은 데이터를 테스트
데이터로 사용한다면 문제가 될 수 있습니다.

352
00:37:51,613 --> 00:37:59,762
대신에 데이터셋 전체를 무작위로 섞어서 데이터셋을 나누는 것이
그 문제를 완화 시킬 수 있는 한가지 방법일 수 있습니다.

353
00:38:04,297 --> 00:38:26,961
크로스 벨리데이션을 수행하고 나면 다음과 같은 그래프를 보실 수 있습니다.
X축은 K-NN의 K입니다. 그리고 Y축은 분류 정확도입니다.

354
00:38:26,961 --> 00:38:31,705
이 경우에는 5-fold 크로스 벨리데이션을 수행하였습니다.

355
00:38:31,705 --> 00:38:38,346
각 K마다 5번의 크로스 벨리데이션을 통해
알고리즘이 얼마나 잘 동작하는지를 알려줍니다.

356
00:38:38,346 --> 00:38:50,276
그리고 "테스트셋이 알고리즘 성능 향상에 미치는 영향" 를 알아보려면
 K fold 크로스벨리데이션이 도움을 줄 수 있습니다.

357
00:38:50,276 --> 00:38:57,606
여러 validation folds 별 성능의 분산(variance)을
고려해 볼 수 있습니다.

358
00:38:57,606 --> 00:39:04,301
분산을 같이 계산하게 되면, 어떤 하이퍼파라미터가 가장
좋은지 뿐만 아니라, 그 성능의 분산도 알 수 있습니다.

359
00:39:04,301 --> 00:39:08,151
여러분이 기계학습 모델을 학습시키는 경우에
보통 이런 모습의 그래프를 그리게 될 것입니다.

360
00:39:08,151 --> 00:39:12,380
하이퍼파라미터에 따라 모댈의 정확도와
성능을 평가할 수 있습니다.

361
00:39:12,380 --> 00:39:19,995
그리고 벨리데이션 셋의 성능이 최대인
하이퍼 파라미터를 선택하게 될 것입니다.

362
00:39:19,995 --> 00:39:25,528
이 예제에서는 아마도 K = 7 일 경우에 가장 좋은 성능을 내는군요.

363
00:39:29,713 --> 00:39:34,458
하지만 실제로는 입력이 이미지인 경우에는
k-NN 분류기를 잘 사용하지 않습니다.

364
00:39:34,458 --> 00:39:38,233
앞서 이야기한 문제들 때문이죠.

365
00:39:38,233 --> 00:39:44,287
우선 한 가지 문제점은 k-nn이 너무 느리다는 것입니다. 우리가
원하는 것과 정 반대이며 이 내용은 앞서 이야기한 적이 있었습니다.

366
00:39:44,287 --> 00:39:54,495
또 하나의 문제는 L1/L2 Distance가 이미지간의 거리를
측정하기에 적절하지 않다는 점입니다.

367
00:39:54,495 --> 00:40:01,254
이 벡터간의 거리 측정 관련 함수들은(L1/L2)
이미지들 간의 "지각적 유사성"을 측정하는 척도로는 적절하지 않습니다.

368
00:40:01,254 --> 00:40:08,796
우리들은 이미지간의 차이를 어떻게 지각하는 것일까요?
가령 여기 왼쪽에 한 여성이 있습니다.

369
00:40:08,796 --> 00:40:11,234
오른쪽에는 세 개의 왜곡된 이미지가 있습니다.

370
00:40:11,234 --> 00:40:18,416
눈과 입을 가려도 보고, 몇 픽셀식 이동도 시켜보고,
전체 이미지에 파란색 색조도 추가시켜 보았습니다.

371
00:40:18,416 --> 00:40:25,425
그리고 각 이미지와 원본의 사이의 
Euclidean Distance를 측정해보면

372
00:40:25,425 --> 00:40:29,469
이들은 모두 동일한 L2 Distance를 가집니다.
좋지 않은 현상이죠

373
00:40:29,469 --> 00:40:39,119
이는 L2 Distance가 이미지들 간의 "지각적 유사도" 를
측정하기에는 적합하지 않다는 의미이기 때문입니다.

374
00:40:40,642 --> 00:40:46,819
K-NN의 또 다른 문제 중 하나는 바로
"차원의 저주" 입니다.

375
00:40:46,819 --> 00:40:51,279
K-NN을 다시한번 살펴보자면

376
00:40:51,279 --> 00:40:57,186
K-NN가 하는 일은 트레이닝 데이터를 이용해서
공간을 분할하는 일이였습니다.

377
00:40:57,186 --> 00:41:05,646
이는 K-NN이 잘 동작하려면 전체 공간을 조밀하게 커버할 만큼의 
충분한 트레이닝 샘플이 필요하다는 것을 의미합니다.

378
00:41:05,646 --> 00:41:15,004
그렇지 않다면 이웃이 사실은 엄청 멀 수도 있고 그렇게 되면 
테스트 이미지을 제대로 분류할 수 없을 것입니다.

379
00:41:16,738 --> 00:41:24,666
공간을 조밀하게 덮으려면 충분한 량의 학습 데이터가 필요하고
그 양은 차원이 증가함에 따라 기하급수 적으로 증가합니다.

380
00:41:24,666 --> 00:41:29,217
아주 좋지 않은 현상입니다. 
기하급수적인 증가는 언제나 옳지 못합니다.

381
00:41:29,217 --> 00:41:35,587
고차원의 이미지라면 모든 공간을 조밀하게 메울만큼의 
데이터를 모으는 일은 현실적으로 불가능합니다.

382
00:41:35,587 --> 00:41:41,300
K-NN을 사용할 시 여러분은 항상 이 점을  염두해야 합니다.

383
00:41:41,300 --> 00:41:45,701
요약을 해보자면 이미지 분류가 무엇인지 설명하기 위해 
K-NN 예제를 들어보았습니다.

384
00:41:45,701 --> 00:41:51,445
"이미지"와 "정답 레이블"이 있는 트레이닝 셋이 있었고
테스트 셋을 예측하는데 이용하였습니다.

385
00:41:51,445 --> 00:41:52,278
질문 있나요?

386
00:41:52,278 --> 00:41:54,519
[질문하는 학생]

387
00:41:54,519 --> 00:41:57,271
오 죄송합니다. 질문은
"이전 슬라이드의 그림이 어떤걸 의미하는지"

388
00:41:57,271 --> 00:41:59,168
"그림의 초록 점과 파란 점은 무엇인지" 입니다.

389
00:41:59,168 --> 00:42:05,596
각 점은 트레이닝 샘플들을 의미합니다.
점 하나하나가 트레이닝 샘플입니다.

390
00:42:05,596 --> 00:42:11,004
그리고 각 점의 색은 트레이닝 샘플이 속한
카테고리를 나타낸다고 보시면 됩니다.

391
00:42:11,004 --> 00:42:17,525
가령 맨 왼쪽의 1차원을 보시면 
이 공간을 조밀하게 덮으려면 트레이닝 샘플 4개면 충분합니다.

392
00:42:17,525 --> 00:42:25,529
2차원 공간을 다 덮으려면 16개가 필요합니다.
1차원의 4배 입니다.

393
00:42:25,529 --> 00:42:28,767
이렇게 3, 4, 5 차원 같이 고차원을 고려해보면

394
00:42:28,767 --> 00:42:35,200
각 공간을 조밀하게 덮기 위해 필요한 트레이닝 샘플의 수는
차원이 늘어남에 따라 기하급수적으로 증가합니다.

395
00:42:35,200 --> 00:42:40,501
그리고 가령 2차원 공간에서는 커브모양이 있습니다.

396
00:42:40,501 --> 00:42:47,641
혹은 더 높은 차원에서는 일종의 
샘플들의 manifolds가 있을 수 있습니다.

397
00:42:47,641 --> 00:42:53,029
하지만 K-NN 알고리즘은 샘플들의 manifolds를
가정하지 않기 때문에

398
00:42:53,029 --> 00:42:58,796
K-NN이 제대로 동작할 수 있는 유일한 방법은 공간을 조밀하게 
덮을 만큼 충분히 많은 트레이닝 샘플을 가지는 것입니다.

399
00:43:01,741 --> 00:43:04,915
지금까지 K-NN을 살펴보았습니다.

400
00:43:04,915 --> 00:43:11,214
첫 과제에 K-NN 실습이 있으니 실제로 
구현해 볼 기회가 있을 것입니다.

401
00:43:11,214 --> 00:43:16,059
K-NN에 관현한 질문을 받고 다음 주제로 넘어 가겠습니다.

402
00:43:16,059 --> 00:43:16,892
질문있나요?

403
00:43:16,892 --> 00:43:21,014
[학생이 질문]

404
00:43:21,014 --> 00:43:22,034
죄송하지만 다시 말해주세요

405
00:43:22,034 --> 00:43:25,951
[학생이 질문]

406
00:43:28,437 --> 00:43:32,033
질문은 "왜 저 이미지들의 L2 Distance가 
같은지" 입니다.

407
00:43:32,033 --> 00:43:35,915
제가 이 이미지들이 같은 L2 Distance를 가지도록
임의로 만들어냈기 때문입니다.

408
00:43:35,915 --> 00:43:38,716
[웃음]

409
00:43:38,716 --> 00:43:45,096
저는 단지 L2 Distance가 이미지간의 유사도을 측정하는데는
좋지 않다는 점을 강조하고 싶었습니다.

410
00:43:45,096 --> 00:43:50,223
실제로 이 이미지들은 저마다 모두 다릅니다.

411
00:43:52,470 --> 00:43:57,649
하지만 여러분이 K-NN을 사용한다면 이미지 간의
유사도를 특정할 수 있는 유일한 방법은

412
00:43:57,649 --> 00:44:00,236
바로 이 단일 거리 성능 척도(L1/L2 등)을 이용하는 수 밖에 없습니다.

413
00:44:00,236 --> 00:44:08,949
이 예시는 여러분들에게 Distance metric이 실제로는
이미지간의 유사도를 잘 포착해 내지 못한다는 것을 알려줍니다.

414
00:44:08,949 --> 00:44:15,384
이 예시에 경우에 이러한 translation과 offset에도
Distance가 일치하도록 제가 임의로 만들어낸 것입니다.

415
00:44:15,384 --> 00:44:16,217
질문 있으십니까?

416
00:44:16,217 --> 00:44:19,884
[학생이 질문]

417
00:44:28,672 --> 00:44:36,615
질문은 "이미지들이 모두 같은 사람이므로 
distance가 같으면 좋은 것 아닌지"입니다.

418
00:44:36,615 --> 00:44:41,810
이 예시에서는 그럴 수도 있습니다. 하지만 반례가 있을 수 있습니다.
가령 서로 다른 두 개의 원본 이미지가 있고

419
00:44:41,810 --> 00:44:48,316
어떤 적절한 위치에 박스를 놓거나, 색을 더하거나 하게 되면
결국 두 이미지의 Distance를 엄청 가깝게 만들 수 있을 것입니다.

420
00:44:48,316 --> 00:44:52,007
반대로 이 예시에서 똑같은 하나의 이미지에
(하나의 이미지이니 Distance가 변하면 안되지만)

421
00:44:52,007 --> 00:44:57,469
임의로 움직이거나(shift) 색을 더하면(tinting)
 Distance는 제멋대로 변할 것입니다.

422
00:44:57,469 --> 00:45:03,172
그러니 다양한 서로다른 이미지들이 같은 Distance를 가지는
경우라면 잘 못될 수도 있는 것입니다.

423
00:45:03,172 --> 00:45:04,039
질문 있으신가요?

424
00:45:04,039 --> 00:45:07,956
[학생이 질문]

425
00:45:15,207 --> 00:45:24,098
질문은 "최적의 하이퍼파라미터를 찾을 때 까지 학습을
다시 시키는 것이 흔한 방법인지" 입니다.

426
00:45:24,098 --> 00:45:30,982
실제로 사람들은 가끔 그렇게 하곤 합니다.
하지만 그때 그때 다르다고 할 수 있습니다.

427
00:45:30,982 --> 00:45:34,430
만약 여러분이 데드라인에 쫒기고 있고
당장 모델을 사용해야 한다면

428
00:45:34,430 --> 00:45:39,875
그런데 데이터 셋 전부를 다시 학습시키는 것이 너무 오래 걸리면
다시 학습시키기 쉽지 않겠죠

429
00:45:39,875 --> 00:45:50,012
하지만 다시 학습시킬 여유가 있고 1%의 성능이라도
짜내고 싶다면 여러분이 할 수있는 하나의 트릭이 될 수 있습니다.

430
00:45:53,288 --> 00:45:56,758
지금까지는 k-NN이 기계학습 알고리즘이라는 점에서
지닌 다양한 특성들에 대해 배웠습니다.

431
00:45:56,758 --> 00:46:03,823
하지만 실제로는 성능이 엄청 좋지는 않습니다.
특히 이미지에는 잘 사용하지 않습니다.

432
00:46:05,258 --> 00:46:08,895
다 그럼 다음은 
Linear Classification 입니다.

433
00:46:08,895 --> 00:46:19,845
Linear Classification 아주 간단한 알고리즘입니다. 하지만 
아주 중요하고 NN과 CNN의 기반 알고리즘이죠

434
00:46:19,845 --> 00:46:26,242
일부 사람들은 Nerural Network를 레고블럭에 비유합니다.

435
00:46:26,242 --> 00:46:30,345
NN을 구축할 때 다양한 컴포넌트들을 사용할 수 있습니다. 
이 컴넌트들을 한데 모아서

436
00:46:30,345 --> 00:46:36,378
CNN이라는 거대한 타워를 지을 수 있는 것입니다.

437
00:46:36,378 --> 00:46:43,215
앞으로 보게될 다양한 종류의 딥러닝 알고리즘들의
가장 기본이 되는 블럭중 하나가 바로 Linear classifier입니다.

438
00:46:43,215 --> 00:46:48,270
때문에 여러분이 Linear classification이 어떻게 동작하는지를
정확히 이해하는것은 아주 중요합니다.

439
00:46:48,270 --> 00:46:52,712
왜냐면 Linear classification이 결국은 전체 NN을
이루게 될 것이기 떄문이지요.

440
00:46:52,712 --> 00:46:56,139
NN의 구조적 특성을 설명하는 또 다른 예시가 있습니다.

441
00:46:56,139 --> 00:47:00,281
저희 연구실에서 진행하고 있는 
Image Captioning과 관련한 것입니다.

442
00:47:00,281 --> 00:47:06,226
Image Captioni 에서는 이미지가 입력이고 
이미지를 설명하는 문장이 출력입니다.

443
00:47:06,226 --> 00:47:14,496
이미지를 인식하기 위해서 CNN을 사용합니다.
그리고 언어를 인식하기 위해서 RNN을 사용합니다.

444
00:47:14,496 --> 00:47:22,767
우리는 그저 두개(CNN + RNN)을 레고 블럭처럼 붙히고 한번에
학습시킵니다. 그러면 이렇게 어려운 문제도 해결할 수 있는 것입니다.

445
00:47:22,767 --> 00:47:26,388
이 모델에 대에서는 앞으로 배우게 되겠지만

446
00:47:26,388 --> 00:47:36,082
여기에서 말하고 싶었던건 NN이 레고블럭과 같다는 것이고.
Linear Classifier가 그것의 기본이 블럭이 된다는 것입니다.

447
00:47:37,096 --> 00:47:41,257
하지만 2강 에서 하기엔 너무 재밌는 내용이니까
우리는 다시 CIFAR-10으로 잠시 돌아가 봐야 겠습니다.

448
00:47:41,257 --> 00:47:42,375
[웃음]

449
00:47:42,375 --> 00:47:45,641
CIFAR-10이 50,000여개의 트레이닝 샘플이 있고

450
00:47:45,641 --> 00:47:49,808
각 이미지는 32x32 픽셀을 가진
3채널 컬러 이미지라는 것을 다시 상기시켜 봅시다.

451
00:47:52,068 --> 00:47:56,696
Linear classification에서는 K-NN과는
조금은 다른 접근 방법을 이용합니다.

452
00:47:56,696 --> 00:48:04,734
Linear classifier는 "parametric model"의
가장 단순한 형태입니다.

453
00:48:04,734 --> 00:48:08,685
parametric model에는 두 개의 요소가 있습니다.

454
00:48:08,685 --> 00:48:12,201
입력 이미지가 있습니다. 
왼쪽에 보이는 고양이 이미지입니다.

455
00:48:12,201 --> 00:48:17,384
이 입력 이미지를 보통 "X" 로 씁니다.

456
00:48:17,384 --> 00:48:24,767
파라미터, 즉 가중치는 문헌에 따라 다르지만 
"W"라고도 하고 세타(theta)라도고 합니다.

457
00:48:24,767 --> 00:48:30,780
이제 우리는 어떤 함수를 작성해야 하는데
이 함수는 data X와 parameter W를 가지고

458
00:48:30,780 --> 00:48:39,991
10개의 숫자를 출력합니다. 이 숫자는
CIFAR-10의 각 10개의 카테고리의 스코어입니다.

459
00:48:39,991 --> 00:48:48,583
이 스코어를 해석해 보자면, "고양이"의 스코어가 높다는 건
입력 X가 "고양이"일 확률이 크다는 것을 의미합니다.

460
00:48:48,583 --> 00:48:49,827
질문 있으십니까?

461
00:48:49,827 --> 00:48:53,494
[학생이 질문]

462
00:48:55,380 --> 00:48:56,717
잘못들었습니다?

463
00:48:56,717 --> 00:48:58,863
[학생이 질문]

464
00:48:58,863 --> 00:49:01,524
질문은 "여기에서 3 무엇인지" 입니다.
(32 x 32 x 3 의 3 이 무엇인지 질문)

465
00:49:01,524 --> 00:49:12,636
3은 Red, Green, Blue 3 채널을 의미합니다. 보통은 컬러 
이미지를 다룹니다. 컬러 정보는 버리기 아까운 유용한 정보입니다.

466
00:49:15,323 --> 00:49:18,999
앞서 K-NN은 파라미터가 없었습니다.

467
00:49:18,999 --> 00:49:24,092
그저 전체 트레이닝 셋을 가지고 있었고
모든 트레이닝 셋을 Test time에 사용했습니다.

468
00:49:24,092 --> 00:49:28,196
하지만 parametric approach 에서는
트레이닝 데이터의 정보를 요약합니다.

469
00:49:28,196 --> 00:49:31,105
그리고 그 요약된 정보를 파라미터 W에 모아줍니다.

470
00:49:31,105 --> 00:49:35,371
이런 방식을 사용하면 Test time에서 더이상 
트레이닝 데이터가 필요하지 않습니다.

471
00:49:35,371 --> 00:49:37,938
Test time에서는 파라미터 W만 있으면 그만입니다.

472
00:49:37,938 --> 00:49:44,684
이 방법은 핸드폰과 같은 작은 디바이스에서 모델을
동작시켜야 할 때 아주 효율적입니다.

473
00:49:44,684 --> 00:49:50,906
그러니 딥러닝은 바로 이 함수 F의 구조를 
적절하게 잘 설계하는 일이라고 할 수 있습니다.

474
00:49:50,906 --> 00:49:55,406
어떤 식으로 가중치 W와 데이터를 조합할지를
여러가지 복잡한 방법으로 고려해 볼 수 있는데

475
00:49:55,406 --> 00:50:01,169
이 과정들이 모두 다양한 NN 아키텍쳐를 설계하는 과정입니다.

476
00:50:01,169 --> 00:50:05,729
가중치 W와 데이터 X를 조합하는 가장 쉬운 방법은
그냥 이 둘을 곱하는 것입니다.

477
00:50:05,729 --> 00:50:08,833
이 방법이 바로 Linear classification 입니다.

478
00:50:08,833 --> 00:50:15,770
F(x,W) = Wx 입니다.
아주 쉬운 식입니다.

479
00:50:15,770 --> 00:50:18,921
그러면 이제 이들의 차원을 한번 알아보겠습니다.

480
00:50:18,921 --> 00:50:34,715
입력 이미지는 32 x 32 x 3 이였습니다. 이 값을 길게
펴서 열 벡터로 만들면 3,072-dim 벡터가 됩니다.

481
00:50:34,715 --> 00:50:38,632
3072-dim열 벡터가 10-classes 스코어가 되어야 합니다.

482
00:50:39,746 --> 00:50:44,236
이는 10개 카테고리에 해당하는 각 스코어를 의미하는
10개의 숫자를 얻고 싶은 것입니다.

483
00:50:44,236 --> 00:50:49,032
따라서 행렬 W는 10 x 3072가 되어야 합니다.

484
00:50:49,032 --> 00:50:57,086
이 둘을 곱하면 10-classes 스코어를 의미하는
10 x 1 짜리 하나의 열 벡터를 얻게 됩니다.

485
00:50:57,086 --> 00:51:01,910
그리고 가끔은 "Bias" 을 보게 될텐데 
가끔 Bias term도 같이 더해주기도 합니다.

486
00:51:01,910 --> 00:51:06,669
Bias term은 10-dim 열 벡터입니다. 
Bias term은 입력과 직접 연결되지 않습니다.

487
00:51:06,669 --> 00:51:12,235
대신에 "데이터와 무관하게" 
특정 클래스에 "우선권"을 부여합니다.

488
00:51:12,235 --> 00:51:16,300
가령 데이터셋이 분균형한 상황을 생각해 볼 수 있습니다.
고양이 데이터가 개 데이터보다 훨씬 더 많은 상황입니다.

489
00:51:16,300 --> 00:51:23,553
이 상황에서는 고양이 클래스에 상응하는 
바이어스가 더 커지게 됩니다.

490
00:51:23,553 --> 00:51:27,778
그러면 이제 이 함수가 어떻게 동작하는지
그림으로 살펴보겠습니다.

491
00:51:28,930 --> 00:51:37,099
이 그림을 보면 왼쪽에 입력 이미지가 있습니다.
2x2 이미지이고 전체 4개의 픽셀입니다.

492
00:51:37,099 --> 00:51:46,577
이 Linear classifier는 2x2 이미지를 입력으로 받고
이미지를 4-dim 열 벡터로 쭉 폅니다.

493
00:51:46,577 --> 00:51:54,030
10개 클래스를 모두 슬라이드에 담을 수 없어서 이 예제에서는
고양이, 개, 배 이렇게 세가지 클래스만 보겠습니다

494
00:51:54,030 --> 00:51:58,197
가중치 행렬 W는 4x3 행렬이 됩니다.

495
00:51:59,890 --> 00:52:02,236
이런 식으로, 입력은 픽셀 4개고 
클래스는 총 3개 입니다.

496
00:52:02,236 --> 00:52:05,567
그리고 추가적으로 3-dim bias 벡터가 있습니다.

497
00:52:05,567 --> 00:52:11,125
bias는 데이터와 독립적으로 
각 카테고리에 연결됩니다.

498
00:52:11,125 --> 00:52:22,814
"고양이 스코어" 는 입력 이미지의 픽셀 값들과 가중치 행렬을
내적한 값에 bias term을 더한 것입니다.

499
00:52:22,814 --> 00:52:30,157
이러한 관점에서 Linear classification은 
템플릿 매칭과 거의 유사합니다.

500
00:52:30,157 --> 00:52:43,183
가중치 행렬 W의 각 행은 각 이미지에 대한 템플릿으로 볼 수  있고
그 행 벡터와 이미지의 열벡터 간의 내적을 계산하는데,

501
00:52:43,183 --> 00:52:50,458
여기에서 내적이란 결국 클래스 간 탬플릿의
유사도를 측정하는 것과 유사함을 알 수 있습니다.

502
00:52:50,458 --> 00:52:57,073
bias는 데이터 독립적으로  각 클래스에 
scailing offsets을 더해주는 것입니다.

503
00:53:00,837 --> 00:53:04,705
템플릿 매칭의 관점에서  
Linear classification 해석해보면

504
00:53:04,705 --> 00:53:12,799
가중치 행렬 W의 한 행을 뽑아서 
이를 이미지로 시각화 시켜 보면

505
00:53:12,799 --> 00:53:18,908
Linear classifier가 이미지 데이터를 인식하기 위해서 
어떤 일을 하는지 짐작할 수 있습니다.

506
00:53:18,908 --> 00:53:23,208
이 예제에서는 Linear classifier가 이미지를 학습합니다.

507
00:53:23,208 --> 00:53:28,974
슬라이드 하단의 이미지는 실제로 
가중치 행렬이 어떻게 학습되는지를 볼 수 있습니다.

508
00:53:28,974 --> 00:53:32,274
CIFAR-10의 각 10개의 카테고리에 해당하는
행 벡터를 시각화시킨 것입니다.

509
00:53:32,274 --> 00:53:35,686
이렇게 시각화된 이미지를 살펴보면 
어떤 일이 일어나는지 알아볼 수 있습니다.

510
00:53:35,686 --> 00:53:40,978
가령 맨 왼쪽의 이미지는 비행기 클래스에 대한 
템플릿 이미지입니다.

511
00:53:40,978 --> 00:53:46,739
이 이미지는 전반적으로 파란 색입니다. 
가운데에는 어떤 물체가 있는 것 같군요

512
00:53:46,739 --> 00:53:51,574
이 이미지를 해석해보면 Linear classifier가 비행기를 
분류할 때 푸르스름한 것들을 찾고 있는 것 같습니다.

513
00:53:51,574 --> 00:53:57,606
이러한 특징들이 이 분류기가 비행기를 더 잘 찾도록 
도와준다고 해석해 볼 수 있습니다.

514
00:53:57,606 --> 00:53:59,444
바로 옆에 있는 자동차의 예시도 한번 보겠습니다.

515
00:53:59,444 --> 00:54:09,654
중앙은 불그스름하고 상단은 푸르스름합니다. 자동차의
앞유리 같군요. 하지만 조금 이상합니다.

516
00:54:09,654 --> 00:54:13,716
실제 자동차 처럼은 보이지가 않습니다.
어떤 자동차도 이렇게 생기진 않았죠.

517
00:54:13,716 --> 00:54:18,317
Linear classifier의 문제 중 하나는 각 클래스에 대해서
단 하나의 템플릿만을 학습하다는 것입니다.

518
00:54:18,317 --> 00:54:24,340
한 클래스 내에 다양한 특징들이 존재할 수 있지만,
모든 것들을 평균화 시키기 때문에

519
00:54:24,340 --> 00:54:29,675
다양한 모습들이 있더라도 각 카테고리를 인식하기
위한 템플릿은 단 하나밖에 없습니다.

520
00:54:29,675 --> 00:54:33,139
이 문제점은 말(馬)을 분류하는 템플릿을 살펴보면 
여실히 드러나는 대목입니다.

521
00:54:33,139 --> 00:54:37,340
바닥은 푸르스름해 보입니다. 보통 말이 풀밭에 서 있으니 
템플릿이 바닥을 푸르스름하게 학습한 것입니다.

522
00:54:37,340 --> 00:54:43,125
그런데 유심히 살펴보면 말의 머리가 두 개 입니다.
각 사이드 마다 하나씩 달려 있습니다.

523
00:54:43,125 --> 00:54:45,855
머리 두개 달린 말은 존재하지 않습니다.

524
00:54:45,855 --> 00:54:52,788
하지만 Linear classifier가 클래스 당 하나의 템플릿밖에 
허용하지 않으므로 이 방법이 최선입니다.

525
00:54:52,788 --> 00:54:59,460
하지만 Neural Network같은 복잡한 모델이라면 
조금 더 정확도 높은 결과를 볼 수 있을 것입니다.

526
00:54:59,460 --> 00:55:05,230
클래스 당 하나의 템플릿만 학습 할 수 있다는 
것과 같은 제약조건이 없다면 말이죠

527
00:55:09,030 --> 00:55:15,649
Linear classifier을 또 다른 관점으로 해석할 수 있습니다.  
이미지를 고차원 공간의 한 점으로 보는 것입니다.

528
00:55:15,649 --> 00:55:23,328
각 이미지을 고차원 공간의 한 점이라고 생각해 봅시다

529
00:55:23,328 --> 00:55:33,125
Linear classifier는 각 클래스를 구분시켜 주는
선형 결정 경계를 그어주는 역할을 합니다.

530
00:55:33,125 --> 00:55:38,897
가령 왼쪽 상단에 비행기의 예를 볼 수 있습니다.

531
00:55:38,897 --> 00:55:49,493
Linear classifier는 파란색 선을 학습해서 
비행기와 다른 클래스를 구분할 수 있습니다.

532
00:55:49,493 --> 00:55:57,318
임의의 값으로 초기화된 모델이 데이터 들을 잘 분류하려고
노력하는 모습을 지켜보면 아주 재밌습니다.

533
00:55:58,709 --> 00:56:04,000
하지만 이미지가 고차원 공간의 하나의 점 이라는 
관점으로 해석해보면

534
00:56:04,000 --> 00:56:09,758
Linear classification이 직면할 수 있는 문제가 있습니다.

535
00:56:09,758 --> 00:56:15,232
이 Linear classifier를 망가뜨릴 수 있는 예제를 
만드는 일은 생각보다 어렵지 않습니다.

536
00:56:15,232 --> 00:56:20,324
맨 왼쪽 그림은 두 개의 클래스를 가진 데이터 셋입니다.

537
00:56:20,324 --> 00:56:26,095
데이터가 조금은 인위적일 수 있지만, 아무튼 데이터셋에는
파랑/빨강 두 개의 카테고리가 있습니다.

538
00:56:26,095 --> 00:56:33,122
파랑색 카테고리는 0보다 큰 픽셀이 홀수 개 인 경우입니다.
(예 : [3,-1] 이면 0보다 큰 수 : 3 (1개, 홀수개) -> 파랑)

539
00:56:33,122 --> 00:56:38,714
반면 0보다 큰 수가 짝수 개면 빨간 카테고리로 분류합니다.

540
00:56:38,714 --> 00:56:53,426
좌표 평면에 이 같은 규칙으로 그려보면
두 개의 사분면에는 파란 클래스,

541
00:56:53,426 --> 00:56:56,063
두 사분면에는 빨간색 클래스를 볼 수 있습니다. 
(예:(1.1):2(짝), (-1,1):1(홀), (-1, -1):0(짝))

542
00:56:56,063 --> 00:57:05,273
이 데이터를 선 하나로 분류할 방법은 없습니다.
 Linear classifie로는 풀기 힘든 문제입니다.

543
00:57:05,273 --> 00:57:09,535
이 예제가 너무 인위적으로 보일 수 있지만 그렇지 않습니다

544
00:57:09,535 --> 00:57:16,424
가령 이렇게 픽셀 갯수를 세는 대신에 영상 내 동물이나 사람의 수가
홀/짝수 인지를 분류하는 문제일 수 있습니다.

545
00:57:16,424 --> 00:57:21,145
홀/짝수를 분류하는 것과 같은 
반전성 문제(parity problem)는

546
00:57:21,145 --> 00:57:25,725
일반적으로 Linear classification으로 풀기 힘든 문제입니다.

547
00:57:28,376 --> 00:57:33,974
Linear classifier로는 풀기 힘든 또 하나는
Multimodal problem입니다. (맨 오른쪽)

548
00:57:33,974 --> 00:57:41,915
맨 오른쪽 이미지를 보면 파란색이 분포하는 
세 개의 섬들이 있습니다.

549
00:57:41,915 --> 00:57:44,791
그 밖의 빨간색은 전부 다른 카테고리에 속합니다.

550
00:57:44,791 --> 00:57:50,959
앞서 소개드린 말(馬)의 예시처럼
Multimodal problem은 언제든 실제로 일어날 수 있습니다.

551
00:57:50,959 --> 00:57:57,268
왼쪽 머리가 하나의 섬이 될 수 있고
오른쪽 머리가 또 하나의 섬이 될 수 있습니다.

552
00:57:57,268 --> 00:58:03,757
섬이 두 개인데 선을  하나만 긋는 것은
그닥 좋은 방법이 아닌 것입니다.

553
00:58:03,757 --> 00:58:10,854
Multimodal data라면 한 클레스가 
다양한 공간에 분포할 수 있으며

554
00:58:10,854 --> 00:58:13,963
이 문제는 Linear classifier로는 풀 수 없습니다.

555
00:58:13,963 --> 00:58:22,259
이처럼 Linear classifier에는 문제점이 일부 있긴 하지만
아주 쉽게 이해하고 해석할 수 있는 알고리즘입니다.

556
00:58:22,259 --> 00:58:27,245
과제1 에서 Linear classifier를 구현하시게 될 것입니다.

557
00:58:28,852 --> 00:58:34,402
이번 시간을 요약해보면 지금까지 Linear classifier의 
수식을 살펴보았습니다.

558
00:58:34,402 --> 00:58:39,185
Linear classifier가 단순히 
행렬과 벡터 곱의 형태라는 것을 배웠고

559
00:58:39,185 --> 00:58:44,922
템플릿 매칭과 관련이 있고, 이 관점에서 해석해 보면 
각 카테고리에 대해 하나의 템플릿을 학습한다는 것을 배웠습니다.

560
00:58:44,922 --> 00:58:55,738
그리고 가중치 행렬 W 를 학습시키고 나면
새로운 학습 데이터에도 스코어를 매길 수 있습니다.

561
00:58:55,738 --> 00:59:01,951
오늘은 어떻게 가중치 행렬 W를 구할 수 있는지는
배우지 않았습니다.

562
00:59:01,951 --> 00:59:06,907
오늘은 Linear classifier가 어떻게 생겼고, 어떻게
동작하는지만 가볍게 알아보았습니다.

563
00:59:06,907 --> 00:59:11,086
지금 보이는 슬라이드가 우리가 다음 시간에 다룰 내용입니다.

564
00:59:11,086 --> 00:59:16,581
다음 강의에서는 적절한 가중치 행렬 W를 고르는 법과 
다양한 알고리즘들에 대해서 다뤄보도록 하겠습니다.

565
00:59:16,581 --> 00:59:21,322
그리고 더 나아가 비용함수, 최적화, 
ConvNet에 대해서 배울 것입니다.

566
00:59:21,322 --> 00:59:25,044
다음 주에 배울 내용들이죠

567
00:59:25,044 --> 00:59:27,044
오늘은 여기까지 하겠습니다.


