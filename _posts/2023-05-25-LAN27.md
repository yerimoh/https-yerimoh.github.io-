---
title: "Symbolic Chain-of-Thought Distillation: Small Models Can Also “Think” Step-by-Step 정리" 
date:   2023-08-15
excerpt: "Symbolic Chain-of-Thought Distillation: Small Models Can Also “Think” Step-by-Step"
category: [Paper]
layout: post
tag:
- Paper
order: 0

comments: true
---

   **[원 논문]**     
[Symbolic Chain-of-Thought Distillation: Small Models Can Also “Think” Step-by-Step
](https://aclanthology.org/2023.acl-long.150.pdf)


-----



# **ABSTRACT**

**[문제]**      
* Chain-of-thought prompting (e.g., “Let’s think step-by-step")는 큰 언어 모델이 예측을 위한 합리화를 verbalize하는 데 가장 기초가 된다.     
* chain-of-thought는 충분히 큰 모델(beyond 50B parameters)에서만 극적인 성능 향상으로 이어질 수 있다.     


**[본 논문]**    
* 규모가 작은 모델(125M—1.3B parameters)도 성능향상을 보여줄 수 있음을 증명
* 이를 달성하기 위해, SCOTD(Symbolmic Chain-of-Thought Disrelation) 제안함
* 여러 상식 벤치마크에 대한 실험은 아래 결과를 보여줌
    * **1)** SCOTD가 supervised 및 few-shot settings 모두에서 student 모델의 성능을 향상시킴         
    * **2)** 특히 challenge 세트의 경우 teacher로부터 많은 reasoning chains을 샘플링하는 것이 무엇보다 중요함을 보여줌.
    * **3)** distillation 후, student의 chain-of-thoughts은 크기가 작은 parameters에도 불구하고 인간에 의해 teacher에 필적 가능
* 본 논문은 아래와 같은 여러 가설을 테스트한다.       
    * diversity vs. teacher likelihood vs. open-endedness       
* 우리는 chain-of-thought 샘플 및 코드의 코퍼스를 공개함        


<details>
<summary>📝 지식 증류 (Knowledge Distillation)란?</summary>
<div markdown="1">
  
 
지식 증류(knowledge distillation)란, 이미 사전학습 되어있는 대규모 모델인 teacher로부터 경량화된 압축 모델인 student로 AI의 지식을 나누어 주는 개념이다.

증류(distillation)라는 단어가 액체 혼합물을 가열하여 액체 혼합물을 분리하는 과정을 의미한다는 점을 생각하면 그 뜻이 쉽게 와닿는다.



<img width="391" alt="image" src="https://github.com/yerimoh/yerimoh.github.io/assets/76824611/64c7eec1-b973-4ad4-95ef-3ad429ae64b8">

즉 위 그림과 같이 NN에서 지식 증류는 큰 모델(teacher network)로부터 증류한 지식을 작은 모델(student netwrok)로 transfer하는 과정이다.
  
</div>
</details>  

---



# 1 Introduction

**[chain-of-thought]**      
* Empirical scaling laws은 benchmark task에 대한 LLM(Large Language Models)의 accuracy를 **모델 크기**와 **pre-training data volume**을 **증가**시켜 향상시킬 수 있음을 시사한다.              
* 그러나 이러한 교육 시간 개선을 넘어 “chain-of-thought" (CoT)이라는 inference-time 전략은, “Let’s think step-by-step" 과 같은 핵심 문구를 통해 **예측 프로세스의 언어화를 유도**하고 성능을 개선함.      



<details>
<summary>📝 “chain-of-thought" (CoT)란 용어 정리?</summary>
<div markdown="1">
  
Sometimes called “self-rationalization" or     
“prompting with explanations.”


We will use these terms interchangeably
in this paper.

  
</div>
</details>  


**[chain-of-thought의 한계]**      
* 그러나, 생각의 chain-of-thought prompting는 <span style="background-color:#FFE6E6">**충분한 규모의 모델**(예: 60B 이상의 매개 변수(Wei et al., 2022b를 가진 모델)**에만 유용**</span>한 것으로 나타났음       



**[Solution]**     
* 이 작업에서, 우리는 <span style="background-color:#fff5b1">**작은 언어 모델**이 **더 큰 언어 모델에 의해 chain-of-thought을 추론할 수 있는 능력**을 "taught"할 수 있는지 여부를 연구</span>함.      
* 이를위해 **SCOTD(Symbolic Chain of Thoughtemplicled)**개발
    * 본 논문은 SCoTD를 통해 소규모 언어 모델이 합리화되지 않은 학습에 비해 3가지 상식 QA 과제에서 자기 합리화를 배우고 훨씬 더 잘 수행한다는 것을 발견함
    * 이 결과는 감독 및 퓨샷 설정 모두에 적용되며 다양한 규모의 학생 모델(1억2500만~1.3B 매개 변수)에 걸쳐 적용됨
    * 특히 contrast sets(Gardner et al. 2020), fully held-out tasks(§3.5)와 같은 어려운 시나리오에 distilled chain-of-thought models(SCO3.4.5)을 적용할 때 성능 향상이 두드러짐
* **이 프로세스의 성공 비결**
    * teacher 모델(예: 30가지 이유/예: 그림 2)에서 **비교적 많은 수의 rationales를 샘플링**하는 것       
    * 이는 예당 하나의 rationales으로 훈련하는 많은 이전 관행과 다름. (Camburu et al., 2018; Li et al., 2022a)     
    * 절제 연구에서, 우리는 개방형 확률 대 다양성 인스턴스에 의해 할당된 코퍼스에 대해 코퍼스를 필터링함             

우리는 코드와 샘플링된 사슬의 코퍼스를 https://github.com/ allenai/cot_communication에서 공개할 것입니다



Key to the success of this process is sampling a relatively large number of rationales per example from the teacher model (e.g., 30 rationales/example) (Figure 2). This is different from many prior practices that train with one rationale per example (Camburu et al., 2018; Li et al., 2022a). In ablation studies, we investigate several competing hypotheses for what are the most important factors within the corpus: we filter the corpus to CoTs that are assigned high probability by GPT-3 vs. filtering to CoTs that are diverse vs. filtering to CoTs that explain more open-ended input instances. While diversity and high probability are reasonable filters that on average perform well, the “null hypothesis” of random downsampling performs well, suggesting that the sheer volume of the rationales is also a key contributing factor

We will release code and the corpus of sampled chain-of-thoughts at https://github.com/ allenai/cot_distillation













