---
title: "Do Language Models Understand Measurements? 정리"
date:   2023-02-13
excerpt: "Do Language Models Understand Measurements?"
category: [Paper]
layout: post
tag:
- Paper
order: 0

comments: true
---

# Abstract
**[배경]**     
최근 pre-trained language models (PLMs)의 **성공은 숫자를 이해**하고 **작업**하는 능력에 대한 관심을 자극했다.     

**[문제]**     
그러나 <span style="background-color:#FFE6E6">**측정에 대한 수치 추론**은 그 중요성에도 불구하고 공식적으로 연구되지 않았다</span>.    

**[논문의 목적]**       
본 논문은 아래와 같은 내용으로 구성되어있다.     
* **PLMs가 측정에 대한 추론에 필요한 능력이 부족**하다는 것을 보여준다.       
* **measurement-rich 말뭉치에 대해 train된 언어 모델**이, **understanding measurements**에 **더 나은 성능**을 보인다는 것을 발견했다.     
* 본 논문은 **숫자와 단위를 더 잘 구별**하기 위한 **간단한 임베딩 전략**을 제안한다.   
➡ 이는 probing tasks의 상당한 개선으로 이어진다.   



# 1 Introduction
The success of pre-trained language models
(PLMs) has led to more research on their ability to
understand commonsense. In this context, numerical reasoning over text (NRoT) is a NLP model’s
ability to interpret and work with numbers in either digit or word form (Spithourakis and Riedel,
2018). Recent studies on NRoT test PLMs to answer questions on numeracy (Wallace et al., 2019),
scalar magnitude comparison (Zhang et al., 2020),
numerical facts (Lin et al., 2020), and math word
problems (Wu et al., 2021).


Despite these efforts, existing works lack an analysis of the forms in which numbers appear. In particular, we focus on the case where numbers appear
as a measurement in the context. In most scientific articles, measurements are an integral part of
the context for capturing its appropriate meaning.
For example, the two sentences "40g of Aspirin
is lethal" and "40mg of Aspirin is lethal" contain
the same words except for the unit of measurement (UoM), but the second sentence is incorrect
because of the UoM

In this work, we examine the measuring skill of
PLMs: the ability to understand the system of measurement and perform numerical reasoning over
measurements. We design three measuring skill
tests (MSTs) and study how many measuring skills
can be acquired. Specifically, UNIT CONVERSION,
REFERENCE RANGE DETECTION, and MEASUREMENT COMPARISON require understanding of the
system of measurement, the normal range of the
biomedical entity, and the ability to combine knowledge about the system of measurement and NRoT,
respectively. Table 1 shows an example of each of
the measuring skill tests.


MST results showed that the models struggled
to find the largest (or smallest) value on the list of
measurements and convert the measurement to another unit, while they performed well on other tests.
Compared to other PLMs, BioBERT (Lee et al.,
2020) showed superior performance on UNIT CONVERSION and REFERENCE RANGE DETECTION,
which implies that pre-training with measurementrich text helps the model understand the system of
measurement. Finally, we speculate that the lack
of skills to distinguish numbers, units, and other
words in the context makes the models fail in some
MSTs. To mitigate this, we introduce scale embedding, which provides the model with the information regarding the position and scale of the numbers
in the input text. We show that scale embedding
significantly improves the MST performance of all
PLMs.


# 2 Measuring Skill Test
In this section, we describe three MSTs to carefully
study the ability of PLMs to understand the system
of measurement and perform numerical reasoning
over the measurements.

## 2.1 Unit Conversion
This task requires the model to decide whether
the two measurements represent the same quantity.
For example, the model might correctly predict
[MASK] in a sentence, such as "3.5g and 3500mg
are [MASK] value" to be filled with same if it under
stands the conversion of units correctly. In general,
it is a convention to combine the unit (e.g., liter,
meter) and its prefix (e.g., kilo, milli) to represent
the numerical value of the measurement within a
range [10−3, 103). Therefore, various unit prefixes
can appear in a single passage, even if the units
are the same. To handle this, UNIT CONVERSION
is essential for complex reasoning over measurements. To succeed in UNIT CONVERSION, we expect the model to handle the unit and numerical
value jointly, based on an understanding of the system of measurement


## 2.2 Reference Range Detection
Given a biomedical entity and measurement, this
task requires a model to predict whether the measurement falls within the reference range. Knowledge of the biomedical entity plays a crucial role
in understanding measurements, since the unit is
determined by the biomedical entity. For example,
we measure the hemoglobin level in g/dL. In addition to understanding UoMs, PLMs must rely on
domain knowledge embedded in their parameters
to solve this task, as context alone does not provide
sufficient clues as to what the reference range is for
the given biomedical entity

## 2.3 Measurement Comparison
Given two measurements (or a series of n measurements), the task is to predict the correct relationship between them. We created the synthetic dataset following other well-known NRoT
tasks. Here, we consider three numerical reasoning tasks: COMPARISON (Talmor et al., 2020),
ARGMIN/MAX (Wallace et al., 2019), and SORTING (Pal and Baral, 2021), all requiring the model
to compare numbers. Note that each measurement
in this task can have a different unit prefix. For
example, the sample "1.59mg is [MASK] than 3.8g"
containing two different units "mg" and "g" appears
in the COMPARISON dataset. This task assesses the
model’s ability to combine an understanding of
measurements and numerical reasoning skills.

