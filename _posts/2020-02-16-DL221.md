---
title: "Deep learning: Training, validation, test datasets 비교"
date:   2020-02-15    
excerpt: " "
category: [Deep Learning]
layout: post
tag:
- Deep Learning
order: 0

comments: true
---


# 목차

---

👀, 🤷‍♀️ , 📜    
이 아이콘들을 누르시면 코드, 개념 부가 설명을 보실 수 있습니다:)

---
----


# Machine Learning in NLP
강의: NLP 배경 및 Transformer 아키텍처의 기반이 된 DNN의 역할   
랩: 튜토리얼 스타일로 Transformer 아키텍처를 사용하는 번역 작업 살펴보기  

랩
Transformer 아키텍처
Transformer 인코더
Transformer 디코더

## 목표
NLP 작업, "All You Need Attention is All You Need"에 발표된 [트랜스포머](https://yerimoh.github.io/Lan/) 아키텍처를 가져온 현재까지의 기술에 대해 개략적으로 설명


---

## NLP 배경

**[NLP란?]**     
'언어를 처리' 하는 것이다.      

<details>
<summary>📜 사용 예시 보기</summary>
<div markdown="1">
  
즉,   
* 기계 번역   
* 감정 분석   
* 질문 답변    
* 자동 텟스트 요약   
* 저자판별    
 * 텍스트 분류       
* 맞춤법 검사    
  
과 같은 처리를 담당한다.
  
</div>
</details>  

**[머신 러닝이 필요한 이유]**     
인간의 언어가 복잡하기 때문이다.    
* 역설, 모호, 풍자 등 인간의 언어는 맥락에 의존한 경우가 많음    
* 언어는 임의성이 강함   
* 발음도 명확하게 나뉘어지지 않음    

<details>
<summary>📜 PRINCIPLES AND PARAMETERS(원리와 매개변수 이론)</summary>
<div markdown="1">
  

## 언어적 개념
Noam Chomsky가 또 다른 유명한 언어학자인 Howard Lasnik과 함께 중대하게 기여한 점 중 하나는 '원리와 매개변수' 이론
* 기본적으로 Chomsky와 Lasnik은 인간은 각 언어의 속성을 정의하는 **보편 문법**(UG, Universal Gram   mar)이라는 **생래적인 규칙을 지니고 태어난**다고 주장   
* 각 언어는 그러한 각 규칙에 적용되는 값과 **그러한 규칙의 우선 순위를 '선택**'함         
 * 물론, 언어학계에서는 그러한 규칙이 무엇이며 어떤 값이 허용되는지에 대해 중점적으로 논의   

이러한 언어 관점은 단일 언어를 다수의 추상적 메서드를 구현(재정의)하는 개체로 생각할 수 있는 개체 지향 프로그램에 아주 잘 맞음    

이러한 메서드를 평가하는 순서를 선택하여 주어진 문장이 해당 언어에서 올바른 발언인지('문법성'이라는 개념) 여부를 판단    
'책임 연쇄'로 알려진 4인방(GoF, Gang-of-Four) 디자인 패턴을 사용하여 이를 구현 가능함

**즉, 요약해서 나타내면 언어와 매개변수이론은,**    
* 언어학자인 Noam Chomsky와 Howard Lasnik이 만든 프레임워크이다      
* 이 프레임워크는 언어가 "생래적(hard-wired)" 원칙과 언어별 인스턴스화로 구성된다는 것을 나타낸다.       
* 소프트웨어 용어로 '언어'는 개체이며, 가상 함수로 다양하게 구현됨    
   * 우리는 Chain-of-Responsibility 구조를 통해 바이너리 값을 실행하여 문장이 문법적이든 아니든 관계없이 바이너리 값을 연산함       

## 언어학자의 시점에서 본 경우
* 언어는 엄격한 규칙과 일반화를 따름.    
* 이러한 일반화는 소프트웨어 구조에 잘 매핑되므로 NLP 시스템을 설계할 때 매우 유용함.    
* 현재 사용 가능한 텍스트 데이터가 엄청나게 많다는 것은 머신 러닝이 NLP에 적합한 접근 방식임을 의미함.     

  
</div>
</details> 



----
----

# INTRO



**[텍스트 처리를 위한 머신러닝 개요]**    

![image](https://user-images.githubusercontent.com/76824611/132247996-270b8a3f-5709-40f9-8c79-acacced7b2ae.png)


텍스트 표현
차원 축소
임베딩
RNN
“Attention is All You Need”

---

## 1️⃣ 텍스트 표현   

**[Bag of words(BOW)]**    

먼저 기존의 방식인 Bag of words(BOW)를 보자!    

**Bag of Words**: 단어들의 ~~순서~~는 전혀 고려하지 않고, 단어들의 **출현 빈도(frequency)** 에만 집중하는 텍스트 데이터의 수치화 표현 방법    

EX) ... the cat sat on the mat  ...  

![image](https://user-images.githubusercontent.com/76824611/132249389-d4d44bb1-cd6b-459c-9335-71324a01dcce.png)

 
⛔ BoW 표현의 문제    
**희소 입력 문제**    
너무 출현 빈도에 의존하니 말뭉치가 커지면 겹치는 어휘수보다 어휘의 종류가 훨씬 많아지니 낭비가 심하다    
즉 이는 입력 데이터의 상당수가 희소 입력, 즉, 값이 0임을 의미한다.            
희소성의 영향은 피처(단어)의 수가 우리가 사용하는 예제의 수보다 훨씬 더 커지게 될 수 있으므로 대부분 [OVERFITTING](https://yerimoh.github.io/DL5/#%EC%98%A4%EB%B2%84%ED%94%BC%ED%8C%85)이 일어난다.     

**의미론적 일반화 없음**     
이 예에서는 dog이 피처 #1이고, cat이 #2입니다.      
이는 누가봐도 기준이 없는 완전히 임의적인 피처다.      
즉, 이는 일반화할 수 없음을 의미한다.  
➡ 모델이 고양이에 대해 배운 지식을 개에 적용할 수 없습니다.      
➡ 두 단어의 ~~**연관성**~~(둘 다 동물, 다리 4개, 꼬리 한 개 등)을 전혀 알지 못하기 때문        


**[분산된 단어 표현]**      
한마디로 정의하면 단어에는 **맥락**이 생명이라는 뜻이다   
⭕ SOLUTION
즉 BoW의 문제를 해결하려면 단어를 **맥락**의 기준에서 봐야한다

<details>
<summary>📜 동시 발생 패턴 </summary>
<div markdown="1">
  
아래의 그림과 같이 같이 나오는 단어들을 분석한 것이다    
➡ 이를 잘 활용하면 맥락을 얻을 수 있다    
![image](https://user-images.githubusercontent.com/76824611/132250889-dcbf5f72-dae8-4508-b146-f4f2aed865a7.png)
  
조금 더 쉽게 설명하자면,    
  
The cat sat on the mat   
The dog sat on the mat   
The elephant sat on the mat   
The **quickly** sat on the mat   

딱 봐도 동물이 들어갈 자리에 들어갔는 **quickly**가 이상하지 않나??     
이게 바로 문맥에 맞지 않는다는 것이다

  
</div>
</details>   
  
---

## 2️⃣ 차원 축소     
* 컴팩트하고 계산상 효율적인 표현 필요   
* 분포 표현으로 캡처한 정보를 노출하는 더 강력한 거리 개념    


### LSA     
SVD를 활용하여 문서에 숨어있는 **의미**를 이끌어내기 위한 방법     
DTM이나 TF-IDF 행렬에 절단된 SVD(truncated SVD)를 사용하여 차원을 축소시키고, 단어들의 잠재적인 의미를 끌어낸다
  
### LDA    
LSA의 단점을 개선하여 탄생한 알고리즘



### 차원 축소용 오토인코더   
  
