---
title: "[03] GPT-1 정리 "
date:   2021-05-13
excerpt: "Improving Language Understanding by Generative Pre-Training"
category: [Language AI]
layout: post
tag:
- Java
order: 0

comments: true
---

# intro
## 핵심  
#multi-head self-attention을 이용해 sequential computation 을 줄여 더 많은 부분을 병렬처리가 가능하게 만들면서 동시에 더 많은 단어들 간 dependency를 모델링 한다는 것

## 읽기 위해 필요한 지식
#[attention](링크 삽입) 
[transformer](https://yerimoh.github.io//Lan/)

## 원 논문
[Improving Language Understanding by Generative Pre-Training](https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf)

---
