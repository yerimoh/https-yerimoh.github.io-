---
title: "[06] Deep learning 1: MNIST 데이터세트로 이미지 분류"
date:   2020-03-7
excerpt: "MNIST 데이터세트로 이미지 분류 쉽게 이해하기"
category: [Deep Learning]
layout: post
tag:
- Deep Learning
order: 0

comments: true
---


# 목차
- [목표](#목표)
- [solution](#solution)
- [MINIST 데이터 설명](#minist-데이터-설명)
- [트레이닝 및 검증 데이터 레이블](#트레이닝-및-검증-데이터-레이블)
- [데이터를 메모리에 로드(Keras 사용)](#데이터를-메모리에-로드-keras-사용-)
- [MNIST 데이터 살펴보기](#mnist-데이터-살펴보기)
- [트레이닝을 위한 데이터 준비](#트레이닝을-위한-데이터-준비)
  * [1) 이미지 데이터 평탄화](#1--이미지-데이터-평탄화)
  * [2) 이미지 데이터 정규화](#2--이미지-데이터-정규화)
  * [3.1) 범주 인코딩](#31--범주-인코딩)
  * [3.2) 레이블 범주 인코딩](#32--레이블-범주-인코딩)
- [모델 생성](#모델-생성)
  * [0) 모델 인스턴스 화](#0--모델-인스턴스-화)
  * [1) 입력 레이어 생성](#1--입력-레이어-생성)
  * [2) 히든레이어 생성](#2--히든레이어-생성)
  * [3) 출력 레이어 생성](#3--출력-레이어-생성)
- [모델 요약](#모델-요약)
- [모델 컴파일](#모델-컴파일)
- [모델 트레이닝](#모델-트레이닝)
- [정확도 관찰](#정확도-관찰)
- [추론](#추론)
- [메모리 지우기](#메모리-지우기)





----

## 목표
처음 접한 이미지를 정확한 클래스로 올바르게 분류

## solution
딥러닝_**시행착오**를 통한 **패턴 인식**에 뛰어난 면모

## MINIST 데이터 설명
0~9의 수기 문자로 구성된 70,000개의 회색조 이미지     
딥러닝 계의 HELLOWORLD    
 ![image](https://user-images.githubusercontent.com/76824611/128688695-7fe4bdca-c59a-47c7-8dc1-00cb3b85c292.png)

-----

## 트레이닝 및 검증 데이터 레이블
**데이터 엔지니어링**: 분석을 위한 데이터 준비과정      
* X: 이미지 자체    
* Y: 이미지의 올바른 레이블     
➡ **모델 트레이닝**을 위한 X,Y 필요     
➡ 트레이닝 된 [**모델 검증**](https://yerimoh.github.io/DL5/#%EC%A0%81%EC%A0%88%ED%95%9C-%ED%95%98%EC%9D%B4%ED%8D%BC%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0-%EA%B0%92-%EC%B0%BE%EA%B8%B0) 을 위한 X,Y 필요      
```x_train```: 뉴럴 네트워크를 트레이닝하는 데 사용되는 이미지     
```y_train```: x_train 트레이닝 중 모델의 예측을 평가하는 데 사용되는 올바른 이미지 레이블     
```x_valid```: 트레이닝된 모델의 성능 검증을 위해 따로 확보해 놓는 이미지     
```y_valid```: x_valid 트레이닝 후 모델의 예측을 평가하는 데 사용되는 올바른 이미지 레이블        


----


## 데이터를 메모리에 로드(Keras 사용)
먼저 MNIST를 위한 Keras 데이터세트를 로드    
* mnist 모듈: 트레이닝 및 검증을 위해 이미지와 레이블로 미리 분할되어 있음

```python
# 데이터 불러옴
from tensorflow.keras.datasets import mnist

# the data, split between train and validation sets
# 훈련데이터와 검증데이터로 나눔
(x_train, y_train), (x_valid, y_valid) = mnist.load_data()
```

----

## MNIST 데이터 살펴보기
다음 셀을 실행하면 
* Keras가 **트레이닝**을 위해 60,000개의 이미지 ,**검증(트레이닝 후)**을 위해 10,000개의 이미지를 분할 확인 가능
* 각 이미지 자체가 28x28 차원의 2D 어레이임을 확인

```python
x_train.shape
#(60000, 28, 28)

x_valid.shape
# (10000, 28, 28)
```

이러한 28x28 이미지가 0~255의 서명되지 않은 8비트 정수 값 모음으로 표현되는 것을 확인 가능.   
* **0**: 검은색  
* **255**: 흰색   
* **0~255**: 모든 값은 둘 사이의 회색조 값    

```python
x_train.dtype
# dtype('uint8')

x_train.min()
# 0
x_train.max()
# 255
```


[Matplotlib](https://yerimoh.github.io/PD3/)를 사용하면 데이터세트에서 이러한 회색조 이미지 중 하나를 렌더링 가능.
```python
import matplotlib.pyplot as plt

image = x_train[0]
plt.imshow(image, cmap='gray')
```
![image](https://user-images.githubusercontent.com/76824611/128698850-91d39b08-1f30-42d0-aa7e-13a9536ce882.png)


이 픽셀의 답이 3인지 5인지 알기 위해서는 정답인 y_train데이터를 불러오면 된다
```python
y_train[0]
# 5
```



----


## 트레이닝을 위한 데이터 준비
딥러닝에서는 대부분의 경우 트레이닝을 위한 적합한 상태로 데이터를 변환 필요      
[변환작업]    
1) 이미지 데이터 **평탄화**: 모델에 입력되는 이미지 간소화      
2) 이미지 데이터 **정규화**: 이미지 입력 값이 모델에서 더 쉽게 작동되게 함      
3) 레이블 **분류**: 레이블 값이 모델에서 더 쉽게 작동되게 함       


### 1) 이미지 데이터 평탄화
Reshpe: 2차원 이미지(28x28픽셀) ➡ 단일 어레이(각 이미지를 784개의 연속 픽셀(28x28 = 784))
```python
x_train = x_train.reshape(60000, 784)
x_valid = x_valid.reshape(10000, 784)
```
확인
```python
x_train.shape
# (60000, 784)
```

### 2) 이미지 데이터 정규화
딥러닝 모델은 0에서 1 사이의 부동 소수점 수를 처리하는데 유용     
* 정규화: 정수 값을 0에서 1 사이의 부동 소수점 값으로 변환     
* 여기서의 정규화: 모든 픽셀 값을 최대인 255로 나눔    
```python
x_train = x_train / 255
x_valid = x_valid / 255
```

### 3.1) 범주 인코딩
딥러닝에서는 이분법적인 정답추론을 시키는 것이 유리함     
* O : 7-2 의 답은 4,9 둘 다 아니다     
* X: 7-2 의 답은 9보다 4에 더 가깝다.        
이를 응용하여 데이터 범주 인코딩을 해보자      
ex) one-hot encoding  
![image](https://user-images.githubusercontent.com/76824611/128699194-eb489949-5a39-40a6-9168-8711a964b4e0.png)

 
이를 0,1 바이너리를 이용하여 풀면,       
![image](https://user-images.githubusercontent.com/76824611/128699206-31eed9c9-af1a-4cce-a8c1-768b8aa1a0ee.png)

이것이 범주 인코딩 즉, 범주 레이블로 이해되어야 하는 값을 모델이 범주 특성을 알 수 있는 표현으로 변환하는 것임            

즉,        
values = ['red, green, blue, green']        
이 값을 트레이닝 값으로 사용하기엔 뉴럴 네트워크가 이를 이해하기 어려워 할 것이다.     
그러므로,    
```python
values = [
    [1, 0, 0],
    [0, 0, 1],
    [0, 1, 0],
    [0, 0, 1]
]
```
이렇게 변환(범주 인코딩)을 해준다     

### 3.2) 레이블 범주 인코딩
Keras는 값을 범주 인코딩하는 유틸리티를 제공        
* 이를 이용하여 트레이닝, 검증 레이블 모두 범주 인코딩 수행

```python
import tensorflow.keras as keras
num_categories = 10

y_train = keras.utils.to_categorical(y_train, num_categories)
y_valid = keras.utils.to_categorical(y_valid, num_categories)
```
확인
```python
y_train[0:9]
###
array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],
       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],
       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],
       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],
       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],
       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)
####
```
그럼 이제 **트레이닝을 위한 데이터가 준비**되었다.

----

## 모델 생성
이제 데이터로 트레이닝할 **모델을 생성**해야 함.        
**[기본 모델]**      
여러 개의 레이어로 이루어짐         
3가지 주요 부분으로 구성    
**✔구성**        
**1)** **입력 레이어**: 어느 정도 예상되는 형식으로 데이터를 수신           
**2)** 여러 개의 히든 레이어: 각각 **다수의 뉴런**으로 구성      
* 각 뉴런: **가중치**로 네트워크의 **추측에 영향**을 미칠 수 있음            
* 가중치: 네트워크가 수많은 반복을 통해 **성능에 대한 피드백을 수신하고 학습**하면서 **업데이트**하게 되는 값       

**3)** 출력 레이어: 주어진 이미지에 대한 네트워크의 추측을 보여줌        
 
 
 
### 0) 모델 인스턴스 화
모델을 찍어서 사용할 인스턴스 생성        
* Keras의 순차 모델 클래스를 사용하여 데이터가 연속으로 통과할 일련의 레이어를 보유한 모델의 인스턴스를 인스턴스화    
![image](https://user-images.githubusercontent.com/76824611/128700461-a2f2f1a0-fad3-438d-997c-fd9f6c25d5ab.png)
 
 
```python
from tensorflow.keras.models import Sequential

model = Sequential()
```



### 1) 입력 레이어 생성
레이어는 **밀집 연결**되어 있음     
* 포함된 **각 뉴런과 가중치**가 **다음 레이어의 모든 뉴런**에 영향을 줌        
* Keras로 이를 수행하려면 Keras의 Dense 레이어 클래스를 사용  
```python
from tensorflow.keras.layers import Dense
```

인수    
* ```units```: 레이어 내 뉴런 수를 지정    
   * 이번은 실험에서 선택한 512를 사용      
   * 올바른 뉴런 수를 선택: 데이터세트의 통계적 복잡성을 없애주는 일 ➡ 데이터 사이언스" 작업의 핵심        

* ```activation```: 활성화 함수 선택      
  * 입력신호의 활성화 여부를 결정          
  * [relu] (https://yerimoh.github.io/DL2/#relu-%ED%95%A8%EC%88%98) 사용      
* ```input_shape```: 값은 수신되는 데이터의 모양을 지정      
   *  여기서는 784개 값으로 이루어진 1D 어레이    
        
```python
model.add(Dense(units=512, activation='relu', input_shape=(784,)))
```

### 2) 히든레이어 생성
추측에 기여하는 더 많은 매개변수 즉, 정확한 학습을 위한 좀 더 예리한 기회를 네트워크에 제공
```python
model.add(Dense(units = 512, activation='relu'))
```

### 3) 출력 레이어 생성
각 레이어의 값이 0에서 1사이의 확률이 되도록 함          
* 활성 함수인 [softmax]( https://yerimoh.github.io/DL2/#%EC%B6%9C%EB%A0%A5%EC%B8%B5-%EC%84%A4%EA%B3%84) 사용: 레이어의 모든 출력이 1에 추가되도록 함       
* 출력: 이미지가 해당 특정 클래스에 속한다는 모델의 추측(확률)을 제공  
    
```python
model.add(Dense(units = 10, activation='softmax'))
```


## 모델 요약
Keras는 모델에 대한 읽을 수 있는 요약을 출력하는 모델 인스턴스 메서드 요약을 제공       
* 트레이닝 가능한 매개변수의 수를 확인 가능: 이러한 각 매개변수는 트레이닝 도중에 조정 가능➡ 트레이닝된 모델의 추측에 기여      


```python
model.summary()

###
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense (Dense)                (None, 512)               401920    
_________________________________________________________________
dense_1 (Dense)              (None, 10)                5130      
=================================================================
Total params: 407,050
Trainable params: 407,050
Non-trainable params: 0
_________________________________________________________________
###
```

## 모델 컴파일       
실제로 데이터를 사용하여 모델을 트레이닝하기 전에 수행해야 할 마지막 단계              

* ```loss```: [손실함수]( https://yerimoh.github.io/DL3/#%ED%9B%88%EB%A0%A8-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%99%80-%EC%8B%9C%ED%97%98-%EB%8D%B0%EC%9D%B4%ED%84%B0) 를 지정     
      * 트레이닝 중 모델에서 **성능을 파악**하는 데 사용됨        
*  ``` accuracy ```: 모델 트레이닝 동안 정확성 추적하도록 지정

```python
model.compile(loss='categorical_crossentropy', metrics=['accuracy'])
```

## 모델 트레이닝 
트레이닝 및 검증 데이터와 모델이 준비되었음    

이제 트레이닝 데이터로 모델을 트레이닝하고 검증 데이터로 이를 검증해야 함     

Keras로 모델을 맞추는(트레이닝하는) 경우에는 모델의 fit 메서드를 사용     

그럼 다음 인수를 예상함    
* 트레이닝 데이터    
* 트레이닝 데이터의 레이블     
* 전체 트레이닝 데이터세트에 대해 트레이닝해야 하는 횟수(에포크)     
* 검증 또는 테스트 데이터 및 해당 레이블      

```python

history = model.fit(
    x_train, y_train, epochs=5, verbose=1, validation_data=(x_valid, y_valid)
)

###
Epoch 1/5
1875/1875 [==============================] - 4s 2ms/step - loss: 0.1913 - accuracy: 0.9426 - val_loss: 0.0983 - val_accuracy: 0.9715
Epoch 2/5
1875/1875 [==============================] - 4s 2ms/step - loss: 0.0986 - accuracy: 0.9747 - val_loss: 0.1300 - val_accuracy: 0.9711
Epoch 3/5
1875/1875 [==============================] - 4s 2ms/step - loss: 0.0807 - accuracy: 0.9803 - val_loss: 0.1040 - val_accuracy: 0.9781
Epoch 4/5
1875/1875 [==============================] - 4s 2ms/step - loss: 0.0715 - accuracy: 0.9838 - val_loss: 0.1352 - val_accuracy: 0.9736
Epoch 5/5
1875/1875 [==============================] - 4s 2ms/step - loss: 0.0647 - accuracy: 0.9858 - val_loss: 0.1116 - val_accuracy: 0.9814
###

```

## 정확도 관찰
관찰해야 할 것        
5회의 에포크 각각에 대해,        
* accuracy: **모든 트레이닝 데이터**에 대한 에포크 동안의 **모델 성능**이 어땠는지를 명시      
* val_accuracy: 모델을 **트레이닝하는 데 전혀 사용되지 않는 검증 데이터**에 대한 모델 성능이 어땠는지를 나타냄      


## 추론
 이 모델을 사용하여 처음 접하는 새로운 수기 이미지를 분류

## 메모리 지우기
다음 노트북으로 넘어가기 위한 필수 작업
```python
import IPython
app = IPython.Application.instance()
app.kernel.do_shutdown(True)
```
