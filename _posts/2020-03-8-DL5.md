---
title: "[05] Deep learning 1 "
date:   2020-03-8
excerpt: "딥러닝 학습관련 기술들/옵티마이저 (Optimizers){확률적 경사 하강법 SGD,모멘텀 Momentum,AdaGrad,Adam,RMSProp},어느 갱신 방법을 이용할 것인가?,가중치의 초깃값,배치 정규화,오버피팅,가중치 감소,드롭아웃,적절한 하이퍼파라미터 값 찾기"
category: [Deep Learning]
layout: post
tag:
- Deep Learning
order: 0

comments: true
---

# 학습 관련 기술들 목차

- [옵티마이저 (Optimizers)](#옵티마이저--optimizers-)
  * [확률적 경사 하강법 SGD](#확률적 경사 하강법-sgd)
    + [SGD 단점](#sgd-단점)
  * [모멘텀 Momentum](#모멘텀-momentum)
  * [AdaGrad](#adagrad)
    + [RMSProp](#rmsprop)
  * [Adam](#adam)
- [어느 갱신 방법을 이용할 것인가?](#어느 갱신 방법을 이용할 것인가?)
- [가중치의 초깃값](#가중치의 초깃값)
  * [은닉층의 활성화값 분포](#은닉층의 활성화값 분포)
- [배치 정규화 Batch Normalization](#배치 정규화-batch-normalization)
- [바른 학습을 위해](#바른 학습을 위해)
  * [오버피팅](#오버피팅)
  * [가중치 감소(weight decay)](#가중치 감소-weight-decay-)
  * [드롭아웃](#드롭아웃)
- [적절한 하이퍼파라미터 값 찾기](#적절한 하이퍼파라미터 값 찾기)
  * [하이퍼파라미터 최적화](#하이퍼파라미터 최적화)
- [정리](#정리)





----

# 옵티마이저 (Optimizers)

# 매개변수 갱신

**[최적화 optimization]**    
**매개변수**의 최적값을 찾는 문제   
* 신경망 학습의 목적: **손실 함수**의 값을 가능한 한 **낮추는** **매개변수**를 찾는 것

## 확률적 경사 하강법 SGD
최적화 중 배운 방법: 매개변수의 **기울기(미분)**이용         
![image](https://user-images.githubusercontent.com/76824611/120159939-b244bc80-c230-11eb-93bb-0fe8001f8a2e.png)
* **$$W$$**: 갱신할 가중치 매개변수    
* **$$aL/aW$$**: **$$W$$** 에 대한 손실 함수의 기울기    
* **$$ƞ$$**: 학습률(실제론 0.01이나 0.001로 미리 정함)     
기울어진 방향으로 일정 거리만 가겠다는 단순한 방법


**[구현]**    
```python
class SGD:
	def __init __(self, lr = 0.01): 
		self.lr = lr

	def update(self, params, grads):
		for key in params.keys():
			params[key] -= self.lr * grads[key]
```
```update (params, grads)``` 메서드: SGD 과정에서 반복해서 불림     
* ```params```와 ```grads```: (지금까지의 신경망 구현과 마찬가지로) 딕셔너리 변수    

**[구현 예시]**   
```python
network = TwoLayerNet(...)
optimizer = SGD()

for i in range(10000):
...
	x _batch, t _batch = get _mini _batch(...) # 미니배치
	grads = network.gradient(x _batch, t _batch) 
	params = network.params
	optimizer.update(params, grads)
...
```
```optimizer```: ‘최적화를 행하는 자’라는 뜻의 단어       
* 이 코드에서는 **SGD**가 그 역할 함   
* 매개변수 **갱신**은 **optimizer**가 책임지고 수행하니,          
* **우리**는 optimizer에 **매개변수**와 **기울기** 정보만 넘겨주면 됨       
이처럼 최적화를 담당하는 클래스를 분리해 구현하면 **기능을 모듈화**하기 좋음
 
### SGD 단점 
![image](https://user-images.githubusercontent.com/76824611/120164309-66e0dd00-c235-11eb-8f24-68aa2fe0744a.png)
![image](https://user-images.githubusercontent.com/76824611/120164321-69dbcd80-c235-11eb-8e24-f58adc436740.png)
* 위 식의 최솟값은 (0,0) 인데 대부분의 화살표 방향이 그렇지X     
* 최적화 갱신 경로 : 최솟값인 (0, 0)까지 지그재그로 이동하니 비효율적      
* 비등방성 anisotropy 함수: (**방향에 따라** 성질, 즉 여기에서는 **기울기가 달라지는** 함수)에서는 탐색 경로가 비효율적이라는 것       
**원인**: **기울어진 방향**이 본래의 **최솟값과 다른 방향**을 가리켜서         
* 모멘텀, AdaGrad, Adam로 단점 개선
* **Y축 방향**으로의 **~~갱신 강도(위 아래)~~**를 줄이자!!!!

## 모멘텀 Momentum
‘운동량’을 뜻하는 단어    
![image](https://user-images.githubusercontent.com/76824611/120165956-110d3480-c237-11eb-9352-d45d82149f43.png)
![image](https://user-images.githubusercontent.com/76824611/120164851-f4243180-c235-11eb-86db-2b5759eed4b0.png)
* **$$W$$**: 갱신할 가중치 매개변수    
* **$$aL/aW$$**: W에 대한 손실 함수의 기울기     
* **$$ƞ$$**: 학습률    
* **$$v$$**:(velocity): 물리에서 말하는 속도   
* **$$αv$$**: 물체가 아무런 힘을 받지 않을 때 서서히 하강시키는 역할 (α는 0.9 등의 값으로 설정). 물리에서의 지면 마찰이나 공기 저항에 해당       
기울기방향으로 힘을 받아 물체가 가속된다는 물리법칙을 따름    




**즉,**     
* SDG: 기울어진 방향만 뺌
* Momentum: 기울어진 방향에 **마찰이나 공기저항을 제외하고** 뺌(물리에서의 속도로 간주)      

**[구현]**     
```python
class Momentum:
	# 인스턴스 변수 v가 물체의 속도: v는 초기화 때는 아무 값도 담지X
	def __init__(self, lr = 0.01, momentum = 0.9):
		self.lr = lr 
		self.momentum = momentum 
		self.v = None

	# W 업데이트 식
	def update(self, params, grads):
		#update ( ) 가 처음 호출될 때 매개변수와 같은 구조의 데이터를 딕셔너리 변수로 저장
		# 기울기와 형태를 같은 형태로 만듦
		if self.v is None:
			self.v = {} 
			for key, val in params.items():
				self.v[key] = np.zeros_like(val)

		#해당 속도와 기울기 조정
		#위의 해당 식 구현
		for key in params.keys():
			# αv의 momentum= a
			# v설정 식
			self.v[key] = self.momentum*self.v[key] – self.lr*grads[key] 
			# W 설정 식
			params[key] + = self.v[key]
```

![image](https://user-images.githubusercontent.com/76824611/120167509-c8567b00-c238-11eb-96d0-a255a6eb0a32.png)
모멘텀의 갱신 경로는 공이 그릇 바닥을 구르듯 움직임     
* SGD와 비교하면 **‘지그재그 정도’가 덜함**    

* **x축**    
  * 힘: 아주 **작지만**    
  * 방향: **일정**    
  * 한 방향으로 **일정하게 가속**        
* **y축**    
  * 힘: **크지만**    
  * 방향: 위아래로 번갈아 받음  **일정X, 상충**    
  * y축 방향의 **속도는 안정적X**     
* **전체적**: SGD보다 x축 방향으로 빠르게 다가가 지그재그 움직임이 줄어듦     

## AdaGrad
**학습률(ƞ)**: 신경망 학습에서 중요      
* 이 값이 너무 **작으면** **학습 시간이 너무 길어지고**,    
* 반대로 너무 **크면** 발산하여 **학습이 제대로 이뤄지지 않음**

**학습률 감소(learning rate decay)**: 이 학습률을 정하는 효과적 기술     
* 학습을 진행하면서 **학습률을 점차 줄여가는** 방법    
* **처음**에는 **크게 학습**하다가 **조금씩 작게 학습**    
* 실제 신경망 학습에 자주 쓰임     
      
학습률을 서서히 낮추는 가장 간단한 방법: 매개변수 ‘전체’의 학습률 값을 일괄적으로 낮추는 것.    
* 이를 더욱 발전시킨 것이 AdaGrad

### 정의
AdaGrad: **‘각각의’ 매개변수**에 **‘맞춤형’ 값**을 만들어 줌      
* 개별 매개변수에 적응적으로 **adaptive 학습률을 조정**하면서 학습 진행.     

**[AdaGrad의 갱신 방법 수식]**      
![image](https://user-images.githubusercontent.com/76824611/120169662-25533080-c23b-11eb-8d8e-c79e28c047ca.png)
* **$$W$$**: 갱신할 가중치 매개변수   
* **$$aL/aW$$**: W에 대한 손실 함수의 기울기   
* **$$ƞ$$**: 학습률   
* **$$h$$**: (기존 기울기 값)^2하여 계속+   
 * **☉기호**: 행렬의 원소별 곱셈          
    * **$$1/h^(1/2)$$**:매개변수를 갱신할 때 이를 곱해 학습률을 조정

매개변수의 원소 중에서 **많이 움직인(크게 갱신된) 원소**는 **학습률이 낮아진**다는 뜻    
* **학습률 감소**가 **매개변수의 원소마다 다르게 적용**  

기존 기울기에 계속 루트를 하여 점점 학습률을 낮춤    

**(작동방식)**    
 AdaGrad는 과거의 기울기를 제곱하여 계속 더해감    
 * 학습을 진행할수록 갱신 강도가 약해짐.    
 * **[Problem]** 무한히 계속 학습한다면 갱신량이 0이 되어 더 이상 갱신 X    


### RMSProp
위의 [Problem]이 문제를 개선한 기법.           
과거의 모든 기울기를 균일하게 더해가는 것X     

**지수이동평균(Exponential Moving Average, EMA)**
* ~~먼 과거의 기울기~~는 서서히 잊고 **새로운 기울기** 정보를 **크게**     
* **과거 기울기**의 반영 규모를 **기하급수적으로 감소**시킴    


**[AdaGrad의 구현]**
```python  
class AdaGrad:
	def __init __(self, lr = 0.01):
		self.lr = lr 
		self.h = None

	def update(self, params, grads):
		if self.h is None:
			self.h = {}
    		     	for key, val in params.items():
				self.h[key] = np.zeros_like(val)

			for key in params.keys():
				self.h[key] + = grads[key] * grads[key] 
				params[key] - = self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)
```
* **$$1e-7$$**: 이 작은 값 더함 (이 작은 값은 self.h[key]=0일 떄 대비)     
  * 대부분의 딥러닝 프레임 워크에서는 이 값도 인수로 설정 가능.

![image](https://user-images.githubusercontent.com/76824611/120173029-98aa7180-c23e-11eb-9461-047487a2b5ee.png)
* y축 방향: 기울 기가 커서 처음에는 크게 움직이지만, 그 큰 움직임에 비례해 갱신 정도도 큰 폭으로 작아지도록 조정 
   * 그래서 y축 방향으로 갱신 강도가 빠르게 약해지고, 지그재그 움직임이 줄어듦       

## Adam
**Adam**: 두 기법(모멘텀,AdaGrad)을 융합한 것          
* 모멘텀: 공이 그릇 바닥을 구르는 듯한 움직임을 보임       
* AdaGrad: 매개변수의 원소마다 적응적으로 갱신 정도를 조정(y의 지그재그 변화를 줄임)        

**Adam**: 하이퍼파라미터의 ‘편향 보정’진행    
![image](https://user-images.githubusercontent.com/76824611/120173751-503f8380-c23f-11eb-82b8-5e3887e1d7a9.png)

그릇 바닥을 구르듯 움직임(모멘텀)       
+ 모멘텀 때보다 공의 좌우 흔들림이 적음(이는 학습의 갱신 강도를 적응적으로 조정해서)       


**[Adam의 3개의 하이퍼파라미터]**          
* 학습률    
* 일차 모멘텀용 계수 β 1     
* 이차 모멘텀용 계수 β 2     

논문에 따른 기본 설정값,   
* β 1 은 0.9     
* β 2 는 0.999      
이 값이면 많은 경우에 좋은 결과를 얻을 수 있음.

---

# 어느 갱신 방법을 이용할 것인가?
**[위 4개 결과 비교]**     
![image](https://user-images.githubusercontent.com/76824611/128633810-74a0df55-c574-42f6-b386-7f3987f17075.png)
* 각자의 장단이 있어 잘 푸는 문제와 서툰 문제가 있음          
* 지금도 많은 연구에서 SGD를 사용.      
* 모멘텀과 AdaGrad도 시도해볼 만한 가치가 충분.      
* 요즘에는 많은 분이 Adam에 만족해함.        
* 일반적으로 SGD보다 다른 세 기법이 빠르게 학습하고, 때로는 최종 정확도도 높게 나타납니다.


----

# 가중치의 초깃값
신경망 학습에서 특히 중요한 것이 가중치의 초깃값      

**[초깃값을 0으로 하면?]**      
가중치 감소 weight decay 기법을 소개할 것             
* **오버피팅을 억제**해 범용성능을 높이는 테크닉         
* 가중치 매개변수의 값이 작아지도록 학습하는 방법     
* 가중치 값을 작게 하여 ~~오버피팅~~이 일어나지 않게 하는 것    
사실 지금까지 가중치의 초깃값은 0.01 * np.random.randn (10, 100 )처럼 정규분포에서 생성되는 값을0.01배 한 작은 값(표준편차가 0.01인 정규분포)을 사용.   


**(결론)**    
가중치 초깃값을 0으로 하면 학습이 올바로 이뤄지지 않음    
* 정확히는 ~~가중치를 균일한 값~~으로 설정 해서는 안 됨      

**이유**: 오차역전파법(오차를 점점 거슬러 올라가면서 비율에 맞게 다시 전파하는 것을 의미)(기울기를 효율적으로 구함)에서 모든 가중치의 값이 똑같이 갱신되기 때문      
(ex)     
2층 신경망에서 첫 번째와 두 번째 층의 가중치가 0     
* 순전파: 입력층의 가중치가 0이기 때문에 두 번째 층의 뉴런에 모두 같은 값이 전달됨     
* 역전파: 위의 순전파로 인해 두 번째 층의 가중치가 모두 똑같이 갱신된다(곱셈노드의 역전파)   
역전파 방법은 결과 값을 통해서 다시 역으로 input 방향으로 오차를 다시 보내며 가중치를 재업데이트 하는 것이다.        
물론 결과(오차율)에 영향을 많이 미친 노드(뉴런)에 더 많은 오차를 돌려줄 것이다.    
	 
![image](https://user-images.githubusercontent.com/76824611/128636670-571ec890-28d4-4801-9022-eac7667f9b00.png)

이 ‘가중치가 고르게 되어버리는 상황’을 막으려면 (정확히는 가중치의 대칭적인 구조를 무너뜨리려면) **초깃값을 무작위로 설정**해야 함.     

## 은닉층의 활성화값 분포
은닉층의 활성화값(다른 문헌에서는 계층 사이를 흐르는 데이터)(활성화 함수의 출력 데이터)의 분포를 관찰하면 중요한 정보를 얻을 수있음.       
* 이번 절에서는 **가중치의 초깃값**에 따라 **은닉층 활성화**값들이 어떻게 변화하는지 확인    
    
### 1) 기울기 소실 gradient vanishing
가중치를 표준편차가 1인 정규분포로 초기화할 때(너무 다름),    
활성화값들이 0과 1에 치우쳐 분포      
* 역전파의 기울기 값이 점점 작아지다가 사라짐
     
![image](https://user-images.githubusercontent.com/76824611/128637055-30ad0c08-202a-4751-92bd-99be22823de9.png)

### 2) 표현력 제한
가중치를 표준편차가 0.01인 정규분포로 초기화할 때(너무 같음),      
0.5 부근에 집중 -> 표현력 관점에서는 큰 문제       
* 다수의 뉴런이 거의 같은 값을 출력하고 있으니 뉴런을 여러 개 둔 의미가 없어짐
     
![image](https://user-images.githubusercontent.com/76824611/128637060-06ed0799-7015-4223-87cb-48c4b185e0b0.png)

➡ 각 층의 활성화값은 적당히 고루 분포되어야 함.     
층과 층 사이에 적당하게 **다양한 데이터가 흐르게 해야** 신경망 학습이 효율적으로 이뤄지기 때문 


### 각 활성화 함수 별 추천 초기값       
**[sigmoid나 tanh 등의 S자 모양 곡선]**   
**Xavier 초깃값($$1/√n$$)**: 권장하는 가중치 초깃값       
* **n**: 앞 계층의 노드가 n개라면 표준편차가 이것인 표준분포 사용(앞 층의 노드 수)       
* 일반적인 딥러닝 프레임워크들이 표준적으로 이용    
* Xavier 초깃값은 활성화 함수가 **선형**인 것을 전제로 이끈 결과. 
  * sigmoid 함수와 tanh 함수는 좌우 대칭이라 중앙 부근이 선형인 함수

![image](https://user-images.githubusercontent.com/76824611/128637261-380b33eb-65cf-42ee-8f59-261a7524c8ce.png)

Xavier 초깃값을 사용하면 앞 층에 노드가 많을수록 대상 노드의 초깃값으로 설정하는 가중치가 좁게 퍼짐      
➡ 많을 수록 좁게 분포
![image](https://user-images.githubusercontent.com/76824611/128637313-185bb9b7-b90c-492b-9d6b-1fbd5ef6c6d6.png)
➡ 이 결과를 보면 층이 깊어지면서 형태가 다소 일그러지지만, 앞에서 본 방식보다는 넓게 분포됨

**[ReLU를 사용할 때의 가중치 초깃값]**        
**He 초깃값($$√(2/n)$$)**: ReLU에 특화된 초깃값을 이용 권장 이 특화된 초깃값       
* ReLU는 음의 영역이 0이라서 더 넓게 분포시키기 위해 2배의 계수가 필요          
(std = 0.01)        
* 신경망에 아주 작은 데이터가 흘러 기울기 작음     
* 학습이 거의 X     
![image](https://user-images.githubusercontent.com/76824611/128637622-3ff04de2-e134-4c91-97df-2f59d3ac9885.png)

(Xavier 초깃값)       
* 기울기 소실(층이 깊어지면 활성화값들의 치우침)     
![image](https://user-images.githubusercontent.com/76824611/128637628-fd93a304-c9fa-4f24-a7ce-aaae7d8dfe28.png)


(He 초깃값)     
* 표준 분포를 더 크게 잡아 위의 문제를 완화시킴        
![image](https://user-images.githubusercontent.com/76824611/128637632-2b52aece-1b8d-4cfa-8bc0-c1d7d0e27086.png)



---


# 배치 정규화 Batch Normalization

앞 절에서는 각 층의 활성화값 분포를 직접 관찰 후, 가중치의 초깃값을 적절히 설정           
그렇다면 **각 층이 활성화를 적당히 퍼뜨리도록 ‘강제’**해보면?            
➡ 배치 정규화 Batch Normalization를 이용

**[배치 정규화 알고리즘]**    
**의미**    
1) 미니배치의 평균과 분산을 이용해서 정규화 한 뒤에      
2) scale 및 shift 를 감마(γ) 값, 베타(β) 값을 통해 실행     
3)  정규화 된 값을 활성화 함수의 입력으로 사용하고, 최종 출력 값을 다음 레이어의 입력으로 사용       

**장점**     
* 학습을 빨리 진행할 수 있다(학습 속도 개선).     
* 초깃값에 크게 의존하지 않는다(골치 아픈 초깃값 선택 장애여 안녕!).     
* 오버피팅을 억제한다(드롭아웃 등의 필요성 감소).         

➡ ‘배치 정규화 Batch Norm 계층’을 신경망에 삽입

![image](https://user-images.githubusercontent.com/76824611/128637880-045a1ae0-e79d-4e95-8b2c-e830601e2fd6.png)


**[배치 정규화 과정]**    
학습 시 미니배치를 단위로 정규화       
➡ 데이터 분포가 평균이 0, 분산이 1이 되도록 정규화     
미니배치 B = {x 1 , x 2 , ..., x m }이라는 m개의 입력 데이터집합     
**1)** 평균 μ B 와분산 σ B2 구함       
**2)** 입력 데이터를 **평균이 0, 분산이 1**이 되게(적절한 분포가 되게) 정규화.    
* 이 처리를 활성화 함수의 앞(혹은 뒤)에 삽입함으로써 **데이터 분포가 덜 치우치게** 할 수 있음.          ![image](https://user-images.githubusercontent.com/76824611/128638137-3490d074-08f8-486b-8eee-f303195c954b.png)
+ ɛ(epsilon, 엡실론) 는 작은 값(예컨대 10e-7 등)으로, 0으로 나누는 사태를 예방하는 역할    
    ex)       
    단순히 미니배치 입력 데이터{x 1 , x 2 , ..., x m }을 평균 0, 분산 1인 데이터 {x ˆ 1 , x ˆ 2 , ..., x ˆ m }으로 변환하는 일을 함        
    {4,5,6} -> {-0.01,0,0.01}

**3)** 배치 정규화 계층마다 이 정규화된 데이터에 고유한 확대 scale 와 이동 shift 변환을 수행.     ![image](https://user-images.githubusercontent.com/76824611/128638295-f1787682-e7ff-4e36-955e-29a22c8cc48c.png)
* γ: 확대     
* β: 이동     
처음에는 γ = 1(1배 확대), β = 0(이동 안함)부터 시작하고,     
학습하면서 적합한 값으로 조정해감     
➡ 이 알고리즘이 신경망에서 순전파 때 적용     
![image](https://user-images.githubusercontent.com/76824611/128638467-56f457c1-916f-46dd-9713-8c0201c65ab9.png) 


----

# 바른 학습을 위해

## 오버피팅
오버피팅이 일어나는 경우    
- 매개변수가 많고 표현력이 높은 모델    
- 훈련 데이터가 적음     
![image](https://user-images.githubusercontent.com/76824611/128638516-3382b030-c7e7-41e1-a0b0-f7747066537b.png) 
더 단순한 모델이 새 데이터를 더 잘 일반화함     
즉 왼쪽과 같은 경우가 오버피팅     

## 가중치 감소(weight decay)
오버피팅 억제기제        
학습 과정에서 **큰 가중치**에 대해 **큰 페널티**를 부과하여 **오버피팅 억제**     
(오버피팅은 가중치 매개변수의 값이 커서 발생하는 경우가 많기 때문)         

신경망 학습의 목적은 손실 함수의 값↓     
가중치의 제곱 노름 norm (L2 노름)(||W||2)( $$1/2 λw^2$$)을 손실 함수에 (+)      
➡ 손실함수 ↑       
➡ 가중치(W)가 커지는 것을 억제 가능(손실함수 줄이려고)         
  
**L2노름에 따른 가중치 감소= $$1/2 λw^2$$**     
(λ 람다 는 정규화의 세기를 조절하는 하이퍼파라미터)         
* λ를 크게 설정할수록 큰 가중치에 대한 페널티가 커짐     
* 1/2 미분 결과인 $$λw^2$$를 조절하는 상수      

* L2 노름은 각 원소의 제곱들을 더한 것       
가중치 W = (w 1 , w 2 , … ,w n ) ->√(W_I^2+⋯+W_n^2 )

## 드롭아웃
존재 이유: 신경망 모델이 복잡해지면 가중치 감소만으로는 대응하기 어려워짐    
**[의미]**     
* 뉴런을 임의로 삭제하면서 학습하는 방법.             
* 훈련 때 은닉층의 뉴런을 무작위로 골라 삭제.      
➡  삭제된 뉴런은 신호 전달 X       

**훈련 시**: 데이터를 흘릴 때마다 삭제할 뉴런을 무작위로 선택     
**시험 시**: 모든 뉴런에 신호를 전달       
➡  단, 시험 때는 **각 뉴런의 출력에 훈련 때 삭제 안 한 비율을 곱하여 출력**      
![image](https://user-images.githubusercontent.com/76824611/128639006-e40191a8-27ee-4cf7-bc23-88e22f9c1e95.png)
 

**[구현]**      
```python
class Dropout:
# self.mask는 x와 형상이 같은 배열을 무작위로 생성하고, 그 값이 
# dropout_ ratio보다 큰 원소만 True로 설정
def _ _init _ _(self, dropout _ratio = 0.5):
self.dropout _ratio = dropout _ratio 
self.mask = Non

def forward(self, x, train _flg = True): 
if train _flg:
self.mask = np.random.rand(*x.shape) > 
self.dropout _ratio 
return x * self.mask 
else:
return x * (1.0 - self.dropout _ratio)

# 역전파 때의 동작은 ReLU와 같음
# 즉, 순전파때 신호를 통과시키는 뉴런은 역전파 때도 신호를 그대로 통과시키고
# 순전파 때 통과시키지 않은 뉴런은 역전파 때도 신호를 차단
def backward(self, dout):
return dout * self.mask
```

**[forward(순전파)]**    
메서드에서는 훈련 때(```train_flg = True일 때```)만 잘 계산해두면 시험 때. 삭제 안 한 비율은 곱하지 않아도 OK      
실제 딥러닝 프레임워크들도 비율을 곱하지 않습니다.    
* 핵심은 훈련 시에는 순전파 때마다 **self.mask에 삭제할 뉴런을 False**로 표시       
 
![image](https://user-images.githubusercontent.com/76824611/128675347-7f54af52-f146-41ed-a391-225842b5281a.png)
* 훈련 데이터와 시험 데이터에 대한 **정확도 차이↓**      
   * 훈련 데이터에 대한 정확도가 100%에 도달X       
* **표현력↑** 오버피팅을 억제가능

**[앙상블 학습(ensemble learning)]**
**개별**적으로 학습시킨 여러 모델의 출력을 **평균** 내어 추론하는 방식        
* 신경망의 정확도 개선     
* 드롭아웃과 밀접
   * **학습 시**: 드롭아웃이 뉴런을 무작위로 삭제하는 행위를 매번 다른 모델을 학습시키는 것으로 해석         
   * **추론 시**: 뉴런의 출력에 삭제한 비율(이를테면 0.5 등)을 곱함으로써 앙상블 학습에서 여러 모델
의 평균을 내는 것과 같은 효과       
* 드롭아웃은 앙상블 학습과 같은 효과를 (대략) **하나의 네트워크**로 구현했다고 생각 가능    



-----

# 적절한 하이퍼파라미터 값 찾기
**하이퍼파라미터**: 예를 들어각 층의 뉴런 수, 배치 크기, 매개변수 갱신 시의 **학습률**과 **가중치 감소** 등을 말함     
* 모델의 성능에 큰 영향     
* 그 값을 결정하기까지는 많은 시행착오를 겪음.       
  
**정의**: 파라미터가 매게변수이므로 이는 **초 매개변수**   

**적용**    
**1)** dropout: 하이퍼파라미터는 **뉴런들을 out**시킬 비율
* 확률이 낮으면 효과 얻지X     
* 값이 크면 underfitting     


## 검증 데이터
**하이퍼파라미터의 성능을 평가 시**: 시험데이터(test용 not학습)를 사용 X          
**[이유]**     
시험 데이터를 사용하여 조정 시 하이퍼파라미터 값이 시험 데이터에 오버피팅되기 때문           
* 하이퍼파라미터 값의 ‘좋음’을 시험 데이터로 확인      
* 하이퍼파라미터의 값이 시험 데이터에만 적합하도록 조정      
* 범용 성능이 떨어짐      

**[결론]**     
검증 데이터(validation data) 필요     
하이퍼파라미터를 조정시 하이퍼파라미터 전용 확인 데이터    
* 훈련 데이터: 매개변수(가중치와 편향)의 학습에 이용      
* 검증 데이터: 하이퍼파라미터의 성능을 평가하는 데 이용    
* 시험 데이터: 신경망의 범용 성능 평가      

## 하이퍼파라미터 최적화
하이퍼파라미터의 ‘최적 값’이 존재하는 범위를 조금씩 줄여가는 것      
**범위를 조금씩 줄이려면**     
**1)** 대략적인 범위를 설정하고    
**2)** 그 범위에서 무작위로 하이퍼파라미터 값을 골라냄(샘플링)      
**3)** 2단계에서 샘플링한 하이퍼파라미터 값을 사용하여 학습하고, 검증 데이터로 정확도를 평가합니다(단, 에폭은 작게 설정합니다).      
**4)** 2,3단계를 특정 횟수(100회 등) 반복하며,     
그 정확도의 결과를 보고 하이퍼파라미터의 범위를 좁힘         

신경망의 하이퍼파라미터 최적화에서는,    
그리드 서치(grid search) 같은 ~~규칙적인 탐색~~보다는 **무작위로 샘플링**해 탐색하는 편이 좋은 결과       
* 최종 정확도에 미치는 영향력이 하이퍼파라미터마다 다르기 때문        

**[하이퍼파라미터의 범위]**     
‘대략적으로’ 지정하는 것이 효과적      
* <실제> 로그 스케일(log scale) 로 지정       
   * 0.001에서 1,000 사이(10 -3 ~10 3 )와 같이 ‘10의 거듭제곱’ 단위로 범위를 지정    

하이퍼파라미터를 최적화할 때는 딥러닝 학습에는 오랜 시간(예컨대 며칠이나 몇 주 이상)이 걸림    
-> 따라서 나쁠 듯한 값은 일찍 포기해라      
=> 학습을 위한 에폭을 작게 하여, 1회 평가에 걸리는 시간을 단축하는 것이 효과적        



----

# 정리
● 매개변수 갱신 방법에는 확률적 경사 하강법(SGD ) 외에도 모멘텀, AdaGrad, Adam 등이 있다.     
● 가중치 초깃값을 정하는 방법은 올바른 학습을 하는 데 매우 중요.     
● 가중치의 초깃값으로는 ‘Xavier 초깃값’과 ‘He 초깃값’이 효과적       
● 배치 정규화를 이용하면 학습을 빠르게 진행할 수 있으며, 초깃값에 영향을 덜 받게 된다.       
● 오버피팅을 억제하는 정규화 기술로는 가중치 감소와 드롭아웃이 있다.        
● 하이퍼파라미터 값 탐색은 최적 값이 존재할 법한 범위를 점차 좁히면서 하는 것이 효과적이다.       
