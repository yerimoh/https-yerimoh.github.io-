---
title: "[30] [INDEX] CS224N 정리"
date:   2021-03-9
excerpt: "CS224n: Natural Language Processing with Deep Learning"
category: [Deep Learning]
layout: post
tag:
- Deep Learning
order: 0

comments: true
---


본 포스팅은 CS224N을 한국어로 정리한 포스팅입니다   
* [CS224N lecture overview](https://web.stanford.edu/class/cs224n/)     
* [CS224N lecture vedio](https://www.youtube.com/watch?v=rmVRLeJRkl4&list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ)


-----


# [31] Lecture 1: Word Vectors   
  
[learn 31](https://yerimoh.github.io/DLCS31/){: .btn}  
- [**INTRO**](--#intro--)
- [**Problems with NLP**](#--problems-with-nlp--)
  * [Problems resources like WordNet](#problems-resources-like-wordnet)
  * [Representing words as discrete symbols](#representing-words-as-discrete-symbols)
- [**Word2Vec**](#--word2vec--)
  * [Representing words by their context](#representing-words-by-their-context)
  * [Word2Vec Overview](#word2vec-overview)
  * [Word2vec: objective function](#word2vec--objective-function)
  * [more about objective function](#more-about-objective-function)
- [**train the model**](#--train-the-model--)

   


------
-----


# [32] Lecture 2: Word Vectors 2 and Word Window Classification


[learn 32](https://yerimoh.github.io/DLCS32/){: .btn}  
- [**INTRO**](#--intro--)
- [**Word2vec2**](#--word2vec2--)
  * [negative sampling](#negative-sampling)
  * [aside](#aside)
  * [co-occurrence matrix](#co-occurrence-matrix)
- [**GLOVE**](#--glove--)
  * [evaluate word vectors](#evaluate-word-vectors)
    + [Intrinsic](#intrinsic)
    + [Extrinsic](#extrinsic)
- [**Word senses and word sense ambiguity**](#--word-senses-and-word-sense-ambiguity--)


