---
title: "Mat2vec: Unsupervised word embeddings capture latent knowledge from materials science literature 정리"
date:   2023-06-20
excerpt: "Unsupervised word embeddings capture latent knowledge from materials science literature"
category: [Paper]
layout: post
tag:
- Paper
order: 0

comments: true
---



**[원 논문]**     
[Unsupervised word embeddings capture latent knowledge from materials science literature](https://www.nature.com/articles/s41586-019-1335-8)https://www.nature.com/articles/s41586-019-1335-8

-----


# ABSTRACT
**[문제]**      
* scientific knowledge은 거의 text로 출판됨     
➡ 전통적인 통계 분석이나 현대적인 기계 학습 방법으로 분석하기 어려움.      
* 기존 materials research와 관련된 machine-interpretable data는 structured property databases [1](https://www.cambridge.org/core/journals/mrs-bulletin/article/materials-science-with-largescale-data-and-informatics-unlocking-new-opportunities/BE294BD45E360E45C9FE0253E702D6B5) [2](https://www.nature.com/articles/s41586-018-0337-2)에서 왔음        
➡ small fraction of the knowledge만 알 수 있음       
* 출판물에는 small fraction 값 외에도 저자가 해석한 **데이터 항목 간의 연결** 및 **관계**에 대한 귀중한 지식이 포함되어 있음.      
* 과거에는 위 문제를 개선하기 위해, large **hand-labelled datasets** for training를 사용하여 과학 문헌에서 정보를 검색하는 데 초점을 맞춤     


**[본 연구]**    
* **방법**     
   * 본 논문은 출판된 문헌에 존재하는 materials science knowledge이 **Human labelling or supervision 없이** information-dense word embeddings(EX, GLOVE)으로 효율적으로 인코딩될 수 있음을 보여줌   
* **장점**    
   * 화학 지식을 명시적으로 삽입하지 않고, 이러한 임베딩은 주기율표의 기본 구조 및 재료의 구조-특성 관계와 같은 **복잡한 재료 과학 개념을 포착** 가능          
   * 또한, 우리는 unsupervised method이 발견되기 몇 년 전 functional 응용 프로그램에 대한 materials를 추천할 수 있음을 보여줌
  ➡ 이것은 **미래의 발견에 관한 잠재적인 지식**이 **과거의 출판물에 상당 부분 내재**되어 있음을 시사함
* 본 논문의 연구 결과는 거대한 과학 문헌에서 **집단적인 방식으로 지식과 관계를 추출할 수 있는 가능성을 강조**하고 **과학 문헌 채굴에 대한 일반화된 접근 방식을 지향**합니다.     





----

# Main
**구문 및 의미 관계를 보존**하기 위해, 텍스트 말뭉치의 단어에 **high-dimensional vectors (embeddings)를 할당**하는 것은 자연어 처리(NLP)의 가장 기본적인 기술 중 하나임(EX, GloVe, Word2vec)      
* 예를 들어, 적절한 텍스트 본문에 대해 훈련할 때, 그러한 방법은 '유기' 벡터보다 '강철' 벡터에 코사인 거리만큼 더 가까운 단어 '철'을 나타내는 벡터를 생성해야 함     

---

**[model train]**         
* **1) text corpus 생성**      
embeddings을 trian하기 위해, 1922년부터 2018년 사이에 발표된 **약 3.3 million개의 scientific abstracts을** materials-related research가 포함될 가능성이 높은 1,000개 이상의 저널에서 수집 및 처리하여 약 **50만 개의 단어가 생성**하였다.       
* **2) skip-gram variation of Word2vec 사용**    
위에서 만든 text corpus를 skip-gram variation of Word2vec에 넣어서 훈련시킴    
이 모델은 target word의 200차원 임베딩을 학습하기 위한 수단임     


----

**[model 작동 예시]**      
![image](https://github.com/yerimoh/yerimoh.github.io/assets/76824611/c0e4c66c-af53-4172-a5bb-2a234bd4e092)
* **1) input word embedding**     
Target words 'LiCoO2'와 'LiMn2O4'는 one-hot encoding으로 바꿈     
즉, 해당 어휘 색인에 있는 단어(예: 그림에서 가각 5와 8번째 만 1임)는 1, 그 외에는 모두 0으로 나타냄.     
* **2) model train with input enbedding**          
이러한 one-hot encoded vectors는 single linear hidden layer (for example, 200 neurons)을 가진 신경망의 입력으로 사용됨      
주어진 Target 단어에서 특정 거리 내에서 언급된 모든 단어**(context words)를 예측하도록 훈련**됨          
ex) LiCoO2와 LiMn2O4와 같은 유사한 배터리 양극 재료의 경우, 텍스트에서 발생하는 컨텍스트 워드(예: 'cathode', 'electrochemical' 등)는 대부분 동일함
* **3) after train**     
이 output을 바탕으로 train이 완료된 후 hidden layer weights 업데이트      
이러한 hidden layer weights는 실제 단어 embedding이다.     

-----


**[main idea of model]**   
* 유사한 의미를 가진 단어가 유사한 맥락에서 나타나는 경우가 많기 때문에, 해당 embeddings도 유사할 것     
* 모델에 대한 자세한 내용은 방법 및 SUPPLEMENTARY INFORMATION S1 및 S2에 포함되어 있음     
여기서 GloVe와 같은 대체 알고리즘 옵션에 대해서도 논의합니다.
* 우리는 **algorithm에 화학 정보나 해석이 추가되지 않더라도**, 얻은 word embeddings이 다양한 벡터 연산(projection, addition, subtractio)을 사용하여 결합될 때, **화학적 직관과 일관되게 동작**한다는 것을 발견했음.
   * 예를 들어, 우리 corpus의 많은 단어들은 materials의 chemical compositions을 나타내며, LiCoO2(잘 알려진 리튬 이온 양극 화합물)와 가장 유사한 다섯 가지 물질은 normalized word embeddings의 dot product (projection)을 통해 결정될 수 있음.          
   * 우리의 모델에 따르면 $$LiCoO_2$$와 가장 유사한 compositions은 $$LiMn_2O_4$$, $$LiNi_{0.5}Mn_{1.5}O_4$$, $$LiNi_{0.8}Co_{0.2}O_2$$, $$LiNi_{0.8}Co_{0.15}Al_{0.05}O_2&&, &&LiNiO_2$$이다. 이 다섯가지는 모두 리튬 이온 양극 재료이다.              
* **domain-specific analogies 지원**       
   * 원래 Word2vec paper11에서 관찰한 것과 유사하게, 이러한 임베딩은 **도메인별일 수 있는 유사성**도 지원합니다.   
   * 예를 들어, 'NiFe'는 '강자성'이고, 'IrMn'은 '?'이고, 여기서 가장 적절한 반응은 '반강자성'이다.   
   * 이러한 유사성은 임베딩 간의 subtraction 및 addition 연산 결과에 가장 가까운 단어를 찾아 Word2vec 모델에서 표현되고 해결됨      
<center> ferromagnetic(강자성) − NiFe + IrMn ≈ antiferromagnetic(반강자성)</center>    

-----

**[임베딩 시각화]**      
* **주성분 분석(principal component analysis)을 사용한 시각화**        
  * 이러한 임베디드 관계를 더 잘 시각화하기 위해 주성분 분석(principal component analysis)(그림 1b)을 사용하여 Zr, Cr 및 Ni의 임베딩과 해당 산화물 및 결정 구조를 2차원에 투영했다.         
  * 감소된 차원에서도 '산화물(oxide of)'(Zr - ZrO2 ≈ Cr - Cr2O3 ≈ Ni - NiO)과 '구조(structure of)'(Zr - HCP ≈ Cr - BCC ≈ Ni - FCC) 개념에 대한 벡터 공간에서의 일관된 연산이 있다.       
  * 이는 zirconium이 표준 조건에서 hexagonal close packed (HCP) 결정 구조를 가지고 있고 주요 산화물이 ZrO2라는 사실이 임베딩에 잘 반영됨.       
    ![image](https://github.com/yerimoh/img/assets/76824611/39242ad7-919d-4c9e-ae51-b9c053d30302)
* **Other types of materials analogies captured by the model**     
  * 각 범주의 정확도는 50%에 육박하며, 이는 원래 Word2vec 연구에서 설정한 기준선과 유사함.       
![image](https://github.com/yerimoh/img/assets/76824611/62f885a1-4fab-423b-a57d-9899070b3aae)  
* **단어의 위치를 통한 관계성 표현**        
  * 특히, 우리는 화학 원소의 임베딩이 2차원에 투영될 때, **주기율표**에서 그들의 위치를 대표한다는 것을 발견함     
  * SUPPLEMENTARY INFORMATION 섹션 S4 및 S5에서 자세히 설명       
  * 활성화 에너지 예측(formation energy prediction—outperforming)과 같은 quantitative machine learning models에서 effective feature vectors 역할을 할 수 있음             
  ➡ 이는 이전에 보고된 몇 가지 선별된 특징 벡터를 능가함(밑의 그림 1c, d, SUPPLEMENTARY INFORMATION S6).          
    ![image](https://github.com/yerimoh/img/assets/76824611/f8950c86-6e57-4682-8cea-8e9a38fc3980)
* **본 논문의 강조점**       
  * 우리는 Word2vec가 이러한 entities를 단순히 strings로 취급함     
  * 모델에 화학적 해석이 명시적으로 제공되지 않음      
  ➡ 오히려 scientific abstracts에서 **단어의 위치를 통해** materials knowledge이 포착된다             


+ Extended Data Fig. 1 | Chemistry is captured by word embeddings
  
-----
----

## thermoelectric관련 실험



**[현 논문의 main advantage and novelty]**       
* 'thermoelectric(열전성)'과 같은 응용 키워드가 '$$Bi_2Te_3$$'와 같은 material formulae과 동일한 표현을 가지고 있다는 것임.   

* material embedding과 'thermoelectric' 임베딩의 cosine similarity이 높을 때,
text corpus는 필수적으로 이 material의 thermoelectric behaviour에 대해 보고하는 abstracts을 포함한다고 예상할 수 있다.    


**[실험 결과 & 가설 설정]**
* 그러나 본 논문의 임베딩 결과, **'thermoelectric'라는 단어와 상대적으로 코사인 유사성이 높은 다수의 물질**(아래 그림 참고)이 발견되었는데,
이 물질이 포함된 **abstract에는 본 물질이 'thermoelectric'라는 것을 명시적으로 나타내지 않는다**.         
➨ 우리는 이러한 사례들을 가짜라고 치부하기보다는, <span style="background-color:#fff5b1">그러한 사례들이 새로운 '**thermoelectric' materials의 예측으로 유용하게 해석**될 수 있는지 조사</span>했다.



<img width="93" alt="image" src="https://github.com/yerimoh/yerimoh.github.io/assets/76824611/e4dcde14-fd0e-41dd-b814-1e0754c5520f">
* thermoelectric materials의 순위는 'thermoelectric'이라는 단어가 포함된 material 임베딩의 cosine similarities을 사용하여 생성될 수 있음.      
* 'thermoelectric' 응용을 위해 아직 연구되지 않은 높은 순위의 물질이 관련선이 있다고 가정할 수 있다.   
 


----

### first test

첫 번째 테스트로, 우리는 예측된 thermoelectric compositions을 available computational data와 비교했다.         


구체적으로 본 논문은 임베딩 결과 중 아래의 과정을 통해 **material을 선정**하고 **선정된 material에 rank** 매긴 것이다.       
* 1️⃣ **예측 기준이 되는 데이터 셋과 비교**      
[density functional theory (DFT)(밀도함수 이론)](https://www.nature.com/articles/sdata201785)을 사용하여 계산된 약 48,000개의 compounds의 **thermoelectric power factors**(전체 thermoelectric 가치 수치(zT)의 중요한 구성 요소)**에 대한 데이터 세트**에 **3번 이상 언급된 물질** 선정        
➨ 그 결과, 두 데이터 세트 사이에 총 **9,483개의 화합물이 중복**됨 확인      
* 2️⃣ **예측 후보 선정**      
중복 물질 중,**7,663개**는 텍스트 말뭉치에서 **thermoelectric 키워드와 함께 언급된 적이 없으며, 예측 후보로 간주**될 수 있다.
* 3️⃣ **예측 후보 rank 설정**         
예측을 얻기 위해, 우리는 이 7,663개의 화합물 각각을 **'thermoelectric'이라는 단어 임베딩으로 정규화**된 **output 임베딩의 dot product**으로 rank를 매겼다.
<img width="271" alt="image" src="https://github.com/yerimoh/img/assets/76824611/6d9949fc-6ffc-40cf-9b67-81cd03884d13">  
(출력 대 단어 임베딩 사용에 관한 보충 정보 섹션 S1 및 S3 참조).      





**[rank 해석]**            
* 이 rank는 **text corpus에서 명시적으로 발생하지 않았음**에도 불구하고 **해당 물질이 scientific abstract의 'thermoelectric'이라는 단어와 공존**할 가능성으로 해석될 수 있다.       
* density functional theory응 이용해 계산된 power factors        
<img width="155" alt="image" src="https://github.com/yerimoh/img/assets/76824611/71230bdc-7fea-4272-bfc9-edc7bc3cecd0">
  * fig 구성       
    * **purple:** 1,820개의 알려진 thermoelectrics      
    * **green**: 7,663개의 아직 연구되지 않은 thermoelectric materials 후보 물질    
    * **점선:** 단어 임베딩 접근법에서 가장 높은 순위를 차지한 10개의 후보의 값,      
      상위 10개의 임베딩에 기반한 Power factors (not studied as thermoelectrics in our text corpus)      
      Li2CuSb, CuBiS2, CdIn2Te4, CsGeI3, PdSe2, KAg2SbS4, LuRhO3, MgB2C2, Li3Sb and TlSbSe2     
   * fig 해석
     * **상위 10개 예측(점선)이** 후보 물질의 평균(green), thermoelectric의 평균(purple) 모두에서 **더 좋은 computed power factor**($$μW ^{K-2} cm-^{1}$$)를 갖는다.      
     * 이러한 **상위 10(점선)개 예측**에 대한 40.8$$μW ^{K-2} cm-^{1}$$의 **average maximum power factor의 크기**     
        * 후보 물질(green)의 평균(11.5μW K-2 cm-1)보다 3.6배 크다.
        * 알려진 열전기의 평균(purple)(17.0$$μW ^{K-2} cm-^{1}$$)보다 2.4배 크다.
     * 또한 **상위 10개 예측**에서 가장 높은 세 가지  **power factors**은 **알려진 열전기(purple)의** **99.6번째**, 96.5번째 및 95.3번째 **백분위수**이다.         
     * 우리는 supervised methods와 대조적으로, 우리의 임베딩은 **텍스트 말뭉치만을 기반**으로 한다.       
       즉, **DFT 데이터를 사용하여 어떤 방식으로든 훈련되거나 수정되지 않는다**는 것에 주목한다.     


-----

### second test 

다음으로, 동일한 모델을 실험적으로 측정된 power factors를 [$$zTs$$](https://pubs.acs.org/doi/10.1021/cm400893e)와 직접 비교했다.        


우리의 접근 방식은 이러한 양에 대한 numerical estimations을 제공하지 않기 때문에,     
우리는 텍스트 말뭉치와 실험 세트에 모두 나타나는 83가지 재료에 대해 Spearman rank correlation을 통해 candidates의 상대적 ranking를 비교했다.      

maximum power factor 및 maximum zT에 대한 임베딩 기반 순위와 실험 결과의 59% 및 52%의 rank상관 관계를 얻었다.       

예상치 못하게 우리 모델은 이전 단락에서 사용된 power factor DFT 데이터 세트를 능가했는데, 이는 experimental maximum power factors과 31%의 순위 상관관계만 나타낸다.       



-----


### fianl test     
마지막으로, 모델이 과거 논문을 토대로 trian되었다면,  thermoelectric materials을 제대로 예측하였는지 실험하였다.     


**[실험 1]**     
* 구체적으로, 우리는 2001년과 2018년 사이에 출판된 abstracts으로만 구성된 18개의 다른 'historical' 텍스트 말뭉치를 생성함.        
* 우리는 각 **과거 데이터 세트**에 대해 별도의 단어 임베딩을 훈련했고, 이러한 임베딩을 사용하여 **미래(테스트) 연도에 보고될 가능성이 있는 상위 50개 thermoelectrics를 예측**했다.         


**[결과]**    
* 예측 날짜가 지난 매년, 우리는 thermoelectrics 키워드와 함께 문헌에 보고된 예측 열전 성분의 누적 백분율을 표로 작성했다.     
* 다양한 'historical' 데이터 세트에서 얻은 word embeddings을 사용한 thermoelectric materials 예측 결과.     
<img width="200" alt="image" src="https://github.com/yerimoh/img/assets/76824611/5067e00d-ffbe-473b-a4b0-29e758b21758">    
   * **그래프 detail**      
     * 회색 선은'historical' 데이터 세트의 결과(2001년과 2018년 사이에 출판된 abstracts)로 나타냄
     * 예를 들어, '2015'라는 레이블이 붙은 옅은 회색 선은 2015년 1월 1일 이전에 발표된 과학적 추상물에 대해서만 훈련된 모델을 사용하여, 상위 50개 예측 중 1년, 2년, 3년 또는 4년 후(즉 2015-2018년) 열전 키워드와 함께 문헌에 보고된 비율을 나타냅니다           
     * 각 회색 선은 예측을 위해 해당 연도 이전에 publish된 abstracts만 사용한다.       
      (예: 2001년 예측은 2000년 이전의 abstracts을 사용하여 수행됨).            
     * 선은 예측 이후 몇 년 동안 thermoelectrics로 보고된 예측 물질의 누적 백분율을 표시한다.
     초기 예측은 더 긴 테스트 기간에 걸쳐 분석될 수 있으므로 회색 선이 더 길어진다.
     * 결과는 평균(빨간색)이며, 모든 재료(파란색) 또는 [non-zero DFT bandgap materials](https://ceder.berkeley.edu/publications/2013_Jain_Materials_Project.pdf) (녹색)의 기준 백분율과 비교됨       
   * **결과 해석**         
     * 전반적으로. 우리의 결과는 **top 50 word embedding-based predictions materials** (빨간색 선)이 그 당시 우리의 말뭉치에서 무작위로 선택된 연구되지 않은 재료(파란색)와 비교하여, **향후 5년 내에 열전기로 연구될 가능성**이 **평균 8배 더 높았**음        
     * 또한 이 **물질(빨간색 선)**이 **non-zero DFT bandgap (녹색)보다 3배 더 높다**는 것을 나타냄      
     * 위 그림에서 시간이 지날수록 더 가파른 기울기로 표시된 것처럼, **더 최근의 데이터를 통합하는 더 큰 말뭉치의 사용은 성공적인 예측의 속도를 향상**시킴           






**[실험 2]**     
* 이러한 결과를 더 자세히 조사하기 위해,      
우리는 **2009년 이전에 발표된 abstracts**만을 사용하여 결정된 상위 5개 예측의 운명에 초점을 맞춤.       

**[결과]**      
* 아래 그림은 다음 해에 abstracts이 더 추가됨에 따라 이 상위 5개 화합물의 예측 순위의 진화를 보여줌          
<img width="204" alt="image" src="https://github.com/yerimoh/img/assets/76824611/e5d3626a-7deb-4051-90c7-4b4c1d793a75">       
  * **그래프 detail**     
    * 2009년 데이터 세트의 상위 5개 예측 material     
    * 더 많은 데이터가 수집됨에 따른 이 meterial의  prediction ranks      
    * marker(★): thermoelectric로서 첫 번째 published된 보고서의 year                 
  * **결과 해석**      
    *  **$$CuGaTe_2$$**     
      **현재 최고의 thermoelectric 중 하나**이며, 2012년 발표되기 **4년 전에 상위 5개 화합물로 예측**되었다.        
    * **$$ReS_2$$와 $$CdIn_2Te_4$$**     
    우리 알고리즘에서 상위 5개 목록에 처음 등장한 시점으로부터 약 **8-9년 후에 문헌에서 좋은 thermoelectric라고 제안**됨              
    우리는 2015년에 계층화된 **$$ReS_2$$의 순위가 급격히 증가**한 것이, **$$SnSe$$에 대한 기록 $$zT$$의 발견과 일치**한다는 것에 주목한다(이것도 계층화된 물질).    
    * **$$HgZnTe$$와 $$SmInO_3$$**      
    값비싼(Sm, In) 또는 독성(Hg) 요소를 포함하고 있으며 아직 연구되지 않았음     
    $$SmInO_3$$는 더 많은 데이터를 추가함에 따라 순위가 크게 떨어짐      

 
 
 2001년과 2018년 사이의 연도별 상위 10개 예측은 보충 표 S3에서 확인할 수 있습니다.


-----
----


## investigated the series of connections

'thermoelectric'라는 단어 옆에 언급되지 않은 물질이 어떻게 높은 기대 확률을 가진 thermoelectric로 식별되는지 설명하기 위해,  
prediction으로 이어질 수 있는 일련의 connections을 조사했다.     


<img width="226" alt="image" src="https://github.com/yerimoh/yerimoh.github.io/assets/76824611/f3fb9aa6-9fd6-4cca-8d28-6e9cf2c418e5">

A graph showing how the
context words of materials predicted to be thermoelectrics connect to the
word thermoelectric. The width of the edges between ‘thermoelectric’
and the context words (blue) is proportional to the cosine similarity
between the word embeddings of the nodes, whereas the width of the
edges between the materials and the context words (red, green and purple)
is proportional to the cosine similarity between the word embeddings of
context words and the output embedding of the material. The materials are
the first (Li2CuSb), third (CsAgGa2Se4) and fourth (Cu7Te5) predictions.
The context words are top context words according to the sum of the edge
weights between the material and the word ‘thermoelectric’. Wider paths
are expected to make larger contributions to the predictions. Examination
of the context words demonstrates that the algorithm is making
predictions on the basis of crystal structure associations, co-mentions
with other materials for the same application, associations between
different applications, and key phrases that describe the material’s known
properties.

그림 2c에서, 우리는 상위 5개 예측(확장 데이터 표 2)의 세 가지 재료를 이러한 재료를 '열전성'에 연결하는 몇 가지 핵심 문맥 단어와 함께 제시합니다. 예를 들어, CsAgGa2Se4는 '칼코게나이드', '밴드 갭', '광전자' 및 '광전자 응용 프로그램' 옆에 나타날 가능성이 높습니다. 많은 좋은 열전기는 칼코게나이드이며, 밴드 갭의 존재는 대부분의 열전기에 중요하며, 광전자 간에 큰 중복이 있습니다, 태양광 및 열전 재료(추가 정보 섹션 S8 참조). 결과적으로, 이 키워드들과 CsAgGa2Se4 사이의 상관관계는 예측으로 이어졌습니다. 이러한 직접적인 해석 가능성은 재료 발견을 위한 다른 많은 기계 학습 방법보다 큰 장점입니다. 우리는 또한 잘 알려진 열전 재료 클래스가 아님에도 불구하고 유망한 특성을 나타내는 몇 가지 예측이 발견되었다는 것에 주목합니다(보조 정보 섹션 S10 참조). 이것은 단어 임베딩이 사소한 구성적 또는 구조적 유사성을 넘어 인간 과학자가 직접 접근할 수 없는 잠재적 지식을 열 수 있는 잠재력을 가지고 있음을 보여줍니다.

To illustrate how materials never mentioned next to the word ‘thermoelectric’ are identified as thermoelectrics with high expected probability, we investigated the series of connections that can lead to a prediction. In Fig. 2c, we present three materials from our top five predictions (Extended Data Table 2) alongside some of the key context words that connect these materials to ‘thermoelectric’. For instance, CsAgGa2Se4 has high likelihood of appearing next to ‘chalcogenide’, ‘band gap’, ‘optoelectronic’ and ‘photovoltaic applications’: many good thermoelectrics are chalcogenides, the existence of a bandgap is crucial for the majority of thermoelectrics, and there is a large overlap between optoelectronic, photovoltaic and thermoelectric materials (see Supplementary Information section S8). Consequently, the correlations between these keywords and CsAgGa2Se4 led to the prediction. This direct interpretability is a major advantage over many other machine learning methods for materials discovery. We also note that several predictions were found to exhibit promising properties despite not being in any well known thermoelectric material classes (see Supplementary Information section S10). This demonstrates that word embeddings go beyond trivial compositional or structural similarity and have the potential to unlock latent knowledge not directly accessible to human scientists.


마지막 단계로 '광전학', '위상 절연체' 및 '강유전체'의 세 가지 추가 키워드에 대한 예측의 역사적 검증을 수행하여 접근 방식의 일반화 가능성을 검증했습니다. 우리는 이러한 예측에 사용되는 단어 임베딩이 열전기 예측과 동일하다는 것을 강조합니다. 우리는 단순히 도트 제품을 다른 대상 단어로 수정했습니다. 특히 절차가 거의 변경되지 않은 상태에서 세 가지 기능 애플리케이션 모두에 대해 그림 3a와 유사한 추세를 발견했으며, 그 결과는 확장 데이터 그림 2와 확장 데이터 표 3에 요약되어 있습니다.

As a final step, we verified the generalizability of our approach by performing historical validation of predictions for three additional keywords—‘photovoltaics’, ‘topological insulator’ and ‘ferroelectric’. We emphasize that the word embeddings used for these predictions are the same as those for thermoelectrics predictions; we have simply modified the dot product to be with a different target word. Notably, with almost no change in procedure, we find trends similar to the ones in Fig. 3a for all three functional applications, with the results summarized in Extended Data Fig. 2 and Extended Data Table 3.
The success of our unsupervised approach can partly be attributed
to the choice of the training corpus. The main purpose of abstracts is
to communicate information in a concise and straightforward manner,
avoiding unnecessary words that may increase noise in embeddings
during training. The importance of corpus selection is demonstrated
in Extended Data Table 4, where we show that discarding abstracts
unrelated to inorganic materials science improves performance, and
models trained on the set of all Wikipedia articles (about ten times
more text than our corpus) perform substantially worse on materials
science analogies. Contrary to what might seem like the conventional
machine learning mantra, throwing more data at the problem is not
always the solution. Instead, the quality and domain-specificity of the
corpus determine the utility of the embeddings for domain-specific
tasks



We suggest that the methodology described here can also be generalized to other language models, such that the probability of an entity
(such as a material or molecule) co-occurring with words that represent a target application or property can be treated as an indicator of
performance. Such language-based inference methods can become an
entirely new field of research at the intersection between natural language processing and science, going beyond simply extracting entities
and numerical values from text and leveraging the collective associations present in the research literature. Substitution of Word2vec with
context-aware embeddings such as BERT25 or ELMo26 could lead to
improvements for functional material predictions, as these models are
able to change the embedding of the word based on its context. They
substantially outperform context-independent embeddings such as
Word2vec or GloVe across all conventional NLP tasks. Also, in addition
to co-occurrences, these models can capture more complex relationships between words in the sentence, such as negation. In the current
study, the effects of negation are somewhat mitigated because scientific
abstracts often emphasize positive relationships. However, a natural
extension of this work is to parse the full texts of articles. We expect
the full texts will contain more negative relationships and in general
more variable and complex sentences, and will therefore require more
powerful methods.
Scientific progress relies on the efficient assimilation of existing
knowledge in order to choose the most promising way forward and to
minimize re-invention. As the amount of scientific literature grows, this
is becoming increasingly difficult, if not impossible, for an individual
scientist. We hope that this work will pave the way towards making the
vast amount of information found in scientific literature accessible to
individuals in ways that enable a new paradigm of machine-assisted
scientific breakthroughs.




----



3️⃣ 예측 후보 순위 설정 방법 자세히 보기    

**[Figure S3: Word vs output embeddings]**         
<img width="295" alt="image" src="https://github.com/yerimoh/yerimoh.github.io/assets/76824611/1cbb52cf-643f-4fbf-b1d8-5f8112133640">       
* **Word embeddings:** application keyword와 material formula 모두에 대해 Word embeddings을 사용하는 것      
* **output embeddings:** formula의 output embedding과 application keyword의 Word embedding 을 사용하는 것          



**[ranking(결과적으로 predictions)의 선정 방법]**           
* application keyword(예: “thermoelectric”)의 임베딩과 모든 재료의 임베딩(일부 카운트 임계값, 우리의 경우 3 이상)을 곱하여 수행됩니다. 응용 프로그램 키워드의 경우 항상 정규화된 단어 임베딩을 사용합니다. 그러나 재료의 경우 단어 또는 출력 임베딩(그림 S1b)을 사용하려고 합니다. 단어 임베딩을 사용할 경우, 응용 프로그램 키워드와 재료 단어의 유사성을 기준으로 순위가 결정됩니다. 사람들은 이것을 텍스트의 상호 교환성으로 생각할 수 있습니다. 대신 재료의 정규화된 출력 임베딩을 사용하는 경우, 모든 재료가 텍스트에서 동일한 횟수로 언급된 경우 응용 프로그램 키워드와 재료 공식이 서로 옆에 언급될 가능성을 기반으로 예측이 이루어집니다. 이 두 번째 접근법은 일반적으로 그림과 같이 더 나은 결과를 산출합니다. S3 및 이 작업 전반에 걸쳐 사용됩니다.

The ranking (and consequently predictions) are performed by multiplying the embedding of the application keyword (e.g. “thermoelectric”) with the embeddings of all materials (with some count threshold, more than 3 in our case). For the application keyword we always use the normalized word embedding. However, for the materials we attempt to use either the word or the output embedding (fig. S1b). If we use word embeddings, the ranking is based on similarity of the application keyword and the material word. One can think of this as their interchangeability in text. If instead we use the normalized output embedding of the material, the predictions are based on the likelihood of the application keyword and the material formula being mentioned next to each other, if all materials were mentioned equal number of times in the text‡ . This second approach generally yields better results as shown in fig. S3 and is used throughout this work.







