---
title: "[02] GPT-1 정리 "
date:   2021-03-13
excerpt: "Improving Language Understanding by Generative Pre-Training"
category: [Paper]
layout: post
tag:
- Paper
order: 0

comments: true
---

# intro
자연어이해: 원문함의, 질답, 의미 유사성 평가, 문서분류 등 넓은 범위의 task로 이뤄짐   
하지만, 이러한 task들의 학습을 위한 **데이터 부족**       
이 모델구조는 변화를 **최소화**함   
      

## 핵심  
#multi-head self-attention을 이용해 sequential computation 을 줄여 더 많은 부분을 병렬처리가 가능하게 만들면서 동시에 더 많은 단어들 간 dependency를 모델링 한다는 것

## 읽기 위해 필요한 지식
[attention](링크 삽입) 
[transformer](https://yerimoh.github.io//Lan/)

## 원 논문
[Improving Language Understanding by Generative Pre-Training](https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf)

---

# 목차  
- [서론](#서론)
  * [기존 모델의 한계점](#기존-모델의-한계점)
  * [GPT-1의 개요](#gpt-1의-개요)
    + [학습 단계](#학습-단계)
    + [평가](#평가)
- [Framework](#framework)
  * [Unsupervised pre-training](#unsupervised-pre-training)
  * [Supervised fine-tuning](#supervised-fine-tuning)
    + [과정](#과정)
    + [도움이 되는 이유](#도움이-되는-이유)
  * [Task-specific input transformations](#task-specific-input-transformations)
    + [처리 방법](#처리-방법)
  * [결론](#결론)




----


# 서론
**NLP에서 지도학습에 대한 의존성 낮추는 법**      
* 원본 그대로의 텍스트에서 효과적으로 학습하는 능력   
(기존 language model)    
labeling이 필수_ 구글의 자동완성 등


**but,**      
대부분의 딥러닝 방법은 **수동**으로 분류된 방대한 양의 데이터를 필요로 함         
⚠ 분류된 자원의 부족     
⚠ label이 정확하지 않음

**해결 책 필요**          
미분류 데이터로부터 언어적 정보를 얻어낼 수 있는 모델 필요     
ex) 사전학습된 단어 embedding      

## 기존 모델의 한계점     
**미분류 텍스트**에서 단어 수준 정보 이상의 것을 얻는 것이 어려운 이유     
* 어떤 최적화 목적함수가 transfer에 유용한 텍스트 표현(representation)을 배우는 데 **효과적인지 불분명**.     
* 학습된 표현을 **다른 과제로 전이**하는 최적의 방법 존재하지 않음     
  * 존재하는 방법들은 과제에 특화된(task-specific) 변화 필요       
  * 이러한 불확실성은 언어처리에 대한 효과적인 준지도학습 접근법의 개발을 어렵게 함  
* 한정된 데이터에 과적합 되기 쉬운 모델인 ``` discriminative 모델``` 사용

## GPT-1의 개요
**비지도 사전학습(unsupervised pre-training)** 과 **지도 미세조정(supervised fine-tuning)** 의 조합을 사용   
=> 언어이해 과제를 위한 준지도학습 접근법을 탐색     
**[목표]**     
약간의 조정만으로 넓은 범위의 과제에 전이 및 적용할 수 있는 **범용 표현**을 학습하는 것           

### 학습 단계
학습은 두 단계를 거침        
**1)** 신경망모델의 **초기 parameter를 학습**하기 위해 **미분류 데이터**에 대한 언어모델링 **목적함수**를 사용  
**2)** 이 parameter를 연관된 **지도 목적함수**를 사용하여 **목표 과제에 적용**시킴      

모델 구성은 기계번역, 문서생성, 구문분석 등에 상당한 성능을 보이는 [Transformer](https://yerimoh.github.io//Lan/)를 사용.     
* 이 모델은 RNN 등에 비해 장거리 의존성을 다루는 데 뛰어나 더 많은 구조화된 memory를 쓸 수 있게 함.      

전이 중에는 traversal-style 접근법에서 얻은 과제특화된 입력적응을 이용하며 입력은 한 개의, 일련의 ‘연속된 token’으로 주어짐.    
* 이러한 적응방법은 사전학습된 모델의 구조를 바꾸는 것을 최소화     

### 평가
평가 기준    
* 자연어추론    
* 질답     
* 의미 유사성     
* 문서분류
과제에 대한 지식이 없는 이 범용 모델은 12개 중 9개의 과제에서 state-of-the-art 결과를 보이며 선전함   

### 장점
~~``` discriminative모델```~~ 대신 generative 모델 사용     
* 더 범용적으로 사용 가능(매우 많은 데이터 학습 가능)   
* 데이터가 많아질수록 학습효과 뛰어남(discriminative는 많아질수록 오버피팅)     
* 학습시간이 길어짐     
* **labeling 필요 없음**(사람이 필요 없음)    
![image](https://user-images.githubusercontent.com/76824611/118375158-d8e0e180-b5fa-11eb-8864-7e091bcd76d0.png)



---

# Framework
학습은 두 단계로 진행된다.

**1)** ```Unsupervised pre-training``` 큰 말뭉치에서 대용량의 언어모델을 학습.      
**2)** ```Supervised fine-tuning``` 분류 데이터를 써서 특정 과제에 맞춰 모델을 미세조정      

## Unsupervised pre-training
token의 비지도 말뭉치  $$U=u_1,…,u_n$$이 주어질 때,     
다음 likelihood를 **최대화**하도록 표준언어모델링 목적함수(objective function)(최댓값, 최솟값을 구하는 함수)를 사용      

**$$L_1(U)=∑_i{logP(u_i|u_(i−k),...,u_(i−1);Θ)}$$$**       
* **k**: 문맥고려범위(context window)    
* **P**: 조건부확률    
  * **Θ**: parameter가 Θ인 신경망을 사용하도록 설계됨.       
  * 이들은 [**확률적 경사하강법(SGD)**](링크 삽입)에 의해 학습됨   

GPT는 언어모델로 Transformer의 변형인 **multi-layer Transformer decoder**를 사용.     
```multi-layer Transformer decoder```     
* 이 모델은 **입력 문맥** token에 [multi-headed self-attention](https://yerimoh.github.io//Lan/#positional-encoding-%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%B4-%EC%8B%9C%ED%80%80%EC%8A%A4%EC%9D%98-%EC%88%9C%EC%84%9C-%EB%82%98%ED%83%80%EB%82%B4%EA%B8%B0)을 적용한 후,      
*  목표 token에 대한 **출력분포를** 얻기 위해 position-wise feedforward layer를 적용      

**$$h_0=UW_e+W_p$$**      
**$$h_l=transformer_block(h_(l−1))  ∀l∈[1,n]$$**   
**$$P(u)=softmax(h_n(W_e)^T)$$**    

* **$$U=u_1,…,u_n$$**: token의 문맥벡터, 
* **$$n$$**: layer의 수       
* **$$W_e$$**: token embedding 행렬,  


## Supervised fine-tuning
위의 $$L1(U)$$ likelihood에 따라 모델을 학습시키고 나면,    
parameter를 목표 과제에 맞춰 **미세조정**한다.    

* **C**: 분류된 dataset     
* **$$(h_I)^m$$**: 최종 transformer block의 활성값   
* **$$W_y$$**:  parameter
 
(구성요소)   
* **$$x^1,…,x^m$$**: 일련의 입력 token    
* **y**: 정답(label)     

### 과정
[1] 입력은 최종 transformer block의 활성값 $$(h_I)^m$$을 얻기 위해 입력토큰을 위의 **사전학습된 모델**에 전달     
[2] 이 결과는 **다시** $$y$$(정답)를 예측하기 위해 parameter $$W_y$$와 함께 **선형 출력층으로 전달**    
     
(주어진 입력에서 정답일 확률)     
$$P(y|x^1,...,x^m)=softmax((h_I)^m W_y)$$    

이는 다음 likelihood를 최대화하도록 함:     
$$L_2(C)= ∑_(x,y){logP(y|x^1,...,x^m)}$$   

### 도움이 되는 이유
미세조정 단계에 **언어모델**을 **보조 목적함수로 포함**시키는 것이 학습을 돕는 이유      
* 지도 모델의 일반화를 향상시키고      
* 수렴을 가속화    


구체적으로, weight λ  에 대해 다음 목적함수를 최적화함:     
**$$L_3(C)=L_2(C)+λ∗L_1(C)$$**   


💎 종합적으로, 미세조정 단계에서 추가된 parameter는 
* $$W_y$$,    
* 구분자 token을 위한 embedding 뿐임      


## Task-specific input transformations
텍스트 분류와 같은 몇몇 과제는 모델 미세조정을 위에서 언급한 방법으로 직접 가능.    
⚠ 그러나 **질답**과 **원문함의**와 같은 과제에서는 입력 형태가 문장의 2~3개인 등 많이 다르므로      
   이를 처리해주어야 함.       

### 처리 방법
질문/텍스트/선택지/가정/전제 등을 하나씩 따로 ```구분자(delimiter)```로 구분하여 **하나로 연결**하는 방식 사용.    
[구체적인 방법]
* **Textual entailment**(함의): 함의 문제에서는 전제 p와 가정 h를 ```구분자``` $로 연결        

* **Similarity**(유사):  두 개의 텍스트 사이에 순서가 딱히 없음   
     *  텍스트 두 개를 **다른 순서**로 이어붙여 총 2개를 입력으로 씀        
     *  이는 각각의 Transformer에 입력으로 들어간다.       

* **Question Answering and Commonsense Reasoning**(질답&상식추론): [문맥 문서 ;질문 ; $; 가능한 답변 ]로 연결
  * 입력의 개수는 **답변의 개수**만큼 생성됨      
 ![image](https://user-images.githubusercontent.com/76824611/118374496-5a367500-b5f7-11eb-8cb5-10e175500db3.png)


----

## 결론
생성적 사전학습과 특정과제에 특화된 미세조정을 통해 학습된, ~~과제에 대해 별다른 지식~~이 없으며 **자연어이해 능력**이 뛰어난 단일 모델(framework)를 소개함          
* 넓은 범위에 걸친 언어적 정보를 포함하는 다양한 말뭉치에 대해 사전학습을 진행
* 중요한 일반지식과 질답, 의미유사성 평가, 함의 확인, 문서분류 등의 과제에서 성공적으로 전이
* 장거리 의존성을 처리하는 능력을 학습

