---
title: "FastText: Enriching Word Vectors with Subword Information 정리"
date:   2022-11-10
excerpt: "Enriching Word Vectors with Subword Information"
category: [Paper]
layout: post
tag:
- Paper
order: 0

comments: true
---


   
# 원 논문
[Enriching Word Vectors with Subword Information](https://arxiv.org/abs/2112.10508)

**[소스코드]**     
* [git adress](https://github.com/zhang-yu-wei/MTP-CLNN)


**[사전 학습]**
* 읽기 전 아래의 포스트들을 읽어야 무슨소린지 알아듣기 편하다..!   
* 

---

# Abstract
**[기존 모델의 문제]**      
* 레이블이 지정되지 않은 큰 말뭉치에 대해 훈련된 Continuous word representations은 많은 자연어 처리 작업에 유용하다.    
이러한 표현을 학습하는 인기 있는 모델은 각 단어에 고유한 벡터를 할당하여 **단어의 형태를 무시**한다.    
이렇게 단어의 형상을 무시하는 문제는 특히 **어휘가 많고 희귀한 단어가 많은 언어**의 경우 더 문제가 된다.    

**[본 논문에서의 해결법]**      
* 본 논문에서는 **skipgram model**을 기반으로 한 새로운 접근법을 제안한다.     
여기서 각 단어는 문자 n-grams의 bag of character로 표현된다.     
벡터 표현은 각 문자 n-grams과 연관되어 있으며, 단어는 이러한 표현의 합으로 표현된다.     

**[skipgram model의 장점]**      
* 빠름      
* 큰 말뭉치에서 모델을 빠르게 훈련 가능      
* 훈련 데이터에 나타나지 않은 단어에 대한 단어 표현을 계산 가능      
* 단어 유사성과 유추 작업 모두에서 9개의 다른 언어로 우리의 단어 표현 평가한(ord similarity and analogy tasks)결과,          
최근 제안된 형태학적 단어 표현과 비교하여 벡터가 이러한 작업에서 최첨단 성능을 달성한다는 것을 보여준다.    
