---
title: "[02] Machine Learning: sklearn을 사용한 MNIST 분류  "
date:   2020-03-10
excerpt: "머신러닝의 여러가지 기초 개념과 용어, 지도학습, 비지도 학습의 차이"
category: [Machine Learning]
layout: post
tag:
- Machine Learning
order: 0

comments: true
---

# 

----
---

👀, 🤷‍♀️ , 📜    
이 아이콘들을 누르시면 코드, 개념 부가 설명을 보실 수 있습니다:)

---
----

# INTRO

고등학생과 미국 인구조사국 직원들이 손으로 쓴 70,000 개의 작은 숫자 이미지를 모은 MNIST 데이터셋을 사용할 것이다.      
각 이미지에는 어떤 숫자를 나타내는지 레이블링이 되어 있다.         

이 데이터셋은 학습용으로 아주 많이 시용되기 때문에 머신러닝 분야의 ‘Hello World’ 라고 불린다.       

![image](https://user-images.githubusercontent.com/76824611/138802301-5dc673f8-22d0-4d16-8f3e-d80fd20b769a.png)

먼저, 필요한 모듈들을 모두 불러오겠다
<details>
<summary>👀코드 보기</summary>
<div markdown="1">
  
```python
# 파이썬 ≥3.5 필수
import sys
assert sys.version_info >= (3, 5)

# 사이킷런 ≥0.20 필수
import sklearn
assert sklearn.__version__ >= "0.20"

# 공통 모듈 임포트
import numpy as np
import os

# 노트북 실행 결과를 동일하게 유지하기 위해
np.random.seed(42)

# 깔끔한 그래프 출력을 위해
%matplotlib inline
import matplotlib as mpl
import matplotlib.pyplot as plt
mpl.rc('axes', labelsize=14)
mpl.rc('xtick', labelsize=12)
mpl.rc('ytick', labelsize=12)

# 그림을 저장할 위치
PROJECT_ROOT_DIR = "."
CHAPTER_ID = "classification"
IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, "images", CHAPTER_ID)
os.makedirs(IMAGES_PATH, exist_ok=True)

def save_fig(fig_id, tight_layout=True, fig_extension="png", resolution=300):
    path = os.path.join(IMAGES_PATH, fig_id + "." + fig_extension)
    print("그림 저장:", fig_id)
    if tight_layout:
        plt.tight_layout()
    plt.savefig(path, format=fig_extension, dpi=resolution)
```
  
</div>
</details>


----


# 데이터 셋 불러오기   

그럼 먼저 데이터 셋을 불러와보자.      

  
```python
from sklearn.datasets import fetch_openml
mnist = fetch_openml('mnist_784', version=1, as_frame=False)
mnist.keys()
```
  
이 데이터 셋을 살펴보기 위해 ```mnist.keys()```를 사용하면,       
* **DESCR**: 데이터셋을 설명      
* **data**: 샘플이 하나의 행, 특성이 하나의 열로 구성된 배열    
* **target**: 레이블 배열(정답)   
  *  레이블은 문자열임 -> 대부분 머신러닝 알고리즘은 숫자를  기대하므로를 정수(```uint8```)로 변환 필요.      
  
```python
dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])

# target 정수 변환
y = mnist["target"]
y = y.astype(np.uint8)
```  

<details>
<summary>📜 위 배열들 자세히 보기</summary>
<div markdown="1">
 
이미지가 70,000 개 존재    
* 각 이미지에는 784 개의 특성 존재   
  * 이미지가 28 X 28 픽셀이기 때문.       
  * 개개의 특성은 단순히 흰색 부터 255( 검은색)까지의 픽셀 강도를 나타냄     
![image](https://user-images.githubusercontent.com/76824611/138952849-416f3172-79ac-4ff9-aa99-83550c07106a.png)

```python
X, y = mnist["data"], mnist["target"]
X.shape
#(70000, 784)
y.shape
#(70000,)
```
  
</div>
</details>
  
<details>
<summary>📜 targe 자세히 보기</summary>
<div markdown="1">
 

```python
y = mnist["target"]
```
  
이때, y[0]은 아래와 같다
![image](https://user-images.githubusercontent.com/76824611/138953180-e9ee0a77-6e85-4477-aeae-bdbabe1beb98.png)
  
그러므로 이 이미지의 정답 레이블은 5여야 한다.  
  
```python
y[0]
# '5'
```
  
</div>
</details>  


## 훈련세트, 테스트 세트로 나누기
[더 알아보기](https://yerimoh.github.io/DL6/#%ED%8A%B8%EB%A0%88%EC%9D%B4%EB%8B%9D-%EB%B0%8F-%EA%B2%80%EC%A6%9D-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%A0%88%EC%9D%B4%EB%B8%94)
* **훈련 세트**: 이미 섞여 있어서 모든 교차 검증 폴드를 비슷하게 만듦.     
   * 하나의 폴드라도 특정 숫자가 누락되면 안 됨         


 

이 MNIST 데이터셋은 **이미** 나뉘어 있음.      
* 훈련 세트(앞쪽 60,000 개 이미지)       
* 테스트 세트 (뒤쪽 10,000 개 이미지)      

```python
X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]
```
  


-----
-----


# 이진 분류기 훈련

## 1. 타깃 벡터 만들기
**이진분류기 binary classfier**: **두**개의 답 중 하나를 식별하는 것       

즉 이 문제에 적용시켜보면, 5라는 손글씨를 판별할 때,       
* ‘5'       
* '5 아님’(5가 아닌 다른 정답들)       

위와 같은 두 개의 클래스로 구분됨.      


그럼 이제 이를 위해 타깃 벡터를 만들어보겠다 


  
```python
y_train_5 = (y_train == 5) # 5는 True고, 다른 숫자는 모두 False
y_test_5 = (y_test == 5)
```
  

----

## 2. 모델 선택

이제 분류 모델을 하나 선택해서 훈련시켜보겠다.     

**[선택 모델]**    
[확률적 경사 하강법 Stochastic Gradient Descent (SGD)](https://yerimoh.github.io/DL5/#%ED%99%95%EB%A5%A0%EC%A0%81-%EA%B2%BD%EC%82%AC-%ED%95%98%EA%B0%95%EB%B2%95-sgd)        

*  ``` sklearn```의  ```SGDClassifier ``` 클래스      
*  매우 큰 데이터셋을 효율적으로 처리하는 장점을 지님      
   * GD가 한 번에 하나씩 훈련 샘플을 독립적으로 처리하기 때문(위 링크에 나와있음)      


<details>
<summary>📜 데이터셋을 섞는 이유 (독립적 처리의 이유)</summary>
<div markdown="1">

  
어떤 학습 알고리즘은 훈련 샘플의 순서에 민감해서 많은 비슷한 샘플이 연이어 나타나면 성능이 나빠짐 데이터셋을 섞으면 이런 문제를 방지가능   
➡️ SGD가 샘플을 섞어야 하는 대표적인 경우임.       
사이킷런의 SGDClassifier와 SGDRegressor는 기본적으로 에포크(전체 트레이닝 데이터세트에 대해 트레이닝해야 하는 횟수)마다 관련 데이터를 다시 섞음     
  
하지만 반대로 섞으면 오히려 나빠지는 경우가 있다          
(섞는게 좋지 않은 예)      
시계열 데이터
* 주식가격     
* 날씨 예보      

➡️ 이 경우는 다음 포스트에서 살펴보겠다      

  
</div>
</details> 

그럼 이제 SGDClassifier 모델을 만들고 전체 훈련 세트를 사용해 훈련시켜보겠다.    

```python
from sklearn.linear_model import SGDClassifier

sgd_clf = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)
sgd_clf.fit(X_train, y_train_5)
```

```
SGDClassifier(random_state=42)
```


------
-----

# 성능 측정

## 오차행렬
= confusion matrix      
기본적인 아이디어는 클래스 A의 샘플이 클래스 B로 분류된 횟수를 세는 것임.      

예를들어 분류기가 숫자 5의 이미지를 3으로 잘못 분류한 횟수를 알고 싶다면 오차 행렬의 5행 3열을 보면 됨.    

### 예측값 만들기 
오차 행렬을 만들려면 **실제 타깃과 비교**할 수 있도록 먼저 **예측값**을 만들어야 함.       
```cross_val_predict()``` 함수 사용      
* k- 겹 교차 검증을 수행      
* 평가 점수를 반환하지 않고 각 테스트 폴드에서 얻은 예측을 반환     
* 훈련 세트의 모든 샘플에 대해 깨끗한 예측을 얻게 됨.
  * 여기서 깨끗하다는 뜻은 모델이 훈련하는 동안 보지 못했던 데이터에 대해 예측했다는 의미

```python
from sklearn.model_selection import cross_val_predict

y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)
```


### 오차행렬 만들기

![image](https://user-images.githubusercontent.com/76824611/139653528-1fb5f702-30a2-4329-b113-745b2f0c2c2e.png)

* TN : 예측값을 Negative 값 0으로 예측했는데 실제 값 역시 Negative 값 0 일때   
* FP : 예측값을 Positive 값 1으로 예측했는데 실제 값은 Negative 값 0 일때   
* FN : 예측값을 Negative 값 0으로 예측했는데 실제 값은 Positive 값 1 일때   
* TP : 예측값을 Positive 값 1으로 예측했는데 실제 값 역시 Positive 값 1 일때  



```confusion_matrix()``` 함수 사용     
* 타깃 클래스 ```y_train_S```    
* 예측 클래스 ```y_train_pred``` 를 넣고 호출         


```python
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import confusion_matrix

confusion_matrix(y_train_5, y_train_pred)
```

```
array([[53892,   687],
       [ 1891,  3530]])
```


----


## 분류기 지표 

### 정밀도 precision   
오차 행렬이 많은 정보를 제공해주지만 가끔 더 요약된 지표가 필요할 때도 있음.    

이를 위해 양성 예측의 정확도를 살표본 것을 분류기의 정밀도라고 함.      

(정밀도 식)    
$$TP / (TP+FP)$$.         

![image](https://user-images.githubusercontent.com/76824611/139654084-218e9068-abe9-44d6-9976-45947661a7be.png)

(구현)
```python
from sklearn.model_selection import cross_val_predict

precision_score(y_train_5, y_train_pred)  # == 4096 / (4096 + 1522)  
```
```
0.8370879772350012
# 정밀도가 꽤 높다
```

---

### 재현율 recall   
확실한 양성 샘플 하나만 하면 간단히 완벽한 정밀도를 얻을 수 있지만,   
이는 분류기가 **다른 모든 양성 샘플을 무시**하기 때문에 그리 유용하지 않음.    

그러므로 정밀도는 재현율 이라는 또 른 지표와 같이 사용하는 것이 일반적입니다.   

재현율: 분류기가 정확하게 감지한 양성 샘플의 비율      
= 민감도    
= 진짜 양성 비율   

(재현율 식)    
$$TP / (TP+FN)$$.          

![image](https://user-images.githubusercontent.com/76824611/139655006-e43faffd-4b08-46b5-9525-28ad5cc57804.png)



  
(구현)
```python
from sklearn.model_selection import cross_val_predict

recall_score(y_train_5, y_train_pred) # == 4096 / (4096 + 1325) 
```
```
0.6511713705958311
# 반면 재현률은 낮은 수치를 보인다
# 정밀도로는 예측을 단정하기 어렵다는 것을 보여준다
```


----

### $$F_1$$ 점수

정밀도와 재현율을 하나의 숫자로 만든 것.     

이는 두 분류기의 성능비교에 유용함.     

$$F_1$$ 점수는 정밀도와 재현율의 **조화 평균**임     
* 정밀도와 재현율이 비슷한 분류기에서는 $$F_1$$ 점수가 높음     
![image](https://user-images.githubusercontent.com/76824611/139655504-d1cfa084-1223-4440-ab3d-d3d291f89980.png)

(구현)
```python
from sklearn.metrics    import fl_score 
fl_score (y_train_S, y_train_pred) 
```
```
0.7420962043663375 
```




<details>
<summary>📜 $$F_1$$ 점수가 항상 제일 중요한가? </summary>
<div markdown="1">
  
아니다! 상황에 따라 다르다.     
  
상황에 따라 정밀도가 중요할 수도 있고 재현율이 중요할 수도 있다.     
  
**[정밀도가 더 중요한 경우]**     
어린이이에게 안전한 동영상을 걸러 는 분류기를 훈련시키는 상황     
➡️ 재현율은 높으나 정말 나쁜동영상이 몇 개 노출되는것보다     
* **좋은동영상이 많이 제외**되더라도 (낮은재현률)     
* 안전한 것들만 노출시키는 (높은 정밀도) 분류기를 선호        
  

  
</div>
</details>  


----

###  정밀도/재현율 트레이드오프 
위와같이 데이터마다 중요해지는 지표가 다르고 두 지표를 모두 높이는 것은 불가능하다.     

즉  **정밀도/ 재현율 트레이드 오프**는 정밀도를 올리면 재현율이 줄고 그 반대도 마찬가지라는 것을 뜻한다.    

SGDClassifier가 분류를 어떻게 결정하는지 살펴보며 이 트레이드오프를 이해해보자.       

이 분류기는 **결정 함수 decision function** 를 tk용하여 각 샘플의 점수를 계산한다.   
* 이 점수가 임겟값보다 **크면**: 샘플을 양성 클래스에 할당      
* 이 점수가 임겟값보다 **작으면**: 샘플을 음성 클래스에 할당      


이 점수에 따라, 가장 낮은 점수부터 가장 높은 점수까지 몇 개의 숫지를 나열해보면,    
![image](https://user-images.githubusercontent.com/76824611/139658329-a448038d-c567-4589-b151-48d1df129944.png)
[출처] 핸즈온 머신러닝

**양성 예측**: 임겟값 오른쪽    
* 4 개의 진짜양성(실제 숫자 5)      
* 하나의 거짓 양성(실제 숫자 6)      
➡️ 이 임겟값에서 정밀도는 80%(5 개 중 4개)       
 
**전체를 통한 예측**: 실제 숫자 5는 6개고 분류기는 4개      
➡️ 재현율은 67%( 6개 중 4개)입니다.       

**임계값 높여 예측**: 이번에 임겟값을 높이면 임겟값을 오른쪽 화살표로 옮기면 )    
* 정밀도) 거짓 양성 숫자 이 진짜 음성이 되어 정밀도가 높아짐 -> 100이 됨         
* 재현율) 진짜 양성 하나가 거짓 음성이 되었으므로 재현율이 50 로 줄어듦        
➡️ 반대로 임겟값을 내리면 재현율이 높아지고 정밀도가 줄어듭니다.


사이킷런에서 임겟값을 직접 지정할 수는 없지만,     
예측에 사용한 점수는 확인 가능.      
* ```decision_function()``` 메서드를 호출     
* 각 샘플의 점수를 얻을 수 있음.       
* 이 점수를 기반으로 원하는 임겟값을 정해 예측 가능     


<details>
<summary>👀코드 보기</summary>
<div markdown="1">
  
```python
y_scores = sgd_clf.decision_function([some_digit])
# y_scores =  array([2164.22030239])
threshold = 0
y_some_digit_pred = (y_scores > threshold)
y_some_digit_pred
# array([True])
```
  
SGDClassifier 의 임겟값이 0 이므로 위 코드는 True 를 반환
  
</div>
</details>

<details>
<summary>👀 재현율 줄이기(임계값 높이기)</summary>
<div markdown="1">
  
```python
y_scores = sgd_clf.decision_function([some_digit])
# y_scores =  array([2164.22030239])
threshold = 0
y_some_digit_pred = (y_scores > threshold)
y_some_digit_pred
# array([True])
```
  
SGDClassifier 의 임겟값이 0 이므로 위 코드는 True 를 반환
  
</div>
</details>
