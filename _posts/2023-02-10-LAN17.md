---
title: "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer 정리"
date:   2023-02-10
excerpt: "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer paper review"
category: #[Paper]
layout: post
tag:
#- Paper
order: 0

comments: true
---


# Abstract
<span style="background-color:#F5F5F5">**[논문 배경]**</span>    
모델이 Downstream Task에서 fine-tuning되기 전에 data-rich task에서 pre-train을 하는 것은  자연어 처리(NLP)의 강력한 기술로 부상했다.     
즉 이러한 [transfer learning](https://yerimoh.github.io/DL12/)은 NLP에 큰 발전을 가져왔다.    

<span style="background-color:#F5F5F5">**[논문의 목적]**</span>    
* 모든 텍스트 기반 언어 문제를 text-to-text 형식으로 변환하는 통합 프레임워크를 도입하여 <span style="background-color:#fff5b1">NLP에 대한 [transfer learning](https://yerimoh.github.io/DL12/)를 전반적으로 탐구</span>한다.     
* 위 탐구를 통해 얻은 통찰력과 규모 및 본 논문에서 제안할 <span style="background-color:#fff5b1">"Colossal Clean Crawled Corpus"를 결합</span>하여 많은 NLP evaluation에서 SOTA 성능을 보였다.        
➡ 공개한 [data set, pre-trained models, and code](https://github.com/google-research/text-to-text-transfer-transformer) 링크를 첨부하였다.        


<details>
<summary>📜 Downstream Task 의미 보기</summary>
<div markdown="1">
  

구체적으로 풀고 싶은 문제들을 말한다.

NLP에서는 언어모델을 pre-train방식을 이용해 학습을 진행하고,    
그 후에 원하고자 하는 task를 fine-tuning하는 방식을 통해 모델을 업데이트 하는 방식을 사용하는데 이때, task를 Downstream Task라 한다.

예를들어, BERT의 언어모델을 질의응답 Task라인 squad를 학습한다고 할때, 이때 질의응답 Task를 다운스트림 Task로 볼 수 있을것이다.  
  
  
</div>
</details>  

----
----



# Introduction

<span style="background-color:#F5F5F5">**[최근 연구 동향]**</span>    
자연어 처리(NLP)작을 을 위한 train이 가능하여면 모델이 **downstream learning에 적합한 방식으로 텍스트를 처리**할 수 있어야 한다.              
그런데 이는 **모델이 텍스트를 "이해"할 수 있게 학습한다고 보기엔 힘들다**.               
➡ 현대 기계 학습 관행에서 이러한 train이 명시적으로 수행되는 경우가 거의 없어, 대신 **Auxiliary Task의 일부**로 학습되는 경우가 많다.        


<details>
<summary>📜 Auxiliary Task 의미 보기</summary>
<div markdown="1">

본 task는 아니지만, 본 task에서의 성능이 더 잘 나올 수 있도록 도와주는 보조 task  

</div>
</details> 
  
최근에는 **데이터가 풍부한 작업**에 대해 **전체 모델을 pre-train하는 것**이 점점 더 **일반화**되고 있다.     
이상적으로, 이 pre-train은 모델이 범용 능력과 지식을 개발하게 하고, 이를 다운스트림 작업으로 이전할 수 있도록 한다.     
➡ 더 큰 데이터 세트에서 더 큰 모델을 훈련시키는 것만으로 더 나은 성능을 달성할 수 있다.    




<span style="background-color:#F5F5F5">**[현 경향으로 인한 한계]**</span>    
이러한 경향으로 인해 NLP에 대한 **transfer learning 방법론을 개발**하는 연구들이 활발하게 이루어졌다.      
이렇게 이 분야가 급성장하여 연구가 활발해지니 아래와 같은 작업들이 어려워졌다.       
* 여러 algorithms을 비교    
* 새로운 contributions의 효과 파악    
* transfer learning을 위한 기존 방법의 space 이해        


✔ 그래서 본 논문은 이 분야의 원활한 이해를 위해, **다양한 접근법을 체계적으로 연구**하고 **필드의 현재 한계를 밀어낼 수 있는 transfer learning에 대한 통합된 접근법을 활용**한다. 
 


<span style="background-color:#F5F5F5">**[본 논문의 해결책]**</span>      
본 논문 work의 기본 아이디어는 <span style="background-color:#fff5b1">모든 텍스트 처리 문제를 **“text-to-text” 문제로 처리**</span>하는 것이다.             
즉, **텍스트를 입력으로 받아들이고 새로운 텍스트를 출력으로 생성**하는 것이다.          
* 이러한 텍스트 간 프레임워크는 우리가 고려하는 모든 작업에 **동일한 모델, 목표, 훈련 절차 및 decoding 프로세스를 직접 적용**할 수 있게 한다.          
* 본 논문은 질문 답변, 문서 요약 및 감정 분류를 포함한 다양한 영어 기반 NLP 문제에 대한 성능을 평가하여 이러한 **유연성을 활용**한다.        
* 이 통합 접근법을 통해, 우리는 다양한 transfer learning의 target, 레이블이 지정되지 않은 데이터 세트 및 기타 요인의 효과를 비교하는 동시에 이전에 고려되었던 것 이상으로 **모델과 데이터 세트를 확장**하여 NLP에 대한 **transfer learning의 한계를 탐색**할 수 있다.    




본 논문은 본 논문의 목표가 새로운 방법을 제안하는 것이 아니라, **그 분야가 어디에 서 있는지에 대한 포괄적인 관점을 제공하는 것**임을 강조한다.      
즉, 우리의 작업은 본 목표를 달성하기 위해 아래와 같은 task로 구성된다.         
➡ 주로 기존 기술의 조사, 탐구 및 경험적 비교       


또한 본 논문은 다음과 같은 방식으로 **현재 접근 방식의 한계를 탐구**한다.        
본 논문이 고려하는 많은 task에서 SOTA 결과를 얻기 위해 체계적인 연구(train 모델을 최대 110억 개 parameters까지 확장)수행       
* 이 규모의 실험을 수행하기 위해 웹에서 긁어낸 수백 기가바이트의 clean 영어 텍스트로 구성된 데이터 세트인 "Colossal Clean Crawled Corpus"**(C4)** 를 소개한다.        
* **transfer learning의 핵심 기능**은, **데이터가 부족한 환경에서  pre-trained models을 활용할 수 있는 가능성**이라는 것을 인식하여,      
[코드, 데이터 세트 및 사전 훈련된 모델](https://github.com/google-research/text-to-text-transfer-transformer
)을 릴리스했다.    




<span style="background-color:#F5F5F5">**[논문 구성]**</span>            
* base model과 그 구현    
* 모든 text processing 문제를 text-to-text 작업으로 공식화하는 절차 및 고려하는 작업 모음에 대한 논의    
* 섹션 3에서, NLP에 대한 transfer learning 분야를 탐구하는 대규모 실험 세트를 제시          
* 섹션(섹션 3.7)의 끝에서, 우리는 체계적인 연구의 통찰력을 결합하여 광범위한 벤치마크에 대한 최첨단 결과를 얻음    
* 섹션 4에서, 결과에 대한 요약을 제공 한 뒤, 미래에 대한 전망으로 마무리             




---
---


# 2. Setup    



본 논문은 large-scale 경험적 연구의 결과를 제시하기 전에 아래와 같은 것들을 먼저 제시한다,   
* [Transformer 모델 아키텍처](https://yerimoh.github.io/Lan/)와 평가하는 downstream tasks을 포함하여 결과를 이해하는 데 필요한 **배경 주제를 검토**한다.        
* **모든 문제를 text-to-text task으로 처리하기 위한 접근 방식**을 소개    
* **"Colossal Clean Crawled Corpus"(C4) 설명:** 레이블이 지정되지 않은 텍스트 데이터의 소스로 생성한 공통 크롤 기반 데이터 세트임     




우리는 우리의 모델과 프레임워크를  <span style="background-color:#fff5b1">“Text-to-Text Transfer Transformer” (T5)</span> 라고 부른다.      





---


## 2.1 Model


NLP에 대한 전이 학습에 대한 초기 결과는 반복 신경망을 활용했지만,  
최근에는 "Transformer" 아키텍처를 기반으로 한 모델을 사용하는 것이 더 일반화되었다.     


Transformer는 transfer learning에 효과적이므로, 이후 다양한 NLP 설정에 사용되었다.          
본 논문에서도 **모든 모델의 base를 Transformer 아키텍처**로 하였다.         

아래에 언급된 세부사항과 섹션 3.2에서 탐구한 변형을 제외하고,     
본 논문은 Transformer 아키텍처에서 크게 벗어나지 않는다.      


<details>
<summary>📜 Transformer를 자세히 알고 싶다면? (참고자료) </summary>
<div markdown="1">

이 논문(아키텍처)에 대해 더 자세히 알고싶다면 아래 자료들을 참고하자,    
* [원본 논문](https://arxiv.org/abs/1706.03762)    
* 후속 튜토리얼 3,4(뒤에 나옵니다.)    
* [본 포스트를 정리한 필자가 정리한 포스트](https://yerimoh.github.io/Lan/)         

</div>
</details> 
  

그리고 본 논문에서 Transformer에대해 간단간단하게 설명해줬는데 원한다면 아래 자세한 설명 보기를 눌러 한 번 읽어보길 바란다.(그렇지만 원 논문을 읽어봐야 아래 내용들도 이해가 갈 것이다.)   

<details>
<summary>📜 Transformer를 자세히 알고 싶다면?(본 논문의 설명) </summary>
<div markdown="1">




 
**Transformer의 중요한 요소는,** [self-attention](https://yerimoh.github.io/Lan/#sub-layer1-self-attention)이다.         
self-attention은 각 요소를 나머지 sequence의 가중 평균으로 대체하여 시퀀스를 처리하는 attention의 변형이다.    

**Transformer의 구조는,** [encoder-decoder 아키텍처](https://yerimoh.github.io/Lan/#transformer-%EB%AA%A8%EB%8D%B8-%EA%B0%9C%EC%9A%94)로 구성되었으며 sequence-to-sequence 작업을 위해 고안되었다.        

전반적으로, 본 논문 모델의 encoder-decoder Transformer의 구현은 원래 Transformer의 형태를 밀접하게 따른다.               

**[Transformer의 동작 과정]**       
* **1)** 토큰의 input sequence를 embeddings sequence를에 매핑한 다음 encoder로 전달한다.      
* **2)** encoder는  “blocks”의 스택으로 구성되며, 각 스택마다 self-attention layer 계층과 small feed-forward network를 갖고있다.     
* **3)** 각 스택 안의 2가지 요소들의 입력에는 Layer normalization가 적용된다.     
* **4)** 이후, activations이 재조정되고 추가 bias이 적용되지 않는 단순화된 버전의 Layer normalization를 사용한다.      
* **5)** layer normalization 후, residual skip connection은 각 스택 안의 2가지 요소의 입력을 출력에 추가한다.      
* **6)** 드롭아웃은 피드포워드 네트워크 내에서 스킵 연결, 주의 가중치 및 전체 스택의 입력 및 출력에 적용된다.   
* **7)** decoder는 encoder의 출력에 참여하는 각 self-attention layer 다음에 standard attention 메커니즘을 포함한다는 점을 제외하고는 인코더와 구조가 유사하다.       
decoder의 self-attention 메커니즘은 모델이 과거 출력에만 주의를 기울일 수 있도록 한다.     
* **8)** 최종 decoder 블록의 출력은 소프트맥스 출력을 가진  dense 레이어로 들어가며, 그 가중치는 입력 임베딩 매트릭스와 공유된다.      
* ✨ 여기서, 트랜스포머의 모든 attention 메커니즘은 추가로 처리되기 전에 출력이 연결되는 독립적인 “heads”로 나뉘어있다.          
![image](https://user-images.githubusercontent.com/76824611/132572962-94a60e8b-2182-466a-8d1d-47a86ee83a14.gif)
</div>
</details> 
  




<span style="background-color:#F5F5F5">**[position embeddings의 필요성]**</span>         
self-attention는 각 단어를 병렬으로 처리하기 때문에(순서 고려못함), 순서를 부여하는 것이 일반적이다.     
즉 I love you란 문장이 있으면, 아래와 같이 **한 encoder 안에서 따로 처리**되는 것을 확인할 수 있다.    
이렇게 단어 각각이 각각 임베딩되고 **병렬적으로 학습**되므로 **이 단어들의 순서가 무시**된다는 것이다.       
즉 아래 예시에서도 어짜피 순서없이 동시에(병렬로)학습되니 왼쪽과 오른쪽의 차이가 없다.     
⚠️ 즉, **병렬처리로 인해 문장 내의 순서정보가 무시**되어 **이 순서 정보를 넣어주기위해 position embeddings을 추가**하는 것이다.   
![image](https://user-images.githubusercontent.com/76824611/223513725-b980210f-1360-4dc9-b623-68228836ef86.png)


<span style="background-color:#F5F5F5">**[position embeddings의 필요성]**</span>         

원래 Transformer는 sinusoidal [position signal](https://yerimoh.github.io/Lan/#positional-encoding)를 사용하거나 position embeddings을 학습했지만, 최근에는 relative position embeddings을 사용하는 것이 더 일반화되었다.     
* 기존 position embeddings: 각 위치에 고정된 임베딩을 사용     
* 최근 relative position embeddings: self-attention에서 비교되는 “key” 와 “query” 사이의 오프셋에 따라 다른 학습 임베딩을 생성한다.      

Relative position embedding은 self-attention의 key와 query 사이의 거리에 따라 학습된 embedding을 생성한다.

T5에서는 position embedding으로 단순하게 scalar을 사용한다.

그리고 이 스칼라는 attention weight를 계산할 때 logit에 더해주는 값으로 사용한다. 

 

뿐만 아니라 효율성을 위해 position embedding 값은 모든 레이어에서 공유하되,

각 레이어의 attention head에서는 각기 다른 학습된 position embedding을 사용한다.

즉, 가능한 key-query 거리의 범위에 따라 고정된 개수의 embedding이 학습되게 된다.




<span style="background-color:#F5F5F5">**[position embeddings의 필요성]**</span>         
그러나 절대 위치가 아닌 상대 위치에 관한 다른 종류의 데이터를 다루는 경우에는 어떻게 될까.   
아래 그림의 예시를 보자.      
아래 그림과 같은 경우에는 특정노드가(예를 들어 you가) 첫번째라고 말하기엔 임의성이 다분하다.    
그래서 아래와 같은 경우 각 노드(네모)에 순서를 부여하는 과정에선 많은 문제가 생길 수 있다.        
 ![image](https://user-images.githubusercontent.com/76824611/223515775-c59db6cd-1305-4002-95ad-1869c8e11d9b.png)    
 
그래서 **절대 순서를 없애고** 그래프 또는 **시퀀스의 요소 간 거리 관한 상대적 위치**로 인코딩을 하는 것이다.   


상대 임베딩의 경우는 각 토큰에 고유한 위치 임베딩이 있는 기존 position embedding과는 다르다.   
상대적인 표현을 사용하면 각 단어 또는 토큰에 하나의 위치 임베딩만 있는 것이 아니라 **토큰 간의 관계를 설명하기 위해 시퀀스에 있는 토큰 수 만큼 많은 위치 임베딩을 만든다**.    
만드는 방법은 아래 과정과 같다.   
<iframe src="https://www.slideshare.net/slideshow/embed_code/key/oRhvMuYOW21nWC?hostedIn=slideshare&page=upload" width="476" height="400" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"></iframe>

즉 위와 같이 표현함에 따라 각 토큰이 다른 토큰에 대한 위치 관계를 인코딩하게 된다.    
즉 각 토큰($$w_n$$)은 자기 토큰과 다른 토큰과의 위치정보를(거리 정보를)담아 두 토큰관의 관계를 설명한다.    
즉 $$x_4$$의 예시를 들면, 아래와 같다.    
각 position token($$w_n$$)의 n의 기준은 자신과 자신의 위치정보 $$w_0$$을 기준으로 오른쪽으로 이동하면 $$w_1,w_2$$, 왼쪽으로 이동하면 $$w_{-1}, w_{-2}$$가 된다.    

이러한 벡터는 한 토큰과 다른 토큰 사이의 관계에서 비롯되므로 이를 위해 아래와 같은 표기법을 사용할 수 있다.      

논문에선 **k에서 cliping을 실험**한다.     
즉 특정 거리 후에 위치 임베딩이 동일한 값을 얻는다.    
즉 k=2인 경우  $$w_3,w_4$$는 모두  $$w_2$의 값을 갖는다.   
그러니까 아래와 같이 대각선을 기준으로 대칭인 값끼리 같은 값을 갖는다는 것이다.    
![image](https://user-images.githubusercontent.com/76824611/223534198-bccc5acc-a730-4469-8cf2-e4a6777b43e1.png)

자 그런데 $$x_1$$을 표현하기위해 이 토큰($$w_1,w_2,w_3,w_4,w_5)들을 다 더해버리면 위치정보가 이상해진다.     

그러므로 이 위치정보를 유지하면서도 토큰을 표현하기위해 self attention을 사용한다.     

이렇게 self attention을 이용하는 식은 아래와 같다.   
![image](https://user-images.githubusercontent.com/76824611/223534400-1685ee37-d95d-48e5-a5d9-cdc6db658dda.png)


* 1) $$x_jW^v$$L 각 토큰 벡터는 먼저 선형변환으로 변환된다.     
* 2) 그런 다음 각 토큰에 대한 새로운 표현 $$z_i$$는 모든 토큰에 대한 가중치의 합계이며, 가중치는 일종의 중요도 점수이다.     
➡ 따라서 더 중요한 토큰엔 거 많은 가중치가 부여된다.     
* 그래서 여기서 새 표현이 계산되는 위치에 위치 정보를 $$a_{ij}^v$$를 더해줌으로써 추가할 수 있다.(이 과정에서 차원이 더 높아진다.)     


즉 이러한 표현을 통해 "각 토큰은 의미론적 정보를 가지고있지만 어떤 차원에서의 내 위치는 다른 모든 두번째 이웃과 비슷하기 때문에 오른쪽에 있는 두 번째 이웃이기도 한다"를 나타낼 수 있다.      

이제 새로운 표현 z는 상대위치에 대한 정보를 받지만, self attention의 가중치 계수는 그렇지 않다.   
따라서 가중치 계수는 중요도 점수가 위치 정보에 기반한 결정을 내리도록 self position에 대한 푸쉬($$a_{ik}^K$$)도 받는다.   
![image](https://user-images.githubusercontent.com/76824611/223534443-95c8213e-8bbd-45d4-b10e-3f8973cb7e30.png)



그 결과 이제 모든 토큰에는 두가지 변형의 시퀀스에 있는 토큰만큼 많은 Relative Position 임베딩을 갖는다,   
* 첫 번쨰는 위에서 설명한 것과 같이 값에 대한 상대적인 임베딩이다.  
![image](https://user-images.githubusercontent.com/76824611/223534400-1685ee37-d95d-48e5-a5d9-cdc6db658dda.png)
* 두번째도 위에서 설명한 attention 가중치를 알리는 key에 대한 임베딩이다.   
![image](https://user-images.githubusercontent.com/76824611/223534443-95c8213e-8bbd-45d4-b10e-3f8973cb7e30.png)

위으 임베딩을 바탕으로 벡터의 정확한 값이 학습되며, 이는 모델이 스스로 최상의 balance가 무엇인지 파악할 수 있게한다.     

이 논문은 텍스트로만 실험했으며 이는 분명히 시퀀스이며, 기계번역에서 약간의 성능을 얻는따.

그러나 단어 체인은 단순한 그래프일 뿐이며 이를 넘어  일반적으로 요소간의 쌍 관계가 있는 모든 그래프 표현에 이 방법을 적용할 수 있다.   

이러한 상대적 표현은  우리가 시퀀스에 있는지 아니면 더 목잡한 그래프에 있는지에 관계없이 토큰이 서로 얼마나 떨어져있는 지에만 의존하기 때문이다.     

또다른 장점은 k에 대해 클리핑할 때 이 학습된 위치 정보가 모든 시퀀스의 길이로 일반화된다는 것이다.    

k에대해서 클리핑하면 장기종속성 정보가 제거되기때문에 조금 이상하다고 느낄 수 있다.    
그래서 우리는 무언가가 가까이 있거나 멀리 있다는 것 만 저장할 수 있지만 그것이 얼마나 떨어져있는지는 알 수 없다.     

많은 반복을 통해 더 멀리있는 정보가 관심 지점으로 확산될 수있지만 다중 혹은 멀리있는 noise를 포함 할 수 있으므로 항상 좋다고볼 수 ㄴ없다.    


따라서 상대적 위치표현에서 k에서의 클리핑은 대부분 로컬 종속성에 의존하는 작업을 해치치 않는 상대적 위치 이벤트 호라이즌과 약간 비슷하게 작용한다.     









우리는 각 "임베딩"이 주의 가중치를 계산하는 데 사용되는 해당 로짓에 추가되는 단순한 형태의 위치 임베딩을 사용한다. 효율성을 위해, 우리는 또한 주어진 계층 내에서 각 주의 헤드가 다른 학습된 위치 임베딩을 사용하지만, 우리 모델의 모든 계층에 걸쳐 위치 임베딩 매개 변수를 공유한다. 일반적으로, 각각 가능한 키 쿼리 오프셋 범위에 해당하는 고정된 수의 임베딩이 학습된다. 이 연구에서, 우리는 크기가 최대 128의 오프셋까지 대수적으로 증가하는 범위를 가진 모든 모델에 대해 32개의 임베딩을 사용하며, 이를 초과하여 모든 상대 위치를 동일한 임베딩에 할당한다. 주어진 계층은 128 토큰 이상의 상대적 위치에 둔감하지만, 후속 계층은 이전 계층의 로컬 정보를 결합하여 더 큰 오프셋에 대한 민감도를 구축할 수 있다. 요약하면, 우리의 모델은 레이어 표준 편향을 제거하고, 레이어 정규화를 잔류 경로 외부에 배치하고, 다른 위치 임베딩 체계를 사용한다는 점을 제외하고 Vaswani 등(2017)이 제안한 원래 트랜스포머와 대략 동일하다. 이러한 아키텍처 변화는 전이 학습에 대한 경험적 조사에서 고려하는 실험적 요인과 직교하기 때문에 향후 작업을 위해 영향의 절제를 남겨둔다.



As part of our study, we experiment with the scalability of these models, i.e. how their
performance changes as they are made to have more parameters or layers. Training large
models can be non-trivial since they might not fit on a single machine and require a great deal
of computation. As a result, we use a combination of model and data parallelism and train
models on “slices” of Cloud TPU Pods.5 TPU pods are are multi-rack ML supercomputers
that contain 1,024 TPU v3 chips connected via a high-speed 2D mesh interconnect with
supporting CPU host machines. We leverage the Mesh TensorFlow library (Shazeer et al.,
2018) for ease of implementation of both model parallelism and data parallelism (Krizhevsky,
2014).



우리의 연구의 일환으로, 우리는 이러한 모델의 확장성, 즉 더 많은 매개 변수나 계층을 가질수록 성능이 어떻게 변하는지 실험한다. 대규모 모델을 훈련하는 것은 단일 시스템에 맞지 않을 수 있고 많은 계산이 필요할 수 있기 때문에 사소한 일이 아닐 수 있다. 결과적으로, 우리는 모델과 데이터 병렬화를 결합하여 Cloud TPU Pod의 "조각"에서 모델을 훈련시킨다.5 TPU 포드는 CPU 호스트 시스템을 지원하는 고속 2D 메시 인터커넥트를 통해 연결된 1,024개의 TPU v3 칩을 포함하는 멀티 랙 ML 슈퍼컴퓨터이다. 모델 병렬화와 데이터 병렬화의 용이한 구현을 위해 Mesh TensorFlow 라이브러리(Shazeer et al., 2018)를 활용한다(Krizhevsky, 2014).
